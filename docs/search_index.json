[["index.html", "Introduction to Stata Chapter 1 Preface 1.1 How to use this document 1.2 Contact information 1.3 Acknowledgments", " Introduction to Stata CSCAR Staff Last updated: 2023-02-02 Chapter 1 Preface These notes are split into four primary sections: Chapter 2: The Basics of Stata - Interacting with Stata. Chapter 3: Working with Data Sets - Importing, opening, and saving data sets. Chapter 4: Data Management - The basics of maintaining and exploring a data set. Chapter 5: Data Manipulation - Creating and modifying variables and other ways of manipulating your data. These sections will generally be presented in sequence. The discussion will alternate between theory and practice. The format will alternate between lecture and exercises. Please ask questions as soon as they arise in your mind. Please provide feedback or voice concerns. There are two additional sections: Chapter 6: Programming &amp; Advanced Topics - Topics for users who wish to move beyond the basics. Appendix - Houses the exercise solutions. 1.1 How to use this document These notes are published in bookdown format which enables easy creation of longform documents (using a mixture of markdown, R, and for these notes specifically, Stata’s dyndoc, which was added in Stata 15). The table of contents is found on the left hand side, with subsections expanding below the current section. At the top of the page are four icons, from left to right they 1) Hide/show the table of contents, 2) Search this document, 3) Change the font the book is displayed in, and 4) Display keyboard shortcuts. All images should link to full-size versions to see detail if needed. 1.2 Contact information 1.2.1 CSCAR http://cscar.research.umich.edu/ CSCAR is available for free consultations with PhD statisticians (email deskpeople@umich.edu to request a consultation). CSCAR also has GSRAs available for more immediate help. Walk-ins to our office in Rackham are welcomed Monday-Friday 9am to 5pm (Closed Tuesdays 12-1pm). Alternatively, on our website, you can self-schedule into an hour consultation with the graduate students, which can be either remote or in-person (these are usually available same- or next-day). CSCAR operates a email for help with statistical questions, feel free to send concise questions to stats-consulting@umich.edu. The current contact for questions about the notes: Josh Errickson (jerrick@umich.edu). 1.3 Acknowledgments These notes have evolved over the years thanks to many CSCAR statisticians, including Josh Errickson, Giselle Kolenic, Brady West, Heidi Reichert, and Lingling Zhang. This material was created for use in workshops and short courses presented by faculty and staff from the Consulting for Statistics, Computing &amp; Analytics Research (CSCAR) at the University of Michigan. No part of this material may be used for other purposes, copied, changed, or sold. "],["the-basics-of-stata.html", "Chapter 2 The Basics of Stata 2.1 The Stata Environment 2.2 One Data 2.3 Give Stata a command 2.4 Updating 2.5 Installing user-written commands 2.6 Do-files 2.7 Exercise 0 2.8 Basic command syntax 2.9 Stata Help 2.10 Working directory", " Chapter 2 The Basics of Stata 2.1 The Stata Environment When a user first opens Stata, there are five panes that will appear in the main window: The Results Pane All commands which are run are echoed out here, as well as any output they produce. Not all commands produce output though most do (e.g. obtaining summaries of the data or running a statistical procedure). Items that appear in the results pane in blue are clickable. The Command Pane This pane is where users can interactively type Stata commands and submit them to Stata for processing. Everything that one can do in Stata is based on a set of Stata commands. Stata commands are case sensitive. All Stata commands and options are in lower case. When variables are used in any command, the variable names are also case sensitive. The Variables Pane This pane displays all of the variables in the data set that is currently open in Stata, and users can click on variable names in this pane to carry the variables over into Stata commands in the Command pane. Note that Stata allows only one data-set to be open in a session. The History Pane Stata will keep a running record of all Stata commands that have been submitted in the current session in this pane. Users can simply click on previous commands in this pane to recall them in the Command pane. The Properties Pane This pane allows variable properties and data-set properties to be managed. Variable names, labels, value labels, display formats, and storage types can be viewed and modified here. Each of these five panes will be nested within the main Stata session, which contains menus and tool bars. There are additional windows that users can access from the Window menu, which include the Graph window (which will open when graphs have been created), the Viewer window (which is primarily used for help features and Stata news), the Data Editor window (for use when viewing data sets), and the Do-file Editor window (for use when writing .do files). In the lower left-hand corner of the main Stata window (below the panes), there will be a directory displayed. This is known as the working directory, and is where Stata will look to find data files and other associated Stata files unless the user specifies another directory. We will cover examples of changing the working directory. 2.1.1 Alternate Layout An alternate layout (found in View -&gt; Layout) places the History and Variables pane in tabs on the right hand side instead. (Note that this screenshot is taken on a Mac, as opposed to the original screenshot on Windows, just for comparison.) 2.2 One Data One functionality where Stata differs than most other statistical or data analysis software is that Stata can only work with a single data set at a time. Any command you run knows to operate on the data set you have open. For example, there is a command summarize which provides summary information about variables. The command is simply summarize, there is no need to direct it towards a specific data set. If you have multiple data sets you need to work with, you can either Switch between the two data sets as needed. This can be burdensome, though tools such as preserve or frames help greatly. Merge the data sets, the better option. We’ll discuss merging towards the end of the course. 2.3 Give Stata a command Let’s try running a Stata command. In the command pane, type (or copy and paste) the following: version The following should appear in the Results pane: . version version 17.0 The first line proceeded by the . indicates the command that was written, version, and the rest is the output. Here, I am running Stata version 17.0 (your version may vary). In this document, if you see a single command without a period, it indicates something that was not run - either it’s not designed to be run (it’s fake code designed to illustrate a point), or more likely, the output is not interesting or unnecessary. If you instead see a Results output where the first line is the command prefaced by the ., that was run in Stata and only the Results are included since they include the command. The command can still be run, but should be run without the .1. 2.3.1 Saving Results Any output that appears in the Results pane (including the echoed commands and any errors) can be copied and pasted into another location, such as Word. In addition, if you highlight text and right-click, you also have the options: “Copy table”: Useful for exporting to Excel. This can be tempermental; if the selected table is less “regular”, this may not produce the best results. It is most useful for text which comes naturally as a table rather than results which are forced into a table for display purposes. “Copy table as HTML”: You can paste this into a plaintext editor (Notepad.exe or TextEdit, not Word) and save it as a *.html to produce a webpage. If you paste this into Excel you get a slightly different table than the layout for “Copy table” which may be more useful. “Copy as picture”: Does exactly what it says - equivalent to taking a screenshot. Very handy! There are a few commands that can be useful for saving results which we will not cover in this workshop, if you are interested, you can look into the help for them. log: Saves a file consisting of everything printed to the Results pane. putexcel: Adds to a spreadsheet specific strings or output. outreg2: A user-written command to output the results of a model (e.g. regression) in a clean format. 2.3.2 dyndoc Version 15 of Stata introduced “dyndoc” which allows you to weave together narrative text and Stata code to produce a high-quality output (html, word or pdf). This document is written (in part) in dyndoc. It is extremely powerful but is well outside the mandate of this class. If you are interested in this functionality, I’d be happy to help. 2.4 Updating If you have administrative access on your computer (e.g. if it is your personal machine, or your IT department has given you the ability), you can update Stata freely. Major point upgrades such as the newly released 17.0 require purchase and re-installation, but minor upgrades (such as the 16.1 and 16.2 updates) as well as minor internal updates are free. To check for updates, you can run update query If any updates are available (regardless of whether you ran a query first), you can obtain all updates with update all If you do not have administrative access on your computer, you’ll need to reach out to your IT administrators to update. 2.5 Installing user-written commands In addition to built in commands, Stata supports user-written programs, know as “ado-files”2. Once installed, these user-written programs operate identically to any built-in command, with the caveat that they may not be quite as polished or complete since they’re volunteer written. Documentation is rarely up to Stata standards and often relegates details to a manuscript. We won’t be covering any ado-files in these notes, but if you wanted to install a program named newcommand: ssc install newcommand You can remove a program with ssc uninstall newcommand Finally, to see a list of all user-written programs you have installed, used ado Updating Stata will not update any ado-files, instead you can run adoupdate to list all available updates and adoupdate, update to perform all updates. 2.6 Do-files We saw that commands can be typed interactively, one command at a time, and the results immediately observed. From this, the output can be copied/exported/printed, or the results can be saved. However, a better paradigm would save all the commands run separately so that the analysis is reproducible. For this purpose, Stata has Do-files (named because they are saved with the .do extension, such as analysis.do) which are scripts containing only commands and comments. We can then run any subset of the commands (including the entire file), re-running parts or all of the analysis. Additionally you can easily save and/or share this command, allowing yourself or a colleague to re-run the analysis. There are several ways to start a new Do-file. File -&gt; New -&gt; Do-file Click the “Do-file Editor” button in the main window You can enter the command: doedit If you select some commands in the History pane, you can right click and choose “Send select to Do-file Editor”. For the last option there, note that performing that twice will create two separate Do-files instead of appending the commands. Instead, you can copy and paste from the History pane to add to an existing Do-file. Let’s manually add some commands to a Do-file to see how to execute the commands. In a Do-file editor, enter the following sysuse auto, clear summarize price tabulate foreign Once the lines are in the editor, highlight the commands (you do not need to highlight the entire line, you merely need to ensure your selection includes part of every line you want run) and press the “Execute/Do” (on Windows) or “Do” (on Mac) button. You should see the following appear in your Results pane. . sysuse auto, clear (1978 automobile data) . summarize price Variable | Obs Mean Std. dev. Min Max -------------+--------------------------------------------------------- price | 74 6165.257 2949.496 3291 15906 . tabulate foreign Car origin | Freq. Percent Cum. ------------+----------------------------------- Domestic | 52 70.27 70.27 Foreign | 22 29.73 100.00 ------------+----------------------------------- Total | 74 100.00 We will cover in later sections what each of these commands does (sysuse, summarize, tabulate). 2.6.1 Comments Comments are information in a Do-file which Stata will ignore. They can be used to stop a command from running without deleting it, or more usefully, to add information about the code which may be useful for others (or yourself in the future) to understand how some code works or to justify why you made certain choices. In general, comments can also help readability. There are three different ways to enter comments (and one additional special way). First, to comment out an entire line, precede it by *: . * This is a comment Second, you can add a comment to the end of a line with // . version // Returns the Stata version number version 17.0 . // You can also use it to comment out an entire line. There must be a space before the // if it comes after a command: . version// Returns the Stata version number invalid syntax r(198); Thirdly, you can comment out a section by wrapping it in /* and */ . /* Here's a several &gt; line comment. &gt; It just keeps going. */ . summarize /* comment in the middle of a command! */ price Variable | Obs Mean Std. dev. Min Max -------------+--------------------------------------------------------- price | 74 6165.257 2949.496 3291 15906 Note that when a command wraps to more than one line in the Results pane (either due to a manual line break like this or a command that’s too wide for the Results pane), the prefix changes from . to &gt; to indicate that its all one command. Finally, there’s the special comment, ///. Stata commands must be on a single line. However, complicated commands may get very long, such that its hard to read them on a single line. Using /// instead of // allows wrapping onto the next line. . summarize /// &gt; price Variable | Obs Mean Std. dev. Min Max -------------+--------------------------------------------------------- price | 74 6165.257 2949.496 3291 15906 As with //, there needs to be a space before the ///. Only the * works on interactive commands entered in the Command pane. All four versions work in Do-files. 2.6.2 Version control When writing a Do-file, you generally are creating it while using a single version of Stata. If a new version of Stata were released, its possible that your code may operate differently with the new version. If you add version 14.2 to the beginning of your Do-file, Stata will execute the commands as if it were still running version 14.2, even if you’ve updated to Stata 17. This works all the way back to Stata 2. (Obviously, this will not work if you try to run as Stata 17 when you only have Stata 14 installed.) Note that this version is the same command as the version we’ve been discussing before. It operates in this special fashion only when included at the top of a Do-file. Best practices is to always include a version ##.# line at the top of each Do-file, but if its code that will continue to see use, you should test it with the newer releases and update the code as necessary! 2.7 Exercise 0 Get familiar with the Stata interface. If you’ve been following along, you may have already done all these! If you haven’t already, open Stata. (You should be able to do this by clicking on the “Start” menu in the bottom left of the screen, then typing “Stata”.) The use of each pane will become much clearer when we start opening data in the next section, but take a look at each. Give Stata a command: query memory. This lists some settings related to memory usage in Stata, for example, maxvar is the maximum number of variables in a model; matsize is the largest number of predictors allowed in a model. Open a Do file. Place a version command at the top of the file corresponding to the version on your computer. Place the query memory command from the last step in the Do file. Be sure you know how to run these commands from the Do file. Comment out the query memory command; we won’t need it anymore. 2.8 Basic command syntax Most Stata commands which operate on variables (as opposed to system commands such as version, update, query, etc.) follow the same general format. Recognizing this format will make it easier to understand new commands to which you are introduced. The basic syntax is command &lt;variable(s)&gt;, &lt;options&gt; The command can take on more than one word; e.g. to create a scatter plot, the command is graph twoway scatter. Depending on the command, the list of variables can contain 0 variables, 1 variable, or many variables separated by spaces. Whether the order of variables matters depends on the specific command. Above, in the do-file, we ran three lines of code. The first, sysuse auto, is a system command that we’ll discuss later. The second and third lines, summarize price mpg and tabulate foreign, follow the basic syntax - “summarize” and “tabulate” are the commands. “summarize” is operating on two variables, “price” and “mpg”; the order in which the variables appear in the command controls the order in which they appear in the table. “tabulate” is operating on a single variable, creating a one-way table; putting a second variable transforms it into a two-way table. The options are not required (none of the above commands have options), but if they are given, they too are separated by spaces. There are some options that are consistent across a number of commands, and some options are specific to commands. 2.9 Stata Help Stata has, hands down, the best built-in help files of any of the “Big 4” statistical software.3 Stata’s help should be your first stop for any of the following: Understanding the syntax of a command Exploring the options available for a given command Looking at examples of the command in use Understanding the theoretical statistics behind the command. Help can be accessed by calling help &lt;command&gt;, such as help summarize Each help page has numerous features, I will merely point out a few here. The “Title” section contains a link (in blue) to a PDF which contains the Manual, which has more detail and examples than the help file alone. The syntax section shows the basic syntax. Any part written in square brackets ([…]) are optional. The examples in the help are great but basic; the PDF help (see #1) usually has more detailed examples. We will discuss the “Stored results” in the [Programming][programming] section. help can also be used to search for the appropriate command. For example, if you wanted help merging some data together (which we will cover later), you might try running help merging merging is not a valid Stata command, so instead Stata performs a search of the help files. This search is often not great. I would recommend searching online for the appropriate command to use (just search “Stata” and what you are trying to do), then using the built-in help for details on using the command. Finally, help help works and brings up some more information on the help command. 2.9.1 Short commands You’ll frequently see commands with partial underlining; for example summarize has the “su” underlined. Only the underlined part needs to be given for Stata to understand the command; e.g. the following are all equivalent: summarize summ su This is often true for options as well; detail (to report far more summary details) has the “d” underlined. So these are equivalent: summarize, detail su, detail summarize, d su, d The short commands are very useful for quickly writing commands, but not so great at reading them. If you came across someone else’s Stata Do-file and saw su, d, you might have trouble figuring that out unless you already knew that short command. Thankfully, the short commands can be used with help, so help su will bring up the full summarize documentation. 2.10 Working directory We mentioned earlier the notion of a “working directory”, the current one you can see in the bottom left of the Stata window. You can think of a working directory as an open folder inside Windows Explorer (or Finder if you’re on a Mac). You can easily access any file within that folder without any additional trouble. You can access files in other folders (directories), but it requires moving to that folder. In the same sense, when referring to files, any file in the working directory can be referred to buy its name. For example, to open a file (we’ll go into detail about doing this later) named “mydata.dta” which is in your current working directory, you need only enter use mydata.dta (Technically you could just run use mydata as Stata will search for a file with the appropriate “.dta” extension automatically.) If you were in a different working directory, you need to specify the full path to the file: use C:\\Documents\\Stata\\Project\\mydata.dta Similarly, when saving files, the working directory is the default choice. The working directory can be viewed with the pwd command (Print Working Directory) . pwd C:\\Documents You can change the working directory by passing a path to cd (Change Directory): cd C:\\Documents\\Stata\\Project Alternatively and perhaps more easily, you can change the working directory by the menus, choosing “Files -&gt; Change working directory”. After selecting the appropriate directory, the full cd command will be printed in the Results, so you can save it in a Do-file for later use. 2.10.1 File paths There are some distinctions between Windows and Mac in regards to file paths, the most blatant that Windows uses forward slash (\\) whereas Mac uses back slashes (/). You can see full details of this by running help filename. Stata can handle commands that are prefaced by . (with a space between the period and comand) so you can copy/paste the . version and run it as is. However, don’t get used to that habit! The correct command is just version.↩︎ As we’ll see in a bit, you can save Stata commands in a “do-file”. While I’ve never seen an official definition, I tend to think of “ado” as “automatic do”.↩︎ I consider the “Big 4” as Stata, SAS, SPSS, and R. SPSS has terrible help; SAS’s is good but dense and difficult to navigate if you don’t already know what you’re looking for; R’s is very hit-or-miss depending on who wrote it.↩︎ "],["working-with-data-sets.html", "Chapter 3 Working with Data Sets 3.1 Built-in data 3.2 Opening data 3.3 Editing data manually 3.4 Saving data 3.5 Importing data 3.6 Switching between data sets 3.7 Exercise 1", " Chapter 3 Working with Data Sets 3.1 Built-in data Before we turn to using your own data, it is useful to know that Stata comes with a collection of sample data sets which you can use to try the Stata commands. Additionally, most (if not all) of the examples in Stata help will use these data sets. To see a list of the built-in data sets, use . sysuse dir auto.dta census.dta network1a.dta tsline1.dta auto16.dta citytemp.dta nlsw88.dta tsline2.dta auto2.dta citytemp4.dta nlswide1.dta uslifeexp.dta autornd.dta educ99gdp.dta pop2000.dta uslifeexp2.dta bplong.dta gnp96.dta sandstone.dta voter.dta bpwide.dta lifeexp.dta sp500.dta xtline1.dta cancer.dta network1.dta surface.dta and use sysuse again to load data, for example the auto data which contains characteristics of various cars from a 1978 Consumer’s Report magazine. . sysuse auto (1978 automobile data) If you make any modifications to your data, Stata will try and protect you by refusing to load a new data set which would dispose of your changes. If you are willing to dispose of your changes, you can either manually do it by calling clear or passing it as an option to sysuse, . sysuse auto, clear (1978 automobile data) 3.1.1 Stata Website Data In addition to the data sets distributed with Stata, Stata also makes available a large collection of data sets on their website which can be accessed with the webuse command. These data sets are used as examples in the Manual and can be seen listed as http://www.stata-press.com/data/r17/. webuse hiway webuse supports the clear option as well. The exercises in this workshop will be using mostly built-in data sets as it makes distribution easy! 3.2 Opening data As you may have deduced from the sysuse and webuse commands above, the command to load local data is use: use &lt;filename&gt; As discussed in the working directory section, Stata can see only files in its working directory, so only the name of the file needs to be passed. If the file exists in a different directory, you will need to give the full (or relative path). For example, if your working directory is “C:\\Documents\\Stata” and the file you are looking for, “mydata”, is in the “Project” subfolder, you could open it with any of the following: use C:\\Documents\\Stata\\Project\\mydata use Project\\mydata cd Project use mydata Note that if the path (or file name) contains any spaces, you need to wrap the entire thing in quotes: use &quot;C:\\Documents\\Stata\\My Project\\My Data&quot; It is never wrong to use quotes (just not always required), so perhaps that’s a safer option. If the location of your file is much different than your working directory, it can be quicker just to use the menu “File -&gt; Open” and use the file open dialog box instead. As with all commands, the use command will be echoed in the Results after using the dialog box, allowing you to add it to a Do-file. As with sysuse and webuse, the clear option discards the existing data regardless of unsaved changes. 3.2.1 Loading subsets of the data You can load only a subset of the data into the program at a time. Generally I would recommend loading the full data and then discarding the extraneous information. However, if your data is very large, it might be handy to only load in some of it rather than the entire thing. As this is a lesser-used option we won’t go into too much detail, but as an example, if I wanted to load only the variables named “bp”, “heartrate” and “date” from the data set “patientdata”, restricted to male patients, I might use something like use bp heartrate date if gender == &quot;male&quot; using patientdata Here, using and if are subcommands, which we will see used more as the day goes on. The statement gender == \"male\" is a conditional statement which only loads male patients. We’ll discuss later about conditional statements. Alternatively, if you have a very large data set, you can load in a small chunk of it. use patientdata in 1/100 This loads just the first 100 rows (a/b is a “numlist” counting from “a” to “b” by integers). For further details, see help use, specifically the manual which has the full documentation. 3.3 Editing data manually We will discuss in Data Manipulation how to edit your data on a larger scale and in an automated fashion, but Stata does support modifying a spreadsheet of your data similar to Excel. At the top of the main window, you’ll see two buttons, “Data Editor” and “Data Browser”. These open the same new Data window, the only difference is that Stata is protecting you from yourself and if you open the “Data Browser” (or switch to it in the Data window), you cannot modify the data. Once in the Data window, you can select cells and edit them as desired. Note that whenever you make a modification in the Data Editor, there is a corresponding command produced which actually performs the modification. . replace age = 27 in 11 (1 real change made) 3.3.1 Colors as variable type When viewing the data, the color of each column’s text provides information about the type of variable. We’ll go into more details later what these types mean. Below, for the auto data, you can see the make variable is red, indicating a string, the foreign variable is blue indicating a variable with an attached value label and the remainder of the variables are black for numeric. 3.4 Saving data Saving data is done with the save command. There are two variations of running. save, replace In this first variation, by not giving a file name and passing the replace option, Stata will overwrite whichever file you loaded with use. (It will error if you loaded a file via sysuse or webuse.) The second variation takes a file name: save newfile save newfile, replace Here, save will save a copy named “newfile.dta” in the working directory. You can pass it a full path just like with use to refer to a location outside of the working directory. By default, save will not overwrite existing files, but can be overwritten with the replace option. As before, wrap the file name in quotes if it (or the path) includes any spaces. Prior to Stata 14, the save format was different. If you need to save a data set in the older format (perhaps to pass to a collaborator who is woefully behind the times), check help saveold. 3.5 Importing data The need often arises to import data from another format (such as Excel or SPSS). Stata has a suite of very useful commands for importing data sets having other formats. To see the types of data that Stata can import, select “File -&gt; Import”. While there are commands to do the importing (such as import excel file.xlsx), the dialog boxes for importation provide a preview of the imported data, making it easier to ensure that the importation will go smoothly. Just as with editing the data, after performing an import with the dialog box, the corresponding command is executed in the results window and can be copied in a Do-file for reproducibility. 3.5.1 Importing Excel data Data stored in Excel can be ported into Stata easily. To make your life easier, make sure the data adheres to these general principals. While technically none of these are “required”, ignoring them will lead to a lot more work down the road! Remove extraneous information (plots, notes, data dictionaries, summary statistics). Remove “fancy” formatting - merged cells, empty rows/columns. Ensure each column is of one “type” - if the column is supposed to be numbers, don’t include any words! Make missing values blank (unless you are interested in types of missingness, in which case be sure to have a coherent coding scheme). Once you have cleaned your data, you can choose “File -&gt; Import -&gt; Excel Spreadsheet (.xls, .xlsx)”. The next dialog allows you to tweak the options. Important options include Worksheet: Make sure you are importing the correct sheet! Cell range: If you have extraneous information in your spreadsheet, you can exclude it here. (Though in my experience it is better to remove the extraneous data from Excel, as its easy to forget something here!) Import first row as variable names: In Excel, it is common to have the first row being the variable names with the second row starting the data. In Stata, the variable names have their own special field, so only data should exist in the data. Check this to ensure the variables are properly named. Import all data as strings: It should rarely be useful to use this. Stata reads all the data and tries to predict whether each column represents a number or a string. To do so, it goes through some logic. Is anything in the column non-numeric? If yes, it is a String. If no, continue. Is anything in the column formatted as a Date or Time? If yes, it is a Date or Time. If no, continue. It is a number. If Stata makes mistakes here (usually because the data is formatted oddly), things can go wrong. The last option, “Import all data as strings” can be used to force Stata to treat everything as a string so that it reads in the data exactly as stored in the Excel sheet so that you can clean it up later. Note that cleaning this up is usually more complicated then just fixing the Excel sheet first! (Note also that for larger data, this scan can be slow!) Once the preview looks accurate, go ahead and import. As usual, this will create an import excel command in the Results that you can save for the future in a Do-file, but using save to create a Stata data set to load in later is probably a better option. 3.5.2 Importing a CSV File CSV files (comma separated values) are a very useful format for passing data between software. Files specific for software (e.g. .dta for Stata, .xlsx for Excel, .sav for SPSS) carry a lot of overhead information - very useful when working exclusively within that software, but confusing for other software. The import menu in Stata (and other software) can often address this, but a CSV file bypasses this. Data in CSV format might look like id,salary,exprior,market,admin,yearsdg,rank,male 1,38361.75,0,.72,0,14,2,0 2,68906,2,1,,31,3,1 The first row is the variable names, all separated by commas. The 2nd row starts the data, where each variable is again separated by commas. Multiple commas in a row indicate a missing value. The downside of CSV files is we lose any auxiliary information, such as descriptive titles, labels etc. Often, if you are obtaining CSV files from an online resource, they will provide a Do-file alongside the data that reads in the CSV file and applies labels, titles, etc. If not you’ll have to do this yourself! A CSV files can be imported using “File -&gt; Import -&gt; Text Data (delimited, *.csv, …)” Important options include: Delimiter - There are other _SV types of files, such as tab or white space. Generally you can leave this at Automatic, but may need to be precise if your data has a lot of strings in it. Treat sequential delimiters as one - If you have missing data, it will appear as 5,4,,2,1. If this option is not selected, Stata will recognize the missing third entry. On the other hand, if your deliminator is white space, you may have data like 3 1 2 5. If you want that to be four variables instead of a bunch of other missing entries, select this option. Use first row for variable names - Same as the Excel version. 3.5.3 Importing from a file not supported directly by Stata If you have data in a format not supported by Stata, there are three options: First, try opening the the data in a word processor and see if it is delimited instead of more complicated (e.g. a CSV file with a different file extension). This is a long shot, but the easiest! If you open it in something like Word, make sure you don’t save it in .doc format! Instead, rename the file “.txt” or “.csv” and try importing it as that. Second, see if the software which created the data can write it into Stata (.dta) format. Some software such as R supports this, though some software (such as SPSS) only supports writing to older versions of Stata. You can still try this, though be sure to double check that nothing went wrong, and re-save your data (which saves it as the new save format). Finally, see if you can open the data in the other software and export it into CSV or a similar common format. If all else fails, there is software Stat Transfer, https://www.stattransfer.com, which can transfer between all sorts of formats with a click, but is not free. Your department or organization may offer access to it. 3.6 Switching between data sets Here we’ll discuss two ways to switch between data sets. Later we’ll discuss the third way to work with multiple data sets, merging. 3.6.1 Temporarily preserving and restoring data Say you want to carry out a destructive operation on your data, temporarily. This could be either to close your data and load another, or to make a change to the current data.For example, say you want to remove some subset of your observations. One workflow to use would be: sysuse auto &lt;modify data set as desired&gt; save tmp &lt;subset data&gt; &lt;obtain results&gt; use tmp, clear &lt;delete the tmp file manually&gt; Alternatively, the preserve and restore commands perform the same set of operations in a more automated fashion: sysuse auto &lt;modify data set as desired&gt; preserve &lt;subset data&gt; &lt;obtain results&gt; restore The preserve command saves an image of the data as they are now, and the restore command reloads the image of the data, discarding any interim changes. There can only be a single image of the data preserved at a time, so if you preserve, then make a change and want to preserve again (without an intervening restore), you can pass the option not to restore to discard the preserved image of the data. restore, not One thing to note about the use of preserve and restore in Do-files: If you run a chunk of commands which include a preserve statement, after the code executes restore is automatically run even if restore was not in the set of commands you ran! 3.6.2 Frames Starting in Stata 16, Stata can load multiple data sets into different “frames”, though you still work with a single data set at a time. Each frame has a name; when you first open Stata the frame you start with is named “default”. . frame (current frame is default) The “default” frame is nothing special; it’s simply the name when you open a fresh version of Stata. You can create a new frame via frame create, . frame create newframe and move between frames via frame change or cwf. . cwf newframe . frame (current frame is newframe) . cwf default If we look at all frames with frame dir, . frame dir default 74 x 12; 1978 automobile data newframe 0 x 0 we can see that the default frame has the most recent data we loaded, the auto data. We could switch to the newframe and load a separate data set if we wanted. . cwf newframe . sysuse bplong (Fictional blood-pressure data) . frame dir default 74 x 12; 1978 automobile data newframe 240 x 5; Fictional blood-pressure data Note that commands operate on our current frame, so calling describe will describe “bplong” since we’re still in newframe. . describe, short Contains data from /Applications/Stata/ado/base/b/bplong.dta Observations: 240 Fictional blood-pressure data Variables: 5 1 May 2020 11:28 Sorted by: patient We can run commands on the other frame either by changing to that frame with cwf, or by using the frame ___: prefix: . frame default: describe, short Contains data from /Applications/Stata/ado/base/a/auto.dta Observations: 74 1978 automobile data Variables: 12 13 Apr 2020 17:45 Sorted by: foreign 3.6.2.1 Dropping frames When you load a data set, it gets loaded into your computer’s memory. If you keep creating new frames and loading data, you can very quickly run out of memory! Use frame drop to dispose of old frames. . frame dir default 74 x 12; 1978 automobile data newframe 240 x 5; Fictional blood-pressure data . frame drop default . frame dir newframe 240 x 5; Fictional blood-pressure data 3.6.2.2 Copying data into frames Often you may want to create a collapse’d or otherwise modified version of your current data. You can use frame copy to create a duplicate which you can then destroy. . frame copy newframe newframe2 . frame newframe2: collapse (mean) bp, by(patient) . frame dir newframe 240 x 5; Fictional blood-pressure data * newframe2 120 x 2; Fictional blood-pressure data Note: Frames marked with * contain unsaved data. Note that you cannot copy into an existing frame; you must either delete the old frame or copy into a new name. 3.6.2.3 Linking data sets We’re not going to go into it now, but please see the section in the Programming &amp; Advanced Features section for details. You can link data sets between frames to either enable moving variables across frames, or if the data are at different units of analysis (e.g. a patient file and a clinic file), to easily merge the files together. 3.7 Exercise 1 Load the built-in data set “lifeexp”. Open the Data Editor window. Modify at least one of the cells. Close the Data window. Load the built-in data set “sandstone”. Don’t forget to clear or pass the clear option. Save a copy of this data to your computer. Check your working directory. Make sure it is set somewhere convenient. Use save. Make sure to give it a name! If you haven’t already, play with preserve and restore. Preserve the data, modify some values, then observe what happens when you restore. "],["data-management.html", "Chapter 4 Data Management 4.1 Referring to variables 4.2 Describing the data 4.3 Compressing data 4.4 Exercise 2 4.5 Labels 4.6 Managing variables 4.7 Exercise 3 4.8 Summarizing the data 4.9 Exercise 4", " Chapter 4 Data Management Throughout this chapter, we’ll be using the “auto” data set which is distributed with Stata. It can be loaded via . sysuse auto (1978 automobile data) You can reload it as necessary (if you modify it and want the original) by re-running this with the clear option. Feel free to make frequent use of preserve and restore. Whenever you first begin working with a data set, you’ll want to spend some time getting familiar with it. You should be able to answer the following questions (even if some of them are approximations): How many observations does your data have? How many variables are in your data set? What is the unit of analysis? (What does each row represent - a person? a couple? a classroom?) Is there a variable which uniquely identifies each unit of analysis? If the data is repeated measures in some form (multiple rows per person, or data is students across several classrooms), what variable(s) identify the levels and groups? Are there any variables which are strings (non-numeric) that you plan on using in some statistical analysis (and will need to be converted to numeric)? Which variables are continuous (can take on any value in some reasonable range, such as weight) vs which are categorical (take on a set number of values where each represents something). You’ll notice that there are no statistical questions here - we’re not even worried about those yet! These are merely logistical. In this chapter we’ll go over various tools and commands you can use to answer these questions (and more) and overall to gain a familiarity with the logistics of your data. 4.1 Referring to variables When we discussed basic command syntax, we said that the optional list of variables can include any number of variables (for some commands). Writing out all the variables can get very tedious as the number of variables increases. Thankfully there are two alternatives. First, we can use the wild card *4. For example, we could refer to the variables “turn” and “trunk” as t*, as both variables start with “t” and are followed by anything. However, be careful, as this would also match variables such as turnips, tprice, t, etc, if any such variables existed. It can also be used in the middle or beginning, e.g.: c*t would match cat, caught and ct *2 would match age2, gender2 and salary2012. Alternatively, if the variables we want to include are next to each other in the data (e.g. in the Variables pane), we can refer to a list of them. Say the variables x1 through x25 are in ordered in the logical fashion. We could refer to the whole list of them as x1-x25. This includes both x1 and x25, as well as any variable in between them. We will discuss the order command later to re-order variables. Finally, you often don’t need to give the entire name of the variable, just enough characters for Stata to be able to uniquely identify it (similar to short names). We’ll see in a minute more about the describe command, but for example, . describe headr Variable Storage Display Value name type format label Variable label ------------------------------------------------------------------------------- headroom float %6.1f Headroom (in.) Stata will error if you don’t use enough characters: . describe t t ambiguous abbreviation r(111); Be very careful with this approach. I only recommend it’s use when exploring the data using the Command window; when writing a Do-file, use the full variable name to prevent errors! 4.2 Describing the data The first command you should run is describe. . describe Contains data from /Applications/Stata/ado/base/a/auto.dta Observations: 74 1978 automobile data Variables: 12 13 Apr 2020 17:45 (_dta has notes) ------------------------------------------------------------------------------- Variable Storage Display Value name type format label Variable label ------------------------------------------------------------------------------- make str18 %-18s Make and model price int %8.0gc Price mpg int %8.0g Mileage (mpg) rep78 int %8.0g Repair record 1978 headroom float %6.1f Headroom (in.) trunk int %8.0g Trunk space (cu. ft.) weight int %8.0gc Weight (lbs.) length int %8.0g Length (in.) turn int %8.0g Turn circle (ft.) displacement int %8.0g Displacement (cu. in.) gear_ratio float %6.2f Gear ratio foreign byte %8.0g origin Car origin ------------------------------------------------------------------------------- Sorted by: foreign This displays a large amount of information, so let’s break in down. First, the header displays general data set information - the number of observations (obs, the number of rows) and variables (vars). Next, there is a table listing each variable in the data and some information about them. The “storage type” can be one of byte, int, long, float, double; all of which are simply numbers. We’ll touch on the differences between these when we discuss compress, but for now they all represent numeric variables. String variables are represented as str## where the ## represent the number of characters that the string can be, e.g. str18 shows that make has a maximum of 18 letters. (This limit is irrelevant, again, see compress for details.) The “display format” column contains format information about each variable which only control how the variables are displayed in data view. For the most part you can ignore these and leave them at the default, though you may need to work with this if you have date or time information. For further details see help formats “value label” and “variable label” are used to display more information when running analyses using these variables. See the label section for further details. Finally, if the data is sorted, describe will provide information about the sorting. describe can also be used on a per variable basis: . describe mpg Variable Storage Display Value name type format label Variable label ------------------------------------------------------------------------------- mpg int %8.0g Mileage (mpg) . describe trunk displacement Variable Storage Display Value name type format label Variable label ------------------------------------------------------------------------------- trunk int %8.0g Trunk space (cu. ft.) displacement int %8.0g Displacement (cu. in.) If you have a very large number of variables you may wish to suppress the table of variables entirely: . describe, short Contains data from /Applications/Stata/ado/base/a/auto.dta Observations: 74 1978 automobile data Variables: 12 13 Apr 2020 17:45 Sorted by: foreign Alternatively, the simple option returns only the names of the variables, in column-dominant order (meaning you read down the columns not across the rows). . describe, simple make rep78 weight displacement price headroom length gear_ratio mpg trunk turn foreign 4.3 Compressing data As mentioned above, there are different ways to store a number variable, such as byte and long. The various options take more space to save - types which take less space can store only smaller numbers whereas types that take more space can store larger numbers. For example, a number stored as a byte can only take on values between -127 and 100 and only integers (e.g. not 2.5) whereas a number stored as float can store numbers up to (1.7x10^38) with up to 38 decimal places. Strings operate similarly; a string variable with 20 characters would store “abc” as 17 blank characters followed by the “abc”. Understanding the above is not that important these days as computer power and storage has increased to the point where the majority of us will not be reaching its limits. However, Stata does offer the compress command which attempts to store variables in the smallest possible type. For example, if a variable which is a float takes on only values 1 through 10, it is replaced by a byte (and similarly, strings are as long as the longest value). The memory command lets us see the size of our data, particularlly the first entry of “Data” under “Used” shows that we start with 3,182 bytes or roughly 3Kb. . memory Memory usage Used Allocated ---------------------------------------------------------------------- Data 3,182 67,108,864 strLs 0 0 ---------------------------------------------------------------------- Data &amp; strLs 3,182 67,108,864 ---------------------------------------------------------------------- Data &amp; strLs 3,182 67,108,864 Variable names, %fmts, ... 4,178 68,030 Overhead 1,081,344 1,082,136 Stata matrices 0 0 ado-files 23,088 23,088 Stored results 0 0 Mata matrices 1,904 1,904 Mata functions 2,448 2,448 set maxvar usage 4,636,521 4,636,521 Other 19,009 19,009 ---------------------------------------------------------------------- Total 5,753,230 72,942,000 . compress variable mpg was int now byte variable rep78 was int now byte variable trunk was int now byte variable turn was int now byte variable make was str18 now str17 (370 bytes saved) . memory Memory usage Used Allocated ---------------------------------------------------------------------- Data 2,812 67,108,864 strLs 0 0 ---------------------------------------------------------------------- Data &amp; strLs 2,812 67,108,864 ---------------------------------------------------------------------- Data &amp; strLs 2,812 67,108,864 Variable names, %fmts, ... 4,178 68,030 Overhead 1,081,344 1,082,136 Stata matrices 0 0 ado-files 23,088 23,088 Stored results 0 0 Mata matrices 1,904 1,904 Mata functions 2,448 2,448 set maxvar usage 4,636,521 4,636,521 Other 19,009 19,009 ---------------------------------------------------------------------- Total 5,752,860 72,942,000 We see here a very modest saving (370 bytes, about 12%), but sometimes you can see much more significant gains. (When running Stata, instead of using memory, you can look at the “Size” entry in the properties pane.) Don’t be afraid of artificially restricting yourself going forward; if one of your values exceeds the limitations its type supports, Stata will automatically change types. So don’t hesitate to run compress when loading new data or after some manipulations. 4.4 Exercise 2 “census9” is accesible via webuse. Load it. Spend a minute looking at the data. What does this data seem to represent? What variables do we have? (describe will come in handy here!) Are there any missing states? What variables (if any) are numeric and what variables (if any) are strings? Compress the data. How much space is saved? Why do you think this is? 4.5 Labels A raw data set is very sparse on context. In addition to the data itself, it will have at most a variable name, which in Stata cannot include spaces and is limited to 32 characters. All other context associated with the data must either be documented in a data dictionary or exist in the recollection of the analyst. In an Excel file, to get around this, you might add additional content to the sheet outside of the raw data - a note here, a subtitle there, etc. However, Stata does not allow such arbitrary storage. In contrast, Stata allows you to directly label parts of the data with context information which will be displayed in the appropriate Results, to make Stata output much easier to read as well as removing the need for an external data dictionary. 4.5.1 Labeling variables Variables names, as mentioned, are limited to 32 characters and do not allow spaces (or several other special characters). This is to encourage you to choose short, simple, and memorable variable names, since you’ll likely be typing them a lot! We can easily add more information with a variable label. If you look at the describe output, you’ll notice that the auto data set already has variable labels applied to it. . describe Contains data from /Applications/Stata/ado/base/a/auto.dta Observations: 74 1978 automobile data Variables: 12 13 Apr 2020 17:45 (_dta has notes) ------------------------------------------------------------------------------- Variable Storage Display Value name type format label Variable label ------------------------------------------------------------------------------- make str17 %-17s Make and model price int %8.0gc Price mpg byte %8.0g Mileage (mpg) rep78 byte %8.0g Repair record 1978 headroom float %6.1f Headroom (in.) trunk byte %8.0g Trunk space (cu. ft.) weight int %8.0gc Weight (lbs.) length int %8.0g Length (in.) turn byte %8.0g Turn circle (ft.) displacement int %8.0g Displacement (cu. in.) gear_ratio float %6.2f Gear ratio foreign byte %8.0g origin Car origin ------------------------------------------------------------------------------- Sorted by: foreign Note: Dataset has changed since last saved. We can see variable rep78 (an utterly incomprehensible name at first glance, as opposed to mpg) has the label “Repair Record 1978”. You can apply your own variable labels (or overwrite existing by using the command: label variable &lt;variable name&gt; &quot;Variable label&quot; For example: . label variable turn &quot;Some new label for turn&quot; . describe turn Variable Storage Display Value name type format label Variable label ------------------------------------------------------------------------------- turn byte %8.0g Some new label for turn To remove a variable label, you can call label variable &lt;varname&gt; without a new label to remove the existing one. (Equivalent to label variable &lt;varname&gt; \"\", so passing an empty variable label.) . label variable turn . describe turn Variable Storage Display Value name type format label Variable label ------------------------------------------------------------------------------- turn byte %8.0g 4.5.2 Labeling values It is tempting to store categorical variables as strings. If you ask, for example, for someone’s state of residence, you might store the answers as “MI”, “OH”, “FL”, etc. However, Stata (like most statistical software) cannot handle string variables.5 A much better way to store this data would be to assign each state a numerical value, say MI = 1, OH = 2, FL = 3, etc, then keep a data dictionary linking the values to the labels they represent. Stata allows you to store this value labels information within the data set, such that whenever the values are output, the labels are printed instead. Let’s take a look at the foreign variable. This variable takes on two levels, and we can tabulate it to see how many cars are in each category. . tabulate foreign Car origin | Freq. Percent Cum. ------------+----------------------------------- Domestic | 52 70.27 70.27 Foreign | 22 29.73 100.00 ------------+----------------------------------- Total | 74 100.00 Here it appears that foreign is stored as two strings, but we know from describe that it is not: . describe foreign Variable Storage Display Value name type format label Variable label ------------------------------------------------------------------------------- foreign byte %8.0g origin Car origin Additionally, if you look at the data through Data Editor or Data Browser, you see that instead of foreign being red (as a string) it is blue, as we discussed earlier. Let’s look at that table ignoring the value labels: . tabulate foreign, nolabel Car origin | Freq. Percent Cum. ------------+----------------------------------- 0 | 52 70.27 70.27 1 | 22 29.73 100.00 ------------+----------------------------------- Total | 74 100.00 Now we see the values which are actually stored. Look at the describe output: . describe foreign Variable Storage Display Value name type format label Variable label ------------------------------------------------------------------------------- foreign byte %8.0g origin Car origin You’ll notice that the “value label” column has origin attached to foreign. In Stata, the value labels information are stored separately from the variables. They are two separate components - there is a variable and there is a value label. You connect the value label to a variable to use it. The benefit of this separated structure is that if you have several variables which have the same coding scheme (e.g. a series of Likert scale questions, where 1-5 represents “Strongly Disagree”-“Strongly Agree”), you can create a single value label and rapidly apply it to all variables necessary. Correspondingly, this process requires two commands. First we define the value labels: label define &lt;label name&gt; &lt;value&gt; &quot;&lt;label&gt;&quot; &lt;value&gt; &quot;&lt;label&gt;&quot; ..... For example, if we wanted to recreate the value label associated with foreign: . label define foreign_label 0 &quot;Domestic&quot; 1 &quot;Foreign&quot; Value labels exist in the data set, regardless of whether they are attached to any variables, we can see all value labels: . label list foreign_label: 0 Domestic 1 Foreign origin: 0 Domestic 1 Foreign Here we see the original origin as well as our new foreign_label. To attach it to the variable foreign: . label values foreign foreign_label If we wanted to attach a single value label to multiple variables, we could simply provide a list of variables: label values &lt;var1&gt; &lt;var2&gt; &lt;var3&gt; &lt;label&gt; To remove the value labels from a variable, use the label values &lt;variable&gt; command with no label name following the variable name: . label values foreign . describe foreign Variable Storage Display Value name type format label Variable label ------------------------------------------------------------------------------- foreign byte %8.0g Car origin You can view all value labels in the data set: . label list foreign_label: 0 Domestic 1 Foreign origin: 0 Domestic 1 Foreign Note that value labels exist within a data set regardless of whether they are attached to a variable. If there is a label value that you no longer want to keep in the data-set, you can drop it: . label drop foreign_label . label list origin: 0 Domestic 1 Foreign This will not remove the value labels from any variables, but they will no longer be active (i.e. if you run describe it will still show that the value labels are attached, but running tabulate will not use them). So in order to completely remove a value label, you’ll need to both remove it from the variable as well as the data. Do not forget that modifying value labels counts as modifying the data. Make sure you save, replace after making these modifications (if you want to keep them) or they’ll be lost! 4.6 Managing variables In Stata, managing the names and order of variables is important to make entering commands easier due to the shortcuts for referring to variables. Recall that variables can be referred to using wildcards (e.g. a* to include age, address or a10, or using var1-var10 to include all variables between var1 and var10 as they are ordered). Of course, you may also want to rename or re-order variables for other reasons such as making the data easier to look at. 4.6.1 Renaming variables To rename variables: rename &lt;oldname&gt; &lt;newname&gt; For example: . rename rep78 repair_record_1978 . describe, simple make repair_~1978 weight displacement price headroom length gear_ratio mpg trunk turn foreign The output truncated the name because it was so long. Variable names are unique; if you wanted to swap to variable names, you’d have to name one to a temporary name, rename the second, then rename the first again: rename a tmp rename b a rename tmp b You can use wildcards in the renaming too. For example, imagine you had a collection of variables from a longitudinal data set, “visit1_age”, “visit1_weight”, “visit1_height”, etc. To simplify variable names, we’d prefer to use “age1”, “weight1”, etc. rename visit1_* *1 Finally, you can change a variable name to upper/lower/proper case easily by passing upper/lower/proper as an argument and giving no new variable name. . rename length, upper . describe, simple make repair_~1978 weight displacement price headroom LENGTH gear_ratio mpg trunk turn foreign You can also do this for the whole data set with the special variable list _all . rename _all, upper . describe, simple MAKE REPAIR_~1978 WEIGHT DISPLACEMENT PRICE HEADROOM LENGTH GEAR_RATIO MPG TRUNK TURN FOREIGN . rename _all, lower 4.6.2 Changing variable ordering The order command takes a list of variables and moves them to the front/end/before a certain variable/after a certain variable. The options first, last, before(&lt;variable&gt;) and after(&lt;variable&gt;) control this. . order foreign // The default is `first` . describe, simple foreign mpg trunk turn make repair_~1978 weight displacement price headroom length gear_ratio . order weight, last . describe, simple foreign mpg trunk displacement make repair_~1978 length gear_ratio price headroom turn weight . order mpg trunk, before(displacement) . describe, simple foreign repair_~1978 turn displacement make headroom mpg gear_ratio price length trunk weight 4.7 Exercise 3 If you’ve changed to a different data set, load “census9” back up with webuse. Going forward, we’ll be using a version of “census9” with changes we’re making. Save a copy of the data to somewhere convenient (such as your Desktop). Don’t forget to give it a name! The drate variable is a bit vague - the name of the variable provides no clue that “d” = “death”, and the values (e.g. 75) are ambiguous. Rename drate to deathrate. The rate is actually per 10,000 individuals. Label dearthrate to include this information. The variable region has a value label associated with it (“cenreg”). It has some inconsistent choices, namely “NE” and “N Cntrl”. Fix this. Create a new value label which uses “Northeast” and “North Central” instead of “NE” and “N Cntrl”. Attach this new value label to region. Remove the existing value label “cenreg”. Use label list and tabulate to confirm it worked. Save the data, replacing the version you created in step 1. 4.8 Summarizing the data While these notes will not cover anything statistical, it can be handy from a data management perspective to look at some summary statistics, mostly to identify problematic variables. Among other things, we can try and detect Unexpectedly missing data Incorrectly coded data Errors/typos in input data Incorrect assumptions about variable values There are numerous ways to look at summary statistics, from obtaining one-number summaries to visualizations, but we will focus on two Stata commands, summarize and codebook. summarize produces basic summary statistics for numeric variables. . summarize Variable | Obs Mean Std. dev. Min Max -------------+--------------------------------------------------------- foreign | 74 .2972973 .4601885 0 1 make | 0 price | 74 6165.257 2949.496 3291 15906 repair_~1978 | 69 3.405797 .9899323 1 5 headroom | 74 2.993243 .8459948 1.5 5 -------------+--------------------------------------------------------- length | 74 187.9324 22.26634 142 233 turn | 74 39.64865 4.399354 31 51 mpg | 74 21.2973 5.785503 12 41 trunk | 74 13.75676 4.277404 5 23 displacement | 74 197.2973 91.83722 79 425 -------------+--------------------------------------------------------- gear_ratio | 74 3.014865 .4562871 2.19 3.89 weight | 74 3019.459 777.1936 1760 4840 The table reports the total number of non-missing values (make appears to be entirely missing because it is non-numeric), the mean (the average value), the standard deviation (a measure of how spread out the data is) and the minimum and maximum non-missing6 values observed. Here’s some suggestions of how to look at these values. Make sure the amount of missing data is expected. If the number of observations is lower than anticipated, is it an issue with the data collection? Or did the import into Stata cause issues? 5 cars have no repair_record_1978. The mean should be a reasonable number, somewhere in the rough middle of the range of possible values for the variable. If you have age recorded for a random selection of adults and the mean age is 18, something has gone wrong. If the mean age is -18, something has gone tragically wrong! The standard deviation is hard to interpret precisely, but in a very rough sense, 2/3rds of the values should lie within 1 standard deviation of the mean. For example, consider mpg. The mean is ~21 and the standard deviation is ~6, so roughly 2/3rds of the cars have mpg between 15 and 27. Does this seems reasonable? If the standard deviation is very high compared to the mean (e.g. if mpg’s standard deviation was 50) or close to 0, that could indicate an issue. Are the max and min reasonable? If the minimum LENGTH was -9, that’s problematic. Maybe -9 is the code for missing values? If the range of LENGTH is 14 to 2500, maybe the units differ? They measured in feet for some cars and inches for others? summarize can also take a list of variables, e.g. . summarize t* Variable | Obs Mean Std. dev. Min Max -------------+--------------------------------------------------------- turn | 74 39.64865 4.399354 31 51 trunk | 74 13.75676 4.277404 5 23 For more detailed information, we can look at the codebook. codebook works similarly to describe and summarize in the sense that without any additional arguments, it displays information on every variable; you can pass it a list of variables to only operate on those. Because codebook’s output is quite long, we only demonstrate the restricted version. Before we do that, we reload the “auto” data because we messed with it quite a bit earlier! First, categorical data: . sysuse auto, clear (1978 automobile data) . codebook rep78 ------------------------------------------------------------------------------- rep78 Repair record 1978 ------------------------------------------------------------------------------- Type: Numeric (int) Range: [1,5] Units: 1 Unique values: 5 Missing .: 5/74 Tabulation: Freq. Value 2 1 8 2 30 3 18 4 11 5 5 . We see that rep78 takes on five unique values, as well as having some missing values (.). If the unique values is more than expected, it’s something to investigate. Next, continuous variables: . codebook price ------------------------------------------------------------------------------- price Price ------------------------------------------------------------------------------- Type: Numeric (int) Range: [3291,15906] Units: 1 Unique values: 74 Missing .: 0/74 Mean: 6165.26 Std. dev.: 2949.5 Percentiles: 10% 25% 50% 75% 90% 3895 4195 5006.5 6342 11385 We still see the number of unique values reported, but here every observation has a unique value (74 unique values, 74 rows in the data). There is no missing data. The percentiles should be checked to see if they’re reasonable, if 90% of the cars had a price under $100, something’s not right. Finally, string variables: . codebook make ------------------------------------------------------------------------------- make Make and model ------------------------------------------------------------------------------- Type: String (str18), but longest is str17 Unique values: 74 Missing &quot;&quot;: 0/74 Examples: &quot;Cad. Deville&quot; &quot;Dodge Magnum&quot; &quot;Merc. XR-7&quot; &quot;Pont. Catalina&quot; Warning: Variable has embedded blanks. We get less information here, but still useful to check that the data is as expected. There are no empty strings nor any repeated strings. The warning about “embedded blanks” is spaces; it’s telling us that there are spaces in some of the cars (e.g. “Dodge Magnum”). The reason it is a warning is that “Dodge_Magnum” and “Dodge__Magnum” read the same to us, but that extra space means Stata recognizes these as two different variables. Two options for codebook which come in handy: . codebook, compact Variable Obs Unique Mean Min Max Label ------------------------------------------------------------------------------- make 74 74 . . . Make and model price 74 74 6165.257 3291 15906 Price mpg 74 21 21.2973 12 41 Mileage (mpg) rep78 69 5 3.405797 1 5 Repair record 1978 headroom 74 8 2.993243 1.5 5 Headroom (in.) trunk 74 18 13.75676 5 23 Trunk space (cu. ft.) weight 74 64 3019.459 1760 4840 Weight (lbs.) length 74 47 187.9324 142 233 Length (in.) turn 74 18 39.64865 31 51 Turn circle (ft.) displacement 74 31 197.2973 79 425 Displacement (cu. in.) gear_ratio 74 36 3.014865 2.19 3.89 Gear ratio foreign 74 2 .2972973 0 1 Car origin ------------------------------------------------------------------------------- compact shows a reduced size version, most useful for the “Unique” column. (Useful if that’s the only thing you’re running the codebook for.) . codebook, problems Potential problems in dataset /Applications/Stata/ado/base/a/auto.dta Potential problem Variables -------------------------------------------------- str# vars that may be compressed make string vars with embedded blanks make -------------------------------------------------- This reports potential issues Stata has discovered in the data. In this data, neither are really concerns. (We can run compress, but this isn’t a “problem” so much as a suggestion. We already saw above the concern about “embedded blanks.”) More serious problems that it can detect include: Constant columns (all entries being the same value, including all missing). Issues with value labels (if you’ve attached a value label to a variable and subsequently deleted the value label without detaching it; or if your variable takes on values unaccounted for in the value label). Issues with date variables. 4.9 Exercise 4 Using summarize and codebook to explore the “census9” data and answer the following questions: Are there any values which seem to be errors? I’d expect each state to have their own unique value of death rate, population and median age. Is this true? If not, why? Are there any problems with the data? This is the reason why * as a comment does not work in the middle of a line (and we use // instead).↩︎ In the few situations where it can, it doesn’t handle them cleanly.↩︎ As we discuss later, in Stata, missing values (represented by . in the data) are considered to be higher than any other number (so 99999 &lt; .).↩︎ "],["data-manipulation.html", "Chapter 5 Data Manipulation 5.1 Restricting commands to subsets 5.2 Generating new variables 5.3 Replacing existing variables 5.4 More complicated replaces 5.5 Subsetting 5.6 Dealing with duplicates 5.7 Sorting 5.8 Working with strings and categorical variables 5.9 Exercise 5 5.10 Merging Files 5.11 Reshaping Files", " Chapter 5 Data Manipulation Let’s reload the “auto” data to discard any changes made in previous sections and to start fresh. . sysuse auto, clear (1978 automobile data) 5.1 Restricting commands to subsets We’ll discuss operating on subsets of the data in far more detail a bit later, but first we’ll discuss how to modify the basic command syntax to run a command only on some rows of data. Recall the basic command syntax, command &lt;variable(s)&gt;, &lt;options&gt; By default, this will use all rows of the data it can. However, we can restrict this. command &lt;variable(s)&gt; in &lt;number list&gt;, &lt;options&gt; command &lt;variable(s)&gt; if &lt;condition&gt;, &lt;options&gt; Both are optional (obviously), but you can include them if desired. Using in, we pass a number list which consists of a lower bound, a /, and an upper bound. For example, if we wanted to summarize the first 10 rows for a variable, we could run: . summarize weight Variable | Obs Mean Std. dev. Min Max -------------+--------------------------------------------------------- weight | 74 3019.459 777.1936 1760 4840 . summarize weight in 1/10 Variable | Obs Mean Std. dev. Min Max -------------+--------------------------------------------------------- weight | 10 3271 558.3796 2230 4080 As you can see, the second call to summarize thinks there are only 10 rows of data. The if requires defining a conditional statement. Consider the following statements \\[ 4 \\gt 2 \\] \\[ 1 \\gt 2 \\] Remembering back to middle school math classes that \\(\\gt\\) means “greater than”, clearly the first statement is true and the second statement is false. We can assign values of true and false to any such conditional statements, which use the following set of conditional operators: Sign Definition True example False example \\(==\\) equality \\(3 == 3\\) \\(3 == 2\\) \\(!=\\) not equal \\(3 != 4\\) \\(3 != 3\\) \\(\\gt\\) greater than \\(4 \\gt 2\\) \\(1 \\gt 2\\) \\(\\lt\\) less than \\(1 \\lt 2\\) \\(4 \\lt 2\\) \\(\\gt=\\) greater than or equal to \\(4 \\gt= 4\\) \\(1 \\gt= 2\\) \\(\\lt=\\) less than or equal to \\(1 \\lt= 1\\) \\(4 \\lt= 2\\) &amp; and (both statements are true) \\((4 \\gt 2)\\) &amp; \\((3 == 3)\\) \\((4 \\gt 2)\\) &amp; \\((1 \\gt 2)\\) \\(|\\) or (either statement is true) \\((3 == 2) | (1 \\lt= 2)\\) \\((4 \\lt 2) | (1 \\gt 2)\\) So we could summarize a variable only when some other variables have some values. . summarize weight if foreign == 1 Variable | Obs Mean Std. dev. Min Max -------------+--------------------------------------------------------- weight | 22 2315.909 433.0035 1760 3420 . summarize weight if foreign == 1 | (mpg &gt; 20 &amp; headroom &lt; 10) Variable | Obs Mean Std. dev. Min Max -------------+--------------------------------------------------------- weight | 41 2505.122 585.291 1760 4290 Note in the second example we used parentheses to evaluate a more complex expression; we follow order of operations (remember PEMBAS?) and evaluate the inner-most parantheses first. So first mpg &gt; 20 &amp; headroom &lt; 10 gets evaluated and returns TRUE or FALSE; then following that, we evaluate either foreign == 1 | TRUE or foreign == 1 | FALSE depending on what the first result was. We saw the usage of this earlier when discussing loading subsets of the data. 5.2 Generating new variables The generate command can be used to create new variables which are functions of existing variables. For example, if we look at the variable label for weight, we see that it is measured in pounds. . describe weight Variable Storage Display Value name type format label Variable label ------------------------------------------------------------------------------- weight int %8.0gc Weight (lbs.) Let’s create a second weight variable measured in tons. The syntax for generate is straightforward, generate &lt;new varname&gt; = &lt;function of old variables&gt; . generate weight2 = weight/2000 The list command can be used to output some data, let’s use it here to output the first 5 rows’ weight and weight2 variables: . list weight* in 1/5 +------------------+ | weight weight2 | |------------------| 1. | 2,930 1.465 | 2. | 3,350 1.675 | 3. | 2,640 1.32 | 4. | 3,250 1.625 | 5. | 4,080 2.04 | +------------------+ (Note: I use list here because I need the variables outputted to create the document. When using Stata interactively, it’d probably be nicer to use browse or edit in the exact same fashion, e.g. browse weights* in 1/5. These enter the Data Browser (browse) or Data Browser (Edit Mode) (edit) showing the same subset of rows/columns as requested.) If you check the arithmetic, you’ll see that we’ve got the right answer. We should probably add a variable label to our new weight . label variable weight2 &quot;Weight (tons)&quot; . describe weight* Variable Storage Display Value name type format label Variable label ------------------------------------------------------------------------------- weight int %8.0gc Weight (lbs.) weight2 float %9.0g Weight (tons) In addition to direct arithmetic equations, we can use a number of functions to perform calculations. For example, a common transformation is to take the log of any monetary variable, in our case price. This is done because typical monetary variables, such as price or salary, tend to be very right-skewed - most people make $30k-50k, and a few people make 6 or 7 digit incomes. . generate logprice = log(price) . label variable logprice &quot;Log price&quot; . list *price in 1/5 +------------------+ | price logprice | |------------------| 1. | 4,099 8.318499 | 2. | 4,749 8.46569 | 3. | 3,799 8.242494 | 4. | 4,816 8.479699 | 5. | 7,827 8.965335 | +------------------+ In that command, log is the function name, and it is immediately followed by parentheses which enclose the variable to operate on. Read the parentheses as “of”, so that log(price) is read as “log of price”. There are a lot of functions that can be used. We list some commonly used mathematical functions below for your convenience: +, -, *, /: Standard arithmetic abs( ): returns the absolute value exp( ): returns the exponential function of (e^x) log( ) or ln( ): returns the natural logarithm of the argument7 round( ), ceil( ), floor( ): returns the rounded value (rounded to nearest integer, rounded up, and rounded down) sqrt( ): returns the square root You can see a full accounting of all functions you can use in this setting in help functions 5.2.1 Creating dummies Dummy variables (also known as indicator variables or binary variables) are variables which take on two values, 0 and 18. These are typically used in a setting where the 0 represents an absence of something (or an answer of “no”) and 1 represents the presence (or an answer of “yes”). When naming dummy variables, you should keep this in mind to make understanding the variable easier, as well as extracting interpretations regarding the variable in a model. For example, “highschool” is a poor dummy variable - what does 0 highschool or 1 highschool represent? Obviously we could (and should) use value labels to associate 0 and 1 with informative labels, but it is more straightforward to use a variable name such as “highschool_graduate” or \"graduateded_highschool) - a 0 represents “no” to the question of “graduated high school?”, hence a non-high school graduate; and a 1 represents a “yes”, hence a high school graduate. If you are collecting data, consider collecting data as dummies where appropriate - if the question has a binary response, encode it as a dummy instead of strings. If a question has categorical responses, consider encoding them as a series of dummy variables instead (e.g. “Are you from MI?”, “Are you from OH?” etc). These changes will (usually) need to be made later anyways. Now here’s the trick: In Stata9, conditional statements return 1 (True) and 0 (False). So we can use them in generate statements to create binary variables easily. . generate price4k = price &gt; 4000 . list price* in 1/5 +-----------------+ | price price4k | |-----------------| 1. | 4,099 1 | 2. | 4,749 1 | 3. | 3,799 0 | 4. | 4,816 1 | 5. | 7,827 1 | +-----------------+ Note that this is NOT the same thing as using if. E.g., we see the following error: . generate price4k2 = if price &gt; 4000 if not found r(111); Now, price4k takes on values 1 and 0 depending on whether the conditional statement was true. For a slightly more complicated example, lets create a dummy variable representing cheap cars. There are two possible definitions of cheap cars - cars which have a low cost, or cars which have low maintenance costs (high mileage and low repairs). . generate cheap = price &lt; 3500 | (rep78 &lt;= 2 &amp; mpg &gt; 20) . list make price rep78 mpg if cheap == 1 +-----------------------------------------+ | make price rep78 mpg | |-----------------------------------------| 14. | Chev. Chevette 3,299 3 29 | 17. | Chev. Monte Carlo 5,104 2 22 | 18. | Chev. Monza 3,667 2 24 | 34. | Merc. Zephyr 3,291 3 20 | 40. | Olds Starfire 4,195 1 24 | |-----------------------------------------| 52. | Pont. Sunbird 4,172 2 24 | +-----------------------------------------+ The list commands conditions on cheap == 1 because again, the conditional statement will return 1 for true and 0 for false. We see 6 cheap cars; the Chevette and Zephyr are cheap because of their cost, whereas the other four cars are cheap because of the maintenance costs. 5.2.2 System Variables In Stata, under the One Data principal, any information in the data10 must be in a variable. This includes the System Variables of _n and _N. You can imagine that every data st you ever open has two additional columns of data, one for _n and one for _N. _n represents the row number, currently. “Currently” means if the data is re-sorted, _n can change. _N represents the total number of rows in the data, hence this is the same for every row. Again, if the data changes (e.g. you drop some data) then _N may be updated. While you cannot access these System Variables normally (e.g. they don’t appear in the Data Browser), you can use them in generating variables or conditional statements. For example, we’ve seen that list can use in to restrict the rows it outputs, and we’ve seen that it can use if to choose conditionally. We can combine these: . list make in 1/2 +-------------+ | make | |-------------| 1. | AMC Concord | 2. | AMC Pacer | +-------------+ . list make if _n &lt;= 2 +-------------+ | make | |-------------| 1. | AMC Concord | 2. | AMC Pacer | +-------------+ A more useful example is to save the initial row numbering in your data. When we discuss sorting later, it may be useful to be able to return to the original ordering. Since _n changes when the data is re-sorted, if we save the initial row numbers to a permanent variable, we can always re-sort by it later. _N is slightly less useful but can be used similarly. . generate row = _n . generate totalobs = _N . list row totalobs in 1/5 +----------------+ | row totalobs | |----------------| 1. | 1 74 | 2. | 2 74 | 3. | 3 74 | 4. | 4 74 | 5. | 5 74 | +----------------+ 5.2.3 Extensions to generate The command egen offers some functionality that generate lacks, for example creating the mean of several variables egen &lt;newvar&gt; = rowmean(var1, var2, var3) The functions which egen support are fairly random; you can see the full list in the help: help egen 5.3 Replacing existing variables Earlier we created the weight2 variable which changed the units on weight from pounds to tons. What if, instead of creating a new variable, we tried to just change the existing weight variable. . generate weight = weight/2000 variable weight already defined r(110); Here Stata refuses to proceed since weight is already defined. To overwrite weight, we’ll instead need to use the replace command. . replace weight = weight/2000 variable weight was int now float (74 real changes made) . list weight in 1/5 +--------+ | weight | |--------| 1. | 1.465 | 2. | 1.675 | 3. | 1.32 | 4. | 1.625 | 5. | 2.04 | +--------+ replace features syntax identical to generate.11 5.3.1 Conditional variable generation (We’re going to reload the auto data set at this point to ensure all data is as originally saved.) . sysuse auto, clear (1978 automobile data) One frequent task is recoding variables. This can be “binning” continuous variables into a few categories, re-ordering an ordinal variables, or collapsing categories in an already-categorical variable. There are also multi-variable versions; e.g. combining multiple variables into one. The general workflow with these cases will be to optionally use generate to create the new variable, then use replace to conditional replace the original or new variable. As an example, let’s generate a new variable which categorizes cars into light, medium weight, and heavy cars. We’ll define light cars as a weight below 1 ton (2000 lbs), and heavy cars as having a weight of 2 tons (4000 lbs) or more. Before we do this, we’ve learned that the weight reported for the Pont. Grand Prix was incorrect - we don’t know what the correct weight is, but we know the presented one is wrong, so let’s make it missing. We could of course do this manually - open the data editor and delete the value of weight corresponding to the Pont. Grand Prix. As we saw earlier, manually editing the data like this produces a replace call that we can move into our Do file for reproducibility. However, this replace call would refer to a row number, something like replace weight = . in 49 What would happen if our data was shuffled prior to running this command? It would no longer be applied to the correct row. Therefore, it will be safer to use a conditional statement to identify the row corresponding to \"Pont. Grand Prix\". . replace weight = . if make == &quot;Pont. Grand Prix&quot; (1 real change made, 1 to missing) . list make weight if make == &quot;Pont. Grand Prix&quot; +---------------------------+ | make weight | |---------------------------| 49. | Pont. Grand Prix . | +---------------------------+ Now, we’ll return to generating the categorical weight variable. First, we’ll generate the new variable to store this information. . generate weight_cat = 1 . tab weight_cat weight_cat | Freq. Percent Cum. ------------+----------------------------------- 1 | 74 100.00 100.00 ------------+----------------------------------- Total | 74 100.00 Without any conditional statements, every observation’s weight_cat is set to 1. We’ll let the 1 represent the “light” category, so next we’ll replace it with 2 for cars in the “medium” category. . replace weight_cat = 2 if weight &gt;= 2000 &amp; weight &lt; 4000 (57 real changes made) . tab weight_cat weight_cat | Freq. Percent Cum. ------------+----------------------------------- 1 | 17 22.97 22.97 2 | 57 77.03 100.00 ------------+----------------------------------- Total | 74 100.00 Note the choice of &gt;= instead of &gt; and &lt; instead of &lt;=. As above, we stated that light cars have weight below 2000 lbs, so medium cars have a value of 2000 or more (greater than or equal). On the other end, heavy cars have a weght of 4000 lbs or more, so medium cars are strictly less than 4000 lbs (less than). Finish with the “heavy” cars . replace weight_cat = 3 if weight &gt;= 4000 (10 real changes made) . tab weight_cat weight_cat | Freq. Percent Cum. ------------+----------------------------------- 1 | 7 9.46 9.46 2 | 57 77.03 86.49 3 | 10 13.51 100.00 ------------+----------------------------------- Total | 74 100.00 When using less than/greater than conditinal statements to split a variable into groups, you always want to ensure that when the two “endpoints” are the same, one uses strictly less/more, and the other uses “or equal”. If both use “or equal”, you’ll get inconsistent results for exact values. If neither use “or equal”, exact values will not be classified. (For example, if we had used weight &lt; 4000 and weight &gt; 4000, any car with exact weight of 4000 would not fall into either [and its weight_cat would stay 1, a light car]. On the other hand, if we had used weight &lt;= 4000 and weight &gt;= 4000, a car with exact weight of 4000 would be assigned to whichever of the lines was run last.) Lastly, we’ll add some nice labels. . label define weight_cat 1 &quot;Light&quot; 2 &quot;Medium&quot; 3 &quot;Heavy&quot; . label values weight_cat weight_cat . tab weight_cat weight_cat | Freq. Percent Cum. ------------+----------------------------------- Light | 7 9.46 9.46 Medium | 57 77.03 86.49 Heavy | 10 13.51 100.00 ------------+----------------------------------- Total | 74 100.00 There’s one additional complication. Stata represents missing values by ., and . has a value of positive infinity. That means that \\[ 400 \\lt . \\] is true! There is some discussion on the Stata FAQs that goes into the rationale behind it, but the short version is that this slightly complicates variable generation but greatly simplifies and protects some data management tasks. The complication referred to can be seen in the row corresponding to the Pont. Grand Prix . list make weight weight_cat in 46/50 +--------------------------------------+ | make weight weight~t | |--------------------------------------| 46. | Plym. Volare 3,330 Medium | 47. | Pont. Catalina 3,700 Medium | 48. | Pont. Firebird 3,470 Medium | 49. | Pont. Grand Prix . Heavy | 50. | Pont. Le Mans 3,200 Medium | +--------------------------------------+ Even though the Grand Prix has no weight, it is categorized as “Heavy” . replace weight_cat = . if missing(weight) (1 real change made, 1 to missing) . tab weight_cat, missing weight_cat | Freq. Percent Cum. ------------+----------------------------------- Light | 7 9.46 9.46 Medium | 57 77.03 86.49 Heavy | 9 12.16 98.65 . | 1 1.35 100.00 ------------+----------------------------------- Total | 74 100.00 The missing() function returns true for each row with a missing value, and false for each row with an observed value, for the variable inside the parantheses (in this case, weight). You may occasionally see if weight != . or if weight &lt;= . instead of the missing() function. Recall that missing values are sorted to be larger than the largest observed value, so this works just as well as missing(). However, Stata allows you to define “reasons” for missing, specifically .a, .b, all the way through .z. These are sorted such that . &lt; .a &lt; .b &lt; … &lt; .z. For this reason, != . is not suggested, as while . will be captured as missing, .a, etc will not be. Using missing() removes the temptation to write != instead of &lt;=. The missing() function can be proceeded with an exclamation point to indicate not missing. For example replace x = 2 if !missing(y) The missing option to tab forces it to show a row for any missing values. Without it, missing rows are suppressed. To summarize, we used the following commands: generate weight_cat = 1 replace weight_cat = 2 if weight &gt;= 2000 &amp; weight &lt; 4000 replace weight_cat = 3 if weight &gt;= 4000 replace weight_cat = . if missing(weight) There are various other ways it could have been done, such as generate weight_cat = 1 if weight &lt; 2000 replace weight_cat = 2 if weight &gt;= 2000 &amp; weight &lt; 4000 replace weight_cat = 3 if weight &gt;= 4000 &amp; !missing(weight) generate weight_cat = . replace weight_cat = 1 if weight &lt; 2000 replace weight_cat = 2 if weight &gt;= 2000 &amp; weight &lt;= 4000 replace weight_cat = 3 if weight &gt; 4000 &amp; !missing(weight) Of course, we could also generate it in the reverse order (3 to 1) or even mixed up (3, 1, 2). There are also alternate ways to write the various conditionals, such as replacing weight &gt; 4000 with weight &gt;= 4001. There are usually multiple correct ways to specify any conditional. 5.4 More complicated replaces The above example for replace was fairly simplistic, but you can imagine the need for a much more complicated replacing structure (perhaps based on the value of multiple variables). If, however, you do have something this simple, the recode command could be used instead. The recode command syntax is fairly simple, recode &lt;oldvar&gt; (&lt;rule 1&gt;) (&lt;rule 2&gt;) ...., generate(&lt;newvar&gt;) The different rules define the recoding to take place. For example, the above creation of weight_cat can be written as recode weight (1/1999 = 1) (2000/4000 = 2) (4001/99999999 = 3) (missing = .), generate(weight_cat) Each rule has the form of old value(s) = new value, where the old values can be either a single number ((5 = 2)), several numbers (either listed as above in a numlist [note the use of a very large non-missing value for the upper bound], or just a space-separated list of values ((1 5 10 = 4)), the phrases “missing”, “nonmissing” or “else” to capture anything not elsewhere defined. The new value must be a single number or a missing value (. or .a, etc). “else” cannot be used if “missing” or “nonmissing” is defined (and vice-versa), and all of those must be the last rules defined. E.g., recode x (missing = 5) (2 = 4) (else = 3) (1 = 2), generate(y) will not run because “missing” and “else” are both simultaneously defined, and the 1 = 2 rule is last instead of “else” or “missing”. Note that if you see older code you may see either the parantheses or the generate option excluded. You should include both of these. Finally, the rules are executed left-to-right. So if you have two rules referring to the same values, the first one is used, and the second is not. For example, recode x (1/5 = 7) (2 = 4), generate(y) The 2 = 4 rule will never take place because 2 is already recoded to 7 in the 1/5 = 7 rule. 5.5 Subsetting Almost any Stata command which operates on variables can operate on a subset of the data instead of the entire data, as we saw before, by using the if or in statements in the command. This is equivalent to throwing away some data and then performing the command. In general, you should avoid discarding data as you never know when you will possible use it. Of course, you could use preserve and restore to temporarily remove the data, but using the conditional subsetting is more straightforward. If the conditional logic we want to use involves subsets of the data, we could use this to give us results within each group. . summarize price Variable | Obs Mean Std. dev. Min Max -------------+--------------------------------------------------------- price | 74 6165.257 2949.496 3291 15906 . summarize price if foreign == 0 Variable | Obs Mean Std. dev. Min Max -------------+--------------------------------------------------------- price | 52 6072.423 3097.104 3291 15906 . summarize price if foreign == 1 Variable | Obs Mean Std. dev. Min Max -------------+--------------------------------------------------------- price | 22 6384.682 2621.915 3748 12990 Keep track of the number of observations, “Obs”, to see that the second and third commands are in fact operating on the subsets. We see here that American cars are cheaper on average12. 5.5.1 Repeat commands on subsets To look at the average price for American and foreign cars, we ran two individual commands. If we wanted to look at the summaries by rep78, that would take 6 commands (values 1 through 5 and .)! Instead, we can use by and bysort to perform the same operation over each unique value in a variable. For example, we could repeat the above with: . by foreign: summ price ------------------------------------------------------------------------------- -&gt; foreign = Domestic Variable | Obs Mean Std. dev. Min Max -------------+--------------------------------------------------------- price | 52 6072.423 3097.104 3291 15906 ------------------------------------------------------------------------------- -&gt; foreign = Foreign Variable | Obs Mean Std. dev. Min Max -------------+--------------------------------------------------------- price | 22 6384.682 2621.915 3748 12990 There is a strong assumption here that the data is already sorted by the variables we are splitting by on (e.g. foreign). If foreign were not sorted (or if you simply did not want to check/assume it was), you could instead use bysort foreign: summ price bysort is identical to sorting (which we’ll discuss later) first and running the by statement afterwards. In general, it is recommended to always use bysort instead of by, unless you believe the data is already sorted and want an error if that assumption is violated. Before running these commands, consider generating a original ordering variable first. bysort’s variables cannot be conditional statements, so if you wanted to for example get summaries by low and high mileage cars, you’d need to generate a dummy variable first. . gen highmileage = mpg &gt; 20 . bysort highmileage: summ price ------------------------------------------------------------------------------- -&gt; highmileage = 0 Variable | Obs Mean Std. dev. Min Max -------------+--------------------------------------------------------- price | 38 6937.316 3262.392 3291 14500 ------------------------------------------------------------------------------- -&gt; highmileage = 1 Variable | Obs Mean Std. dev. Min Max -------------+--------------------------------------------------------- price | 36 5350.306 2358.612 3299 15906 bysort can take two or more variables, and performs its commands within each unique combination of the variable. For example, . bysort foreign highmileage: summ price ------------------------------------------------------------------------------- -&gt; foreign = Domestic, highmileage = 0 Variable | Obs Mean Std. dev. Min Max -------------+--------------------------------------------------------- price | 33 6585.606 3149.214 3291 14500 ------------------------------------------------------------------------------- -&gt; foreign = Domestic, highmileage = 1 Variable | Obs Mean Std. dev. Min Max -------------+--------------------------------------------------------- price | 19 5181.105 2867.906 3299 15906 ------------------------------------------------------------------------------- -&gt; foreign = Foreign, highmileage = 0 Variable | Obs Mean Std. dev. Min Max -------------+--------------------------------------------------------- price | 5 9258.6 3369.459 5719 12990 ------------------------------------------------------------------------------- -&gt; foreign = Foreign, highmileage = 1 Variable | Obs Mean Std. dev. Min Max -------------+--------------------------------------------------------- price | 17 5539.412 1686.472 3748 9735 When specifying bysort, you can optionally specify a variable to sort on but not to group by. For example, let’s say your data consisted of doctors visits for patients, where patients may have more than one appointment. You want to generate a variable indicating whether a visit is the first by the patient. Say id stores the patient id, date stores the date of the visit. bysort id (date): gen firstvisit = _n == 1 By placing date in parentheses, this ensures that within each id, the data is sorted by date. Therefore the first row for each patient is their first visit, so _n == 1 evaluates to 1 only in that first row and 0 zero otherwise. 5.5.2 Discarding data If you do want to discard data, you can use keep or drop to do so. They each can perform on variables: keep &lt;var1&gt; &lt;var2&gt; ... drop &lt;var1&gt; &lt;var2&gt; ... or on observations: keep if &lt;conditional&gt; drop if &lt;conditional&gt; Note that these cannot be combined: . drop turn if mpg &gt; 20 invalid syntax r(198); keep removes all variables except the listed variables, or removes any row which the conditional does not return true. drop removes any listed variables, or removes any row which the conditional returns true. 5.6 Dealing with duplicates If your data is not expected to have duplicates, either across all variables or within certain variables, the duplicates command can make their detection and correction easier. The most basic command is duplicates report, which simply reports on the status of duplicate rows. Let’s use the built-in “bplong” data. This data contains 120 patients (patient) with measures of blood pressure (bp) at two different time points (when, a Before and After), and some descriptive variables (sex and agegrp). . sysuse bplong, clear (Fictional blood-pressure data) . duplicates report Duplicates in terms of all variables -------------------------------------- Copies | Observations Surplus ----------+--------------------------- 1 | 240 0 -------------------------------------- This report is not very interesting; it reports that there are 240 observations which have 1 copy (e.g. are unique), and hence no surplus. Given that each row should be unique (just in patient ID and before/after alone), this is not surprising. Let’s instead look at the duplicates just for bp and when: . duplicates report bp when Duplicates in terms of bp when -------------------------------------- Copies | Observations Surplus ----------+--------------------------- 1 | 23 0 2 | 42 21 3 | 66 44 4 | 48 36 5 | 35 28 6 | 12 10 7 | 14 12 -------------------------------------- Here we have some duplicates. First, there are 23 observations which are fully unique. All other observations have repeats to some extent. The second row of the output tells of us that there are 42 observations which have 2 copies. The language here can be a bit confusing; all it is saying is that there are 42 rows, each of which has a single duplicate within that same 42. So if we have values 1, 1, 2, 2, that would be reported as 4 observations with 2 surplus. The number of surplus is the number of non-unique rows in that category. We could compute it ourselves - we know that there are 42 rows with 2 copies, so that means that half of the rows are “unique” and the other half are “duplicates” (which is unique and which is duplicate is not clear). So 42/2 = 21, and we have 21 surplus. Consider the row for 4 copies. There are 48 rows, each of which belongs to a set of four duplicates. For example, 1, 1, 1, 1, 2, 2, 2, 2, has observations 8 and copies 2. In this row, 48/4 = 12, so there are 12 unique values, meaning 36 surplus. Other useful commands include duplicates list: Shows every set of duplicates, including its row number and value. Obviously for something like this the output would be massive as of the 240 total rows, only 23 are not duplicated to some degree! duplicates tag &lt;vars&gt;, gen(&lt;newvar&gt;): Adds a new variable which represents the number of other copies for each row. For unique rows, this will be 0. For any duplicated rows, it will essentially be “copies” from duplicates report minus 1. This can be useful for examining duplicates or dropping them. duplicates drop: Be cautious with this, as it drops any row which is a duplicate of a previous row (in other words keeps the first entry of every set of duplicates). 5.7 Sorting We already saw sorting in the context of bysort. We can also sort as a standalone operation. As before, consider generating a original ordering variable first. We’ll switch back to “auto” first. . sysuse auto, clear (1978 automobile data) . gen order = _n The gsort function takes a list of variables to order by. . gsort rep78 price . list rep78 price in 1/5 +---------------+ | rep78 price | |---------------| 1. | 1 4,195 | 2. | 1 4,934 | 3. | 2 3,667 | 4. | 2 4,010 | 5. | 2 4,060 | +---------------+ Stata first sorts the data by rep78, ascending (so the lowest value is in row 1). Then within each set of rows that have a common value of rep78, it sorts by price. You can append “+” or “-” to each variable to change whether it is ascending or descending. Without a prefix, the variable is sorted ascending. . gsort +rep78 -price . list rep78 price in 1/5 +----------------+ | rep78 price | |----------------| 1. | 1 4,934 | 2. | 1 4,195 | 3. | 2 14,500 | 4. | 2 6,342 | 5. | 2 5,886 | +----------------+ Recall that missing values (.) are larger than any other values. When sorting with missing values, they follow this rule as well. If you want to treat missing values as smaller than all other values, you can pass the mfirst option to gsort. Note this does not make missingness “less than” anywhere else, only for the purposes of the current sort. Sorting strings does work and is done alphabetically. All capital letters are “less than” all lower case letters, and a blank string (\"\") is the “smallest”. For example, if you have the strings “DBC”, “Daa”, \"\", “EEE”, the sorted ascending order would be \"\", “DBC”, “Daa”, “EEE”. The blank is first; the two strings starting with “D” are before the string “EEE”, and the upper case “B” precedes the lower case “a”. As a side note, there is an additional command, sort, which can perform sorting. It does not allow sorting in descending order, however it does allow you to sort only a certain number of rows; that is, passing something like sort &lt;varname&gt; in 100/200 would sort only rows 100 through 200, leaving the remaining rows remain in their exact same position. 5.8 Working with strings and categorical variables String variables are commonly used during data collection but are ultimately not very useful from a statistical point of view. Typically string variables should be represented as categorical variables with value labels as we’ve previously discussed. Here are some useful commands for operating on strings and categorical variables. 5.8.1 Converting between string and numeric These two commands convert strings and numerics between each other. destring &lt;variable&gt;, gen(&lt;newvar&gt;) tostring &lt;variable&gt;, replace Both commands can take the options replace (to replace the existing variable with the new one) or gen( ) (to generate a new variable). I would recommend always using gen to double-check that the conversion worked as expected, then using drop, rename and order to replace the existing variable. . desc mpg Variable Storage Display Value name type format label Variable label ------------------------------------------------------------------------------- mpg int %8.0g Mileage (mpg) . tostring mpg, gen(mpg2) mpg2 generated as str2 . desc mpg2 Variable Storage Display Value name type format label Variable label ------------------------------------------------------------------------------- mpg2 str2 %9s Mileage (mpg) . list mpg* in 1/5 +------------+ | mpg mpg2 | |------------| 1. | 18 18 | 2. | 24 24 | 3. | 14 14 | 4. | 17 17 | 5. | 16 16 | +------------+ Now that the new string is correct, we can replace the existing mpg. . drop mpg . rename mpg2 mpg . order mpg, after(price) Let’s go the other way around: . desc mpg Variable Storage Display Value name type format label Variable label ------------------------------------------------------------------------------- mpg str2 %9s Mileage (mpg) . destring mpg, gen(mpg2) mpg: all characters numeric; mpg2 generated as byte . desc mpg2 Variable Storage Display Value name type format label Variable label ------------------------------------------------------------------------------- mpg2 byte %10.0g Mileage (mpg) . list mpg* in 1/5 +------------+ | mpg mpg2 | |------------| 1. | 18 18 | 2. | 24 24 | 3. | 14 14 | 4. | 17 17 | 5. | 16 16 | +------------+ . drop mpg . rename mpg2 mpg . order mpg, after(price) And we’re back to the original set-up.13 When using destring to convert a string variable (that it storing numeric data as strings - “13”, “14”) to a numeric variable, if there are any non-numeric entries, destring will fail. For example, lets replace one the car “make” with a numeric. . replace make = &quot;1&quot; in 1 (1 real change made) . destring make, gen(make2) make: contains nonnumeric characters; no generate We must pass the force option. With this option, any strings which have non-numeric variables will be marked as missing. . destring make, gen(make2) force make: contains nonnumeric characters; make2 generated as byte (73 missing values generated) . tab make2, mi Make and | model | Freq. Percent Cum. ------------+----------------------------------- 1 | 1 1.35 1.35 . | 73 98.65 100.00 ------------+----------------------------------- Total | 74 100.00 tostring also accepts the force option when using replace, we recommend instead to never use replace with tostring (you probably should not use it with destring either!). 5.8.2 Converting strings into labeled numbers If we have a string variable which has non-numerical values (e.g. race with values “white”, “black”, “Hispanic”, etc), the ideal way to store it is as numerical with value labels attached. While we could do this manually using a combination of gen and replace with some conditionals, a less tedious way to do so is via encode. We’ll switch to the “hbp2” data set from the Stata website, records some blood pressure measurements. (Remember this will erase any existing unsaved changes! You will not need any modifications you’ve made to other built-in datasets going forward [except census9 from Exercise 3], but if you do want to save it, do so first!) . webuse hbp2, clear . tab sex, missing Sex | Freq. Percent Cum. ------------+----------------------------------- | 2 0.18 0.18 female | 433 38.32 38.50 male | 695 61.50 100.00 ------------+----------------------------------- Total | 1,130 100.00 . desc sex Variable Storage Display Value name type format label Variable label ------------------------------------------------------------------------------- sex str6 %9s Sex The sex variable is a string with two values. First, let’s create a numeric with value labels version manually. . gen male = sex == &quot;male&quot; . label define male 0 &quot;female&quot; 1 &quot;male&quot; . label values male male . tab male, missing male | Freq. Percent Cum. ------------+----------------------------------- female | 435 38.50 38.50 male | 695 61.50 100.00 ------------+----------------------------------- Total | 1,130 100.00 . replace male = . if sex == &quot;&quot; (2 real changes made, 2 to missing) . tab male, missing male | Freq. Percent Cum. ------------+----------------------------------- female | 433 38.32 38.32 male | 695 61.50 99.82 . | 2 0.18 100.00 ------------+----------------------------------- Total | 1,130 100.00 . tab male, missing nolabel male | Freq. Percent Cum. ------------+----------------------------------- 0 | 433 38.32 38.32 1 | 695 61.50 99.82 . | 2 0.18 100.00 ------------+----------------------------------- Total | 1,130 100.00 Instead, we can easily use encode: . encode sex, gen(sex2) . tab sex2, missing Sex | Freq. Percent Cum. ------------+----------------------------------- female | 433 38.32 38.32 male | 695 61.50 99.82 . | 2 0.18 100.00 ------------+----------------------------------- Total | 1,130 100.00 . tab sex2, missing nolabel Sex | Freq. Percent Cum. ------------+----------------------------------- 1 | 433 38.32 38.32 2 | 695 61.50 99.82 . | 2 0.18 100.00 ------------+----------------------------------- Total | 1,130 100.00 However, we see that encode starts numbering at 1 instead of 0, which is not ideal for dummy variables. To get around this, we can create our value label manually first, then pass it as an argument to encode. . label define manualsex 0 &quot;female&quot; 1 &quot;male&quot; . encode sex, gen(sex3) label(manualsex) . tab sex3, missing Sex | Freq. Percent Cum. ------------+----------------------------------- female | 433 38.32 38.32 male | 695 61.50 99.82 . | 2 0.18 100.00 ------------+----------------------------------- Total | 1,130 100.00 . tab sex3, missing nolabel Sex | Freq. Percent Cum. ------------+----------------------------------- 0 | 433 38.32 38.32 1 | 695 61.50 99.82 . | 2 0.18 100.00 ------------+----------------------------------- Total | 1,130 100.00 This can be extended to allow any sort of ordering desired. For this trivial binary example, it might actually be faster to use gen and do it manually, but for a variable with a large number of categories, this is much easier. decode works in the reverse, creating a string out of a numeric vector with labels attached to it. . decode sex3, gen(sex4) . desc sex4 Variable Storage Display Value name type format label Variable label ------------------------------------------------------------------------------- sex4 str6 %9s Sex . tab sex4, missing Sex | Freq. Percent Cum. ------------+----------------------------------- | 2 0.18 0.18 female | 433 38.32 38.50 male | 695 61.50 100.00 ------------+----------------------------------- Total | 1,130 100.00 decode will fail if its target does not have value labels attached. 5.8.3 String manipulation If you find yourself in a situation where you simply must manipulate the strings directly, there are a number of string functions. You can see the full list in help string functions, but below we list a few commonly used ones. strlen: Returns the number of characters in the string wordcount: Returns the number of whitespace-separated words. “+”: Adding two strings together concatenates them (e.g. “abc” + “def” = “abcdef”). strupper and strlower: Converts to lower/upper case. strtrim: Removes white space before and after strings (e.g. strtrim(\" string \") = \"string\"). To remove only left (preceding) or right (following) spaces, use strltrim or strrtrim. substr: Returns the substring starting at an index for a given number of characters (e.g. `substr(“abcdefg”, 2, 3) = “bcd”). These are used inside gen and replace, e.g. . gen sexupper = strupper(sex) (2 missing values generated) . gen sexinitial = substr(sexupper, 1, 1) (2 missing values generated) . list sex sexupper sexinitial in 1/5 +------------------------------+ | sex sexupper sexini~l | |------------------------------| 1. | female FEMALE F | 2. | | 3. | male MALE M | 4. | male MALE M | 5. | female FEMALE F | +------------------------------+ 5.9 Exercise 5 Open the saved version of “census9” with use, not the original version with webuse. Generate a new variable, deathperc, which is the percentage of deaths in each state. (Remember that deathrate is deaths per 10,000.) The average age of all Americans in 1980 is roughly 30.11 years of age. Generate a categorical with four values as described before, with appropriate value labels. Significantly below national average: medage equal to 26.20 or less Below national average: medage greater than 26.20 and less than or equal to 30.10. Above national average: medage greater than 30.10 and less than or equal to 32.80. Significantly above national average: medage greater than 32.80. What is the death rate in each of those four categories? (You can use summarize to obtain the means.) Does there appear to be any pattern? What state has the lowest death rate? The highest? The lowest average age? The highest? Each state has a single observation here, but if we had multiple years of data, then we could have “long data” with multiple rows per state. To prepare for this sort of data, encode the two-letter state abbreviation into a numeric value with value labels. 5.10 Merging Files When managing data sets, the need often arises to merge two data sets together, either by matching two files together according to values on certain variables, or by adding cases to an existing data set. We’ll start with the simpler case of adding cases to an existing data set. 5.10.1 Appending Files Appending is straightforward. Observations in a new data set (called the “using” data) are appended to the current data set (called the “master” data), matching variable names. If a variable in the using data exists already in the master data, its values are entered there. If a variable in the using data does not exist in the master, the new variable is added to the appended data set which is missing for all members of the master data. This is easiest to visualize. There are two data sets on Stata’s website which we can append, “odd” and “even”. . webuse odd, clear (First five odd numbers) . list +--------------+ | number odd | |--------------| 1. | 1 1 | 2. | 2 3 | 3. | 3 5 | 4. | 4 7 | 5. | 5 9 | +--------------+ . webuse even (6th through 8th even numbers) . list +---------------+ | number even | |---------------| 1. | 6 12 | 2. | 7 14 | 3. | 8 16 | +---------------+ It does not truly matter which data set is the master data and which is the using data (it will later in match-merging), it will only affect the sorted order (the data in master is sorted first). The syntax is simply append using &lt;using data&gt; . webuse even (6th through 8th even numbers) . append using http://www.stata-press.com/data/r16/odd (variable number was byte, now float to accommodate using data's values) . list +---------------------+ | number even odd | |---------------------| 1. | 6 12 . | 2. | 7 14 . | 3. | 8 16 . | 4. | 1 . 1 | 5. | 2 . 3 | |---------------------| 6. | 3 . 5 | 7. | 4 . 7 | 8. | 5 . 9 | +---------------------+ (We must specify the complete path to the data instead of the webuse shorthand of just the data name. Of course, with real data that you locally have on your computer, you follow the working directory rules; if the file exists in your working directory you just give the name, otherwise give the complete path. I obtained that path by visiting the Stata data website and finding the link to “odd”.) Note that the “number” variable, which exists in both data sets, has complete data, while “even” and “odd” both have missing data as expected. The using part of the command is where the term the “using data” comes from. Stata is case sensitive in its variable names, so “varname” and “Varname” are two unique variables. We could always fix this later with something like replace varname = Varname if varname == . but it is better to ensure before appending that the shared variables have identical names. 5.10.2 Match-merging Data A more common data management necessity is to add variables from another data set to a master data set, match-merging the cases in the data sets by values on a single ID variable (or by values on multiple variables). There are two general forms of this match-merging. The first, one-to-one merging, occurs when in each data, each individual is represented by only one row. For example, one data set containing final exam information and one data set containing demographic information. This “1:1” match takes rows which match on some variable(s) and places them together. The second match, many-to-one, occurs when the data are measured on different “levels”. For example, consider if we have one data set containing household level characteristics and another containing town level characters. Two households from the same town would want the same town level data. This is either “1:m” or “m:1” depending on which data is the master data and which is the using data (e.g. 1:m indicates the household data is the master data and town is the using data). (Technically there is also many-to-many matching, “m:m”, but it is rarely used in practice.) We’ll use data sets off Stata’s website again to demonstrate, specifically the “autosize” and “autocost” data which splits the “auto” data into two pieces. . webuse autosize, clear (1978 automobile data) . list in 1/5 +------------------------------------+ | make weight length | |------------------------------------| 1. | Toyota Celica 2,410 174 | 2. | BMW 320i 2,650 177 | 3. | Cad. Seville 4,290 204 | 4. | Pont. Grand Prix 3,210 201 | 5. | Datsun 210 2,020 165 | +------------------------------------+ . webuse autocost (1978 automobile data) . list in 1/5 +-----------------------------+ | make price rep78 | |-----------------------------| 1. | AMC Concord 4099 3 | 2. | AMC Pacer 4749 3 | 3. | AMC Spirit 3799 . | 4. | Audi 5000 9690 5 | 5. | Audi Fox 6295 3 | +-----------------------------+ Now we can perform the merge using the syntax. merge 1:1 &lt;variables to match on&gt; using &lt;using data set&gt; All that needs to be specified is the variable to match cases by and the name of the data set with variables to be added. We could replace 1:1 with m:1 or 1:m as desired. . merge 1:1 make using http://www.stata-press.com/data/r16/autosize Result Number of obs ----------------------------------------- Not matched 68 from master 68 (_merge==1) from using 0 (_merge==2) Matched 6 (_merge==3) ----------------------------------------- . list in 3/6 +----------------------------------------------------------------+ | make price rep78 weight length _merge | |----------------------------------------------------------------| 3. | AMC Spirit 3799 . . . Master only (1) | 4. | Audi 5000 9690 5 . . Master only (1) | 5. | Audi Fox 6295 3 . . Master only (1) | 6. | BMW 320i 9735 4 2,650 177 Matched (3) | +----------------------------------------------------------------+ (Again, we use the full path but for local files, following working directory rules.) First, take a look at the output of the merge command. We see that 68 cars were not matched, which means they exist in only one of the two data sets. In this case, they all exist in master data, but in general you could see a mix of the two. The remaining 6 observations were appropriately matched. This is a terrible merge! Hopefully with your real data, the majority of data is matched and only a few outliers are not matched. Notice the (_merge==#) tags. When you perform a merge, a new variable _merge is added which indicates the source for each row: 1 and 2 indicate the data was only found in the master data or using data respectively, while 3 indicates a match. There are two other possible values (4 and 5) which occur rarely, see the documentation at help merge for details. A few notes: Stata will sort both files by the key variables before and after merging. You can match on more than one variable. For example, if you had data based upon year and state, you might run merge 1:1 state year using … If you wanted to merge another file after the initial merge, you’ll need to drop the _merge variable first. IMPORTANT NOTE: Make sure that the only variables common to both files when performing a match-merge are the variables that will be used to match cases (like ID)! Stata will by default keep the variable in the master data when the merge is performed if the same variable appears in more than one file and is not defined as a matching variable. This may cause problems when performing merges. (You can overwrite this behavior with the update or replace options, see the documentation for details.) 5.11 Reshaping Files Different data formats are needed for various statistical methods. Stata prefers data in “Long” format, but also makes it easy to convert between Long and “Wide”. Stata uses the reshape command to convert data formats. In this example, the wide format of the data has each row representing a single observation. The variables “X1”, “X2” and “X3” are what make this “wide”. These are typically variables measured at different time points, but don’t have to be. In the long format, each row represents an observation at a specific index. A nice feature of Stata’s reshape command is that the syntax to convert from wide-to-long or from long-to-wide are identical, except for desired format (long vs wide). Convert to long: reshape long &lt;stub&gt;, i(&lt;ivar&gt;) j(&lt;jvar&gt;) Convert to wide: reshape wide &lt;stub&gt;, i(&lt;ivar&gt;) j(&lt;jvar&gt;) We need to identify three components, the stub, ivar and jvar. “stub”: The stub in wide format is the common prefix of the repeated variables names. In the illustration above, “X1”, “X2” and “X3” have the common prefix “X”. In the long format, the stub is simply the name of the variable which is repeated. In the illustration above, “X” is this variable. Hence the stub is X for both. “ivar”: The ivar is the id variable. In the long format, this should be constant across individuals. In both formats above, the id is ID. “jvar”: The jvar in long format is the variable that distinguishes which index each repeated measure is from. In the illustration above, “Index” fills this role. In wide format, this does not exist. So when converting from wide to long, you can use any name for the jvar. Putting this all together together, the two commands to convert between the illustrations above would be: reshape long X, i(ID) j(Index) reshape wide X, i(ID) j(Index) As an example, we’ll use the built-in data set “bplong” . sysuse bplong, clear (Fictional blood-pressure data) . list in 1/5 +----------------------------------------+ | patient sex agegrp when bp | |----------------------------------------| 1. | 1 Male 30-45 Before 143 | 2. | 1 Male 30-45 After 153 | 3. | 2 Male 30-45 Before 163 | 4. | 2 Male 30-45 After 170 | 5. | 3 Male 30-45 Before 153 | +----------------------------------------+ Each patient has two rows representing their before and after measurements. when indicates which time period the measurement occurs in, and bp is the only time-varying variable (both sex and agegrp are constant, presumably the “Before” and “After” occur within a short time period such that neither of those can change). Let’s identify the three components “stub”: Since we’re going from long to wide, the “stub” is any time-varying variables, here only bp. “ivar”: patient identifies individuals. “jvar”: when identifies time period. Putting this together, . reshape wide bp, i(patient) j(when) (j = 1 2) Data Long -&gt; Wide ----------------------------------------------------------------------------- Number of observations 240 -&gt; 120 Number of variables 5 -&gt; 5 j variable (2 values) when -&gt; (dropped) xij variables: bp -&gt; bp1 bp2 ----------------------------------------------------------------------------- . list in 1/5 +-------------------------------------+ | patient bp1 bp2 sex agegrp | |-------------------------------------| 1. | 1 143 153 Male 30-45 | 2. | 2 163 170 Male 30-45 | 3. | 3 153 168 Male 30-45 | 4. | 4 153 142 Male 30-45 | 5. | 5 146 141 Male 30-45 | +-------------------------------------+ Each row represents a single patient, and bp1 and bp2 represent the before and after measurements. Let’s generate the command to convert back to long. “stub”: “bp” is the stub of bp1 and bp2. “ivar”: patient identifies individuals. “jvar”: Since the data is currently wide, there is no existing jvar and we can call it whatever we like. For consistency, we’ll call it “when” again. The command is identical! Just swap wide for long. . reshape long bp, i(patient) j(when) (j = 1 2) Data Wide -&gt; Long ----------------------------------------------------------------------------- Number of observations 120 -&gt; 240 Number of variables 5 -&gt; 5 j variable (2 values) -&gt; when xij variables: bp1 bp2 -&gt; bp ----------------------------------------------------------------------------- . list in 1/5 +----------------------------------------+ | patient when bp sex agegrp | |----------------------------------------| 1. | 1 Before 143 Male 30-45 | 2. | 1 After 153 Male 30-45 | 3. | 2 Before 163 Male 30-45 | 4. | 2 After 170 Male 30-45 | 5. | 3 Before 153 Male 30-45 | +----------------------------------------+ The variables are slightly out of order, but we’ve completely recovered the original data. After you’ve run a single reshape command, and assuming nothing has changed (you do not want to change “stub”, “ivar” or “jvar”, and the variables in the data are the same), you can convert between wide and long without specifying anything. Try it: reshape wide reshape long Now, notice that when we reshaped the original long data into wide format, the two “bp” variables where bp1 and bp2, not something like bp_before and bp_after. In most cases this is fine (as the common use case for this is repeated measures over time), but not always - what if we wanted to save the “before” and “after” labels? Do note that thankfully Stata saves these labels, so when converting back to long, it restores the “Before” and “After” tags. If you do want to save the text instead of the count, you need to use strings. We’ll use decode to convert to a string, then use that as the jvar. . decode when, gen(when2) . drop when . rename when2 when . reshape wide bp, i(patient) j(when) string (j = After Before) Data Long -&gt; Wide ----------------------------------------------------------------------------- Number of observations 240 -&gt; 120 Number of variables 5 -&gt; 5 j variable (2 values) when -&gt; (dropped) xij variables: bp -&gt; bpAfter bpBefore ----------------------------------------------------------------------------- . list in 1/5 +----------------------------------------------+ | patient bpAfter bpBefore sex agegrp | |----------------------------------------------| 1. | 1 153 143 Male 30-45 | 2. | 2 170 163 Male 30-45 | 3. | 3 168 153 Male 30-45 | 4. | 4 142 153 Male 30-45 | 5. | 5 141 146 Male 30-45 | +----------------------------------------------+ Note the string option. When converting back to long, you’ll need to encode the string to get it back to numeric. . reshape long (j = After Before) Data Wide -&gt; Long ----------------------------------------------------------------------------- Number of observations 120 -&gt; 240 Number of variables 5 -&gt; 5 j variable (2 values) -&gt; when xij variables: bpAfter bpBefore -&gt; bp ----------------------------------------------------------------------------- . desc when Variable Storage Display Value name type format label Variable label ------------------------------------------------------------------------------- when str6 %9s Status . encode when, gen(when2) . drop when . rename when2 when . desc when Variable Storage Display Value name type format label Variable label ------------------------------------------------------------------------------- when long %8.0g when2 Status A few notes: If you have wide data and some individuals are missing some repeated measures, when converting to tall, they will still have a row with a blank value. You can easily drop it: reshape long drop if &lt;varname&gt; == . Converting back to wide will re-enter those missing values; reshape does not care if the long data is “complete”. More than one stub can be entered if you have more than one repeated measurement. For example, if the variables were {“id”, “x1”, “x2”, “y1”, “y2”}, you could enter reshape long x y, i(id) j(index) Note that they technically don’t have to have the same indices (e.g. you could have “x1”, “x2”, “y3”, “y4”) although that would create a weird result where each row of index 1 or 2 is missing y and each row of index 3 or 4 is missing x. If you have wide data and many time-varying variables, there is no shorthand for entering all the stubs. For large data, this is extremely frustrating. I’d recommend using describe, simple to get a list of all variable names, then using find &amp; replace to remove the indices. If you know a better way, let me know! If you want log with a different base, you can use the transformation that dividing by log(b) is equivalent to using b as a base. In other words, if you need log base 10, use gen newvar = log(oldvar)/log(10).↩︎ Technically and mathematically they can take on any two values, but your life will be easier if you stick with the 0/1 convention.↩︎ This is true of most statistical software in fact.↩︎ We’ll see some exceptions to this in the programming section.↩︎ generate has a few features we do not discuss which replace does not support. Namely, generate can set the type manually (instead of letting Stata choose the best type automatically), and generate can place the new variable as desired rather than using order. Clearly, neither of these features are needed for replace.↩︎ Note that this is not a statistical claim, we would have to do a two-sample t-test to make any statistical claim.↩︎ If you are sharp-eyed, you may have noticed that the original mpg was an “int” whereas the final one is a “byte”. If we had called compress on the original data, it would have done that type conversion anyways - so we’re ok!↩︎ "],["programming-advanced-features.html", "Chapter 6 Programming &amp; Advanced Features 6.1 Macros 6.2 Variable Lists 6.3 Linking data sets 6.4 Loops 6.5 Suppressing output and errors", " Chapter 6 Programming &amp; Advanced Features Stata features the ability to create user-written commands. These can range from simple data manipulation commands to completely new statistical models. This is an advanced feature that not many users will need. However, there are several components of the programming capabilities which are very useful even without writing your own commands. Here we’ll discuss several. Let’s open a fresh version of “auto”: . sysuse auto, clear (1978 automobile data) 6.1 Macros While variables stored as strings aren’t of much use to us, strings stored as other strings can be quite useful. Imagine the following scenario: You have a collection of 5 variables that you want to perform several different operations on. You might have code like this: list var1 var2 var3 var4 var5 in 1/5 summ var1 var2 var3 var4 var5 label define mylab 0 &quot;No&quot; 1 &quot;Yes&quot; label values var1 var2 var3 var4 var5 mylab duplicates list var1 var2 var3 var4 var5 This can get extremely tedious as the number of variables and commands increases. You could copy and paste a lot, but even that takes a lot of effort. Instead, we can store the list of variables (strictly speaking, the string which contains the list of variables) in a shorter key string, and refer to that instead! local vars = &quot;var1 var2 var3 var4 var5&quot; list `vars' in 1/5 summ `vars' label define mylab 0 &quot;No&quot; 1 &quot;Yes&quot; label values `vars' mylab duplicates list `vars' The first command, local, defines what is known as a “local macro”14. Whenever it is referred to, wrapped in a backtick (to the left of the 1 key at the top-left of the keyboard) and a single quote, Stata replaces it with the original text. So when you enter list `vars' in 1/5 Stata immediately replaces `vars’ with var1 var2 var3 var4 var5, then executes list var1 var2 var3 var4 var5 in 1/5 Important: Local macros are deleted as soon as code finishes executing! That means that you must use them in a do-file, and you must run all lines which create and access the macro at the same time, by highlighting them all. Some other notes: If your macro contains text that should be quoted, you still need to quote it when accessing. For example, if you had label variable price1 &quot;Price (in dollars) at Time Point 1&quot; label variable price2 &quot;Price (in dollars) at Time Point 2&quot; you could instead write local pricelab = &quot;Price (in dollars) at Time Point&quot; label variable price1 &quot;`pricelab' 1&quot; label variable price2 &quot;`pricelab' 2&quot; You can use display to print the content of macros to the output to preview them. . local test = &quot;abc&quot; . display &quot;`test'&quot; abc You may occasionally see code that excludes the = in defining a macro (e.g. local vars \"var1 var2\"). The differences between including and excluding the = are mostly unimportant, so I recommend sticking with the = unless you specifically need the other version. 6.1.1 Class and Return Every command in Stata is of a particular type. One major aspect of the type is what the command “returns”. Some commands are n-class, which means they don’t return anything. Some are c-class, which are only used by programmers and rarely useful elsewhere. The two common ones are e-class and r-class. The distinction between the two is inconsequential, besides that they store their “returns” in different places. Here, summarize is a r-class command, so it stores its returns in “return”. We can see them all by return list. On the other hand, mean (which we haven’t discussed, but basically displays summary statistics similar to summarize but provides some additional functionality) is an e-class command, storing its results in ereturn: . summ price Variable | Obs Mean Std. dev. Min Max -------------+--------------------------------------------------------- price | 74 6165.257 2949.496 3291 15906 . return list scalars: r(N) = 74 r(sum_w) = 74 r(mean) = 6165.256756756757 r(Var) = 8699525.974268788 r(sd) = 2949.495884768919 r(min) = 3291 r(max) = 15906 r(sum) = 456229 . mean price Mean estimation Number of obs = 74 -------------------------------------------------------------- | Mean Std. err. [95% conf. interval] -------------+------------------------------------------------ price | 6165.257 342.8719 5481.914 6848.6 -------------------------------------------------------------- . ereturn list scalars: e(df_r) = 73 e(N_over) = 1 e(N) = 74 e(k_eq) = 1 e(rank) = 1 macros: e(cmdline) : &quot;mean price&quot; e(cmd) : &quot;mean&quot; e(vce) : &quot;analytic&quot; e(title) : &quot;Mean estimation&quot; e(estat_cmd) : &quot;estat_vce_only&quot; e(varlist) : &quot;price&quot; e(marginsnotok) : &quot;_ALL&quot; e(properties) : &quot;b V&quot; matrices: e(b) : 1 x 1 e(V) : 1 x 1 e(sd) : 1 x 1 e(_N) : 1 x 1 e(error) : 1 x 1 functions: e(sample) Rather than try and keep track of what gets stored where, if you look at the very bottom of any help file, it will say something like “summarize stores the following in r():” or “mean stores the following in e():”, corresponding to return and ereturn respectively. Along with the One Data principal, Stata also follows the One _-class principal - meaning you can only view the return or ereturn for the most recent command of that class. So if you run a summarize command, then do a bunch of n-class calls (gsort for example), the return list call will still give you the returns for that first summarize. However, as soon as you run another r-class command, you lose access to the first one. You can save any piece of it using a macro. For example, to calculate the average difference in price between foreign and domestic cars15: . summ price if foreign == 1 Variable | Obs Mean Std. dev. Min Max -------------+--------------------------------------------------------- price | 22 6384.682 2621.915 3748 12990 . local fprice = r(mean) . summ price if foreign == 0 Variable | Obs Mean Std. dev. Min Max -------------+--------------------------------------------------------- price | 52 6072.423 3097.104 3291 15906 . local dprice = r(mean) . display `dprice' - `fprice' -312.25874 6.2 Variable Lists Introduced in Stata 16, variable lists solves a common technique used in previous versions of Stata to define a global containing a list of variables to be used later in the document. For example, you might see something like this at the top of a Do file: global predictors x1 x2 x3 x4 then further down the document something like regress y $predictors logit z $predictors Stata has formalized this concept with the addition of the vl command (variable list). It works similarly to the use of globals: lists of variables are defined, then later reference via the $name syntax. However, using vl has the benefits of improved organization, customizations unique to variable lists, error checking, and overall convenience. 6.2.1 Initialization of Variable Lists To begin using variable lists, vl set must be run. . sysuse auto (1978 automobile data) . vl set ------------------------------------------------------------------------------- | Macro's contents |------------------------------------------------------------ Macro | # Vars Description ------------------+------------------------------------------------------------ System | $vlcategorical | 2 categorical variables $vlcontinuous | 2 continuous variables $vluncertain | 7 perhaps continuous, perhaps categorical variables $vlother | 0 all missing or constant variables ------------------------------------------------------------------------------- Notes 1. Review contents of vlcategorical and vlcontinuous to ensure they are correct. Type vl list vlcategorical and type vl list vlcontinuous. 2. If there are any variables in vluncertain, you can reallocate them to vlcategorical, vlcontinuous, or vlother. Type vl list vluncertain. 3. Use vl move to move variables among classifications. For example, type vl move (x50 x80) vlcontinuous to move variables x50 and x80 to the continuous classification. 4. vlnames are global macros. Type the vlname without the leading dollar sign ($) when using vl commands. Example: vlcategorical not $vlcategorical. Type the dollar sign with other Stata commands to get a varlist. This produces a surprisingly large amount of output. When you initialize the use of variable lists, Stata will automatically create four variable lists, called the “System variable lists”. Every numeric variable in the current data set is automatically placed into one of these four lists: vlcategorical: Variables which Stata thinks are categorical. These generally have to be non-negative, integer valued variables with less than 10 unique values. vlcontinuous: Variables which Stata thinks are continuous. These generally are variables which have negative values, have non-integer values, or are non-negative integers with more than 100 unique values. vluncertain: Variables which Stata is unsure whether they are continuous or categorical. These generally are non-negative integer valued variables with between 10 and 100 unique values. vlother: Any numeric variables that aren’t really useful - either all missing or constant variables. There is a potential fifth system variable list, vldummy, which is created when option dummy is passed. Unsurprisingly, this will take variables containing only values 0 and 1 out of vlcategorical and into this list. The “Notes” given below the output are generic; they appear regardless of how well Stata was able to categorize the variables. They can be suppressed with the nonotes option to vl set16. The two thresholds given above, 10 and 100, can be adjusted by the categorical and uncertain options. For example, vl set, categorical(20) uncertain(50) Running vl set on an already vl-set data set will result in an error, unless the clear option is given, which will re-generate the lists. . vl set, dummy nonotes one or more already classified variables specified You requested that variables be added to vl's system classifications, but you specified 11 variables that were already classified. r(110); . vl set, dummy nonotes clear ------------------------------------------------------------------------------- | Macro's contents |------------------------------------------------------------ Macro | # Vars Description ------------------+------------------------------------------------------------ System | $vldummy | 1 0/1 variable $vlcategorical | 1 categorical variable $vlcontinuous | 2 continuous variables $vluncertain | 7 perhaps continuous, perhaps categorical variables $vlother | 0 all missing or constant variables ------------------------------------------------------------------------------- In the above, we changed our minds and wanted to include the vldummy list, but since we’d already vl-set, we had the clear the existing set. 6.2.2 Viewing lists When initializing the variable lists, we’re treated to a nice table of all defined lists. We can replay it via . vl dir ------------------------------------------------------------------------------- | Macro's contents |------------------------------------------------------------ Macro | # Vars Description ------------------+------------------------------------------------------------ System | $vldummy | 1 0/1 variable $vlcategorical | 1 categorical variable $vlcontinuous | 2 continuous variables $vluncertain | 7 perhaps continuous, perhaps categorical variables $vlother | 0 all missing or constant variables ------------------------------------------------------------------------------- To see the actual contents of the variable lists, we’ll need to sue vl list. . vl list ---------------------------------------------------- Variable | Macro Values Levels -------------+-------------------------------------- foreign | $vldummy 0 and 1 2 rep78 | $vlcategorical integers &gt;=0 5 headroom | $vlcontinuous noninteger gear_ratio | $vlcontinuous noninteger price | $vluncertain integers &gt;=0 74 mpg | $vluncertain integers &gt;=0 21 trunk | $vluncertain integers &gt;=0 18 weight | $vluncertain integers &gt;=0 64 length | $vluncertain integers &gt;=0 47 turn | $vluncertain integers &gt;=0 18 displacement | $vluncertain integers &gt;=0 31 ---------------------------------------------------- This output produces one row for each variable in each variable list it is in. We haven’t used this yet, but variables can be in multiple lists. We can list only specific lists: . vl list vlcategorical ------------------------------------------------ Variable | Macro Values Levels ---------+-------------------------------------- rep78 | $vlcategorical integers &gt;=0 5 ------------------------------------------------ or specific variables . vl list (turn weight) ------------------------------------------------ Variable | Macro Values Levels ---------+-------------------------------------- turn | $vluncertain integers &gt;=0 18 weight | $vluncertain integers &gt;=0 64 ------------------------------------------------ If “turn” was in multiple variable lists, each would appear as a row in this output. There’s a bit of odd notation which can be used to sort the output by variable name, which makes it easier to identify variables which appear in multiple lists. . vl list (_all), sort ---------------------------------------------------- Variable | Macro Values Levels -------------+-------------------------------------- displacement | $vluncertain integers &gt;=0 31 foreign | $vldummy 0 and 1 2 gear_ratio | $vlcontinuous noninteger headroom | $vlcontinuous noninteger length | $vluncertain integers &gt;=0 47 mpg | $vluncertain integers &gt;=0 21 price | $vluncertain integers &gt;=0 74 rep78 | $vlcategorical integers &gt;=0 5 trunk | $vluncertain integers &gt;=0 18 turn | $vluncertain integers &gt;=0 18 weight | $vluncertain integers &gt;=0 64 ---------------------------------------------------- The (_all) tells Stata to report on all variables, and sorting (when you specify at least one variable) orders by variable name rather than variable list name. This will also list any numeric variables which are not found in any list. 6.2.2.1 Moving variables in system lists After initializing the variable lists, if you plan on using the system lists, you may need to move variables around (e.g. classifying the vluncertain variables into their proper lists). This can be done via vl move which has the syntax vl move (&lt;variables to move&gt;) &lt;destination list&gt; For example, all the variables in vluncertain are actually continuous: . vl list vluncertain ---------------------------------------------------- Variable | Macro Values Levels -------------+-------------------------------------- price | $vluncertain integers &gt;=0 74 mpg | $vluncertain integers &gt;=0 21 trunk | $vluncertain integers &gt;=0 18 weight | $vluncertain integers &gt;=0 64 length | $vluncertain integers &gt;=0 47 turn | $vluncertain integers &gt;=0 18 displacement | $vluncertain integers &gt;=0 31 ---------------------------------------------------- . vl move (price mpg trunk weight length turn displacement) vlcontinuous note: 7 variables specified and 7 variables moved. ------------------------------ Macro # Added/Removed ------------------------------ $vldummy 0 $vlcategorical 0 $vlcontinuous 7 $vluncertain -7 $vlother 0 ------------------------------ . vl dir ------------------------------------------------------------------------------- | Macro's contents |------------------------------------------------------------ Macro | # Vars Description ------------------+------------------------------------------------------------ System | $vldummy | 1 0/1 variable $vlcategorical | 1 categorical variable $vlcontinuous | 9 continuous variables $vluncertain | 0 perhaps continuous, perhaps categorical variables $vlother | 0 all missing or constant variables ------------------------------------------------------------------------------- Alternatively, since we’re moving all variables in vluncertain, we can see our first use of the variable list! . vl set, dummy nonotes clear ------------------------------------------------------------------------------- | Macro's contents |------------------------------------------------------------ Macro | # Vars Description ------------------+------------------------------------------------------------ System | $vldummy | 1 0/1 variable $vlcategorical | 1 categorical variable $vlcontinuous | 2 continuous variables $vluncertain | 7 perhaps continuous, perhaps categorical variables $vlother | 0 all missing or constant variables ------------------------------------------------------------------------------- . vl move ($vluncertain) vlcontinuous note: 7 variables specified and 7 variables moved. ------------------------------ Macro # Added/Removed ------------------------------ $vldummy 0 $vlcategorical 0 $vlcontinuous 7 $vluncertain -7 $vlother 0 ------------------------------ Note that variable lists are essentially just global macros so can be referred to via $name. Note, however, that the $ is only used when we want to actually use the variable list as a macro - in this case, we wanted to expand vluncertain into it’s list of variables. When we’re referring to a variable list in the vl commands, we do not use the $. 6.2.3 User Variable Lists In addition to the System variable lists, you can define your own User variables lists, which I imagine will be used far more often. These are easy to create with vl create: . vl create mylist1 = (weight mpg) note: $mylist1 initialized with 2 variables. . vl create mylist2 = (weight length trunk) note: $mylist2 initialized with 3 variables. . vl dir, user ------------------------------------------------------------------------------- | Macro's contents |------------------------------------------------------------ Macro | # Vars Description ------------------+------------------------------------------------------------ User | $mylist1 | 2 variables $mylist2 | 3 variables ------------------------------------------------------------------------------- . vl list, user ------------------------------------------------ Variable | Macro Values Levels ---------+-------------------------------------- weight | $mylist1 integers &gt;=0 64 mpg | $mylist1 integers &gt;=0 21 weight | $mylist2 integers &gt;=0 64 length | $mylist2 integers &gt;=0 47 trunk | $mylist2 integers &gt;=0 18 ------------------------------------------------ Note the addition of the user option to vl list and vl dir to show only User variable lists and suppress the System variable lists. We can also demonstrate the odd sorting syntax here: . vl list (_all), sort user ---------------------------------------------------- Variable | Macro Values Levels -------------+-------------------------------------- displacement | not in vluser 31 foreign | not in vluser 2 gear_ratio | not in vluser headroom | not in vluser length | $mylist2 integers &gt;=0 47 mpg | $mylist1 integers &gt;=0 21 price | not in vluser 74 rep78 | not in vluser 5 trunk | $mylist2 integers &gt;=0 18 turn | not in vluser 18 weight | $mylist1 integers &gt;=0 64 weight | $mylist2 integers &gt;=0 64 ---------------------------------------------------- You can refer to variable lists in all the usual shortcut ways: vl create mylist = (x1-x100 z*) We can add labels to variable lists: . vl label mylist1 &quot;Related to gas consumption&quot; . vl label mylist2 &quot;Related to size&quot; . vl dir, user ------------------------------------------------------------------------------- | Macro's contents |------------------------------------------------------------ Macro | # Vars Description ------------------+------------------------------------------------------------ User | $mylist1 | 2 Related to gas consumption $mylist2 | 3 Related to size ------------------------------------------------------------------------------- 6.2.3.1 Modifying User Variable Lists First, note that with User Variable Lists, the vl move command does not work. It only works with system variable lists. We can create new user variable lists which build off old lists with vl create. To add a new variable: . vl create mylist3 = mylist2 + (gear_ratio) note: $mylist3 initialized with 4 variables. . vl list, user -------------------------------------------------- Variable | Macro Values Levels -----------+-------------------------------------- weight | $mylist1 integers &gt;=0 64 mpg | $mylist1 integers &gt;=0 21 weight | $mylist2 integers &gt;=0 64 length | $mylist2 integers &gt;=0 47 trunk | $mylist2 integers &gt;=0 18 weight | $mylist3 integers &gt;=0 64 length | $mylist3 integers &gt;=0 47 trunk | $mylist3 integers &gt;=0 18 gear_ratio | $mylist3 noninteger -------------------------------------------------- . vl create mylist4 = mylist2 - (turn) note: $mylist4 initialized with 3 variables. . vl list, user -------------------------------------------------- Variable | Macro Values Levels -----------+-------------------------------------- weight | $mylist1 integers &gt;=0 64 mpg | $mylist1 integers &gt;=0 21 weight | $mylist2 integers &gt;=0 64 length | $mylist2 integers &gt;=0 47 trunk | $mylist2 integers &gt;=0 18 weight | $mylist3 integers &gt;=0 64 length | $mylist3 integers &gt;=0 47 trunk | $mylist3 integers &gt;=0 18 gear_ratio | $mylist3 noninteger weight | $mylist4 integers &gt;=0 64 length | $mylist4 integers &gt;=0 47 trunk | $mylist4 integers &gt;=0 18 -------------------------------------------------- Instead of adding (or removing) single variables at a time, we can instead add or remove lists. Keeping with the comment above, you do not use $ here to refer to the list. . vl create mylist5 = mylist2 - mylist1 note: $mylist5 initialized with 2 variables. . vl list mylist5 ------------------------------------------------ Variable | Macro Values Levels ---------+-------------------------------------- length | $mylist5 integers &gt;=0 47 trunk | $mylist5 integers &gt;=0 18 ------------------------------------------------ However, if we want to simply modify an existing list, a better approach would be the vl modify command. vl create and vl modify are similar to generate and replace; the former creates a new variable list while the later changes an existing variable list, but the syntax right of the = is the same. . vl modify mylist3 = mylist3 + (headroom) note: 1 variable added to $mylist3. . vl modify mylist3 = mylist3 - (weight) note: 1 variable removed from $mylist3. 6.2.4 Dropping variable list Variable lists can be dropped via vl drop . vl dir, user ------------------------------------------------------------------------------- | Macro's contents |------------------------------------------------------------ Macro | # Vars Description ------------------+------------------------------------------------------------ User | $mylist1 | 2 Related to gas consumption $mylist2 | 3 Related to size $mylist3 | 4 variables $mylist4 | 3 variables $mylist5 | 2 variables ------------------------------------------------------------------------------- . vl drop mylist4 mylist5 . vl dir, user ------------------------------------------------------------------------------- | Macro's contents |------------------------------------------------------------ Macro | # Vars Description ------------------+------------------------------------------------------------ User | $mylist1 | 2 Related to gas consumption $mylist2 | 3 Related to size $mylist3 | 4 variables ------------------------------------------------------------------------------- System lists cannot be dropped; if you run vl drop vlcontinuous it just removes all the variables from it. 6.2.5 Using Variable Lists To be explicit, we can use variable lists in any command which would take the variables in that list. For example, . describe $mylist3 Variable Storage Display Value name type format label Variable label ------------------------------------------------------------------------------- length int %8.0g Length (in.) trunk int %8.0g Trunk space (cu. ft.) gear_ratio float %6.2f Gear ratio headroom float %6.1f Headroom (in.) . describe $vlcategorical Variable Storage Display Value name type format label Variable label ------------------------------------------------------------------------------- rep78 int %8.0g Repair record 1978 We can also use them in a modeling setting. . regress mpg $mylist3 Source | SS df MS Number of obs = 74 -------------+---------------------------------- F(4, 69) = 30.77 Model | 1565.65298 4 391.413244 Prob &gt; F = 0.0000 Residual | 877.806484 69 12.7218331 R-squared = 0.6408 -------------+---------------------------------- Adj R-squared = 0.6199 Total | 2443.45946 73 33.4720474 Root MSE = 3.5668 ------------------------------------------------------------------------------ mpg | Coefficient Std. err. t P&gt;|t| [95% conf. interval] -------------+---------------------------------------------------------------- length | -.1837962 .0327629 -5.61 0.000 -.2491564 -.1184361 trunk | -.0103867 .1627025 -0.06 0.949 -.3349693 .3141959 gear_ratio | 1.526952 1.27546 1.20 0.235 -1.017521 4.071426 headroom | .0136375 .6602514 0.02 0.984 -1.303528 1.330803 _cons | 51.33708 8.300888 6.18 0.000 34.77727 67.8969 ------------------------------------------------------------------------------ However, we’ll run into an issue here - how to specify categorical variables or interactions? The vl substitute command creates “factor-variable lists” that can include factor variable indicators (i.), continuous variable indicators (c.), and interactions (# or ##). (The name “factor-variable list” is slightly disingenuous; you could create a “factor-variable list” that includes no actual factors, for example, if you wanted to interact two continuous variables.) Creating a factor-varible list via vl substitute can be done by specifying variables or variable lists. . vl substitute sublist1 = mpg mylist3 . display &quot;$sublist1&quot; mpg length trunk gear_ratio headroom . vl dir ------------------------------------------------------------------------------- | Macro's contents |------------------------------------------------------------ Macro | # Vars Description ------------------+------------------------------------------------------------ System | $vldummy | 1 0/1 variable $vlcategorical | 1 categorical variable $vlcontinuous | 9 continuous variables $vluncertain | 0 perhaps continuous, perhaps categorical variables $vlother | 0 all missing or constant variables User | $mylist1 | 2 Related to gas consumption $mylist2 | 3 Related to size $mylist3 | 4 variables $sublist1 | factor-variable list ------------------------------------------------------------------------------- Note the use of display \"$listname\" instead of vl list. Factor-variable lists are not just lists of vairables, they also can include the features above, so must be displayed. Note that in the vl dir, “sublist1” has no number of variables listed, making it stand apart. We can make this more interesting by actually including continuous/factor indicatores and/or interactions. . vl substitute sublist2 = c.mylist1##i.vldummy . display &quot;$sublist2&quot; weight mpg i.foreign i.foreign#c.weight i.foreign#c.mpg Note the need to specify that mylist1 is continuous (with c.). It follows the normal convention that Stata assumes predictors in a model are continuous by default, unless they’re invloved in an interaction, in which case it assumes they are factors by default. . regress price $sublist2 Source | SS df MS Number of obs = 74 -------------+---------------------------------- F(5, 68) = 16.82 Model | 351163805 5 70232760.9 Prob &gt; F = 0.0000 Residual | 283901591 68 4175023.4 R-squared = 0.5530 -------------+---------------------------------- Adj R-squared = 0.5201 Total | 635065396 73 8699525.97 Root MSE = 2043.3 ------------------------------------------------------------------------------ price | Coefficient Std. err. t P&gt;|t| [95% conf. interval] -------------+---------------------------------------------------------------- weight | 4.415037 .8529259 5.18 0.000 2.71305 6.117024 mpg | 237.691 125.0383 1.90 0.062 -11.81907 487.201 | foreign | Foreign | 8219.603 7265.713 1.13 0.262 -6278.902 22718.11 | foreign#| c.weight | Foreign | .7408054 1.647504 0.45 0.654 -2.546738 4.028348 | foreign#| c.mpg | Foreign | -257.4683 155.426 -1.66 0.102 -567.616 52.67938 | _cons | -13285.44 5149.648 -2.58 0.012 -23561.41 -3009.481 ------------------------------------------------------------------------------ 6.2.5.1 Updating factor-variable Lists Factor-variable lists cannot be directly modified. . display &quot;$sublist1&quot; mpg length trunk gear_ratio headroom . vl modify sublist1 = sublist1 - mpg sublist1 not allowed vlusernames containing factor variables not allowed in this context r(198); However, if you create a factor-variable list using only other variable lists, if those lists get updated, so does the factor-variable list! . vl create continuous = (turn trunk) note: $continuous initialized with 2 variables. . vl create categorical = (rep78 foreign) note: $categorical initialized with 2 variables. . vl substitute predictors = c.continuous##i.categorical . display &quot;$predictors&quot; turn trunk i.rep78 i.foreign i.rep78#c.turn i.foreign#c.turn i.rep78#c.trunk i. &gt; foreign#c.trunk . vl modify continuous = continuous - (trunk) note: 1 variable removed from $continuous. . quiet vl rebuild . display &quot;$predictors&quot; turn i.rep78 i.foreign i.rep78#c.turn i.foreign#c.turn Note the call to vl rebuild. Among other things, it will re-generate the factor-variable lists. (It produces a vl dir output without an option to suppress it, hence the use of quiet.) 6.2.6 Stored Statistics You may have noticed that certain characteristics of the variable are reported. . vl list mylist3 -------------------------------------------------- Variable | Macro Values Levels -----------+-------------------------------------- headroom | $mylist3 noninteger trunk | $mylist3 integers &gt;=0 18 length | $mylist3 integers &gt;=0 47 gear_ratio | $mylist3 noninteger -------------------------------------------------- This reports some characteristics of the variables (integer, whether it’s non-negative) and the number of unique values. We can also see some other statistics: . vl list mylist3, min max obs ------------------------------------------------------------------------------- Variable | Macro Values Levels Min Max Obs ---------+--------------------------------------------------------------------- headroom | $mylist3 noninteger 1.5 5 74 trunk | $mylist3 integers &gt;=0 18 5 23 74 length | $mylist3 integers &gt;=0 47 142 233 74 gear_r~o | $mylist3 noninteger 2.19 3.89 74 ------------------------------------------------------------------------------- This is similar to codebook except faster; these characteristics are saved at the time the variable list is created or modified and not updated automatically. If the data changes, this does not get updated. . drop if weight &lt; 3000 (35 observations deleted) . summarize weight Variable | Obs Mean Std. dev. Min Max -------------+--------------------------------------------------------- weight | 39 3653.846 423.5788 3170 4840 . vl list (weight), min max obs ------------------------------------------------------------------------------- Variable | Macro Values Levels Min Max Obs ---------+--------------------------------------------------------------------- weight | $vlcontinuous integers &gt;=0 64 1760 4840 74 weight | $mylist1 integers &gt;=0 64 1760 4840 74 weight | $mylist2 integers &gt;=0 64 1760 4840 74 ------------------------------------------------------------------------------- To re-generate these stored statistics, we call vl set again, with the update option. . vl set, update ------------------------------------------------------------------------------- | Macro's contents |------------------------------------------------------------ Macro | # Vars Description ------------------+------------------------------------------------------------ System | $vldummy | 1 0/1 variable $vlcategorical | 1 categorical variable $vlcontinuous | 9 continuous variables $vluncertain | 0 perhaps continuous, perhaps categorical variables $vlother | 0 all missing or constant variables ------------------------------------------------------------------------------- . vl list (weight), min max obs ------------------------------------------------------------------------------- Variable | Macro Values Levels Min Max Obs ---------+--------------------------------------------------------------------- weight | $vlcontinuous integers &gt;=0 34 3170 4840 39 weight | $mylist1 integers &gt;=0 34 3170 4840 39 weight | $mylist2 integers &gt;=0 34 3170 4840 39 ------------------------------------------------------------------------------- When the update option is passed, variable lists are not affected, only stored statistics are updated. 6.3 Linking data sets In addition to allowing multiple data sets to be open at a time, we can link frames together such that rows of data in each frames are connected to each-other and can inter-operate. This requires a linking variable in each data set which will connect the rows. The two data sets can be at the same levels or at different levels. For example, we might have data sets collected from multiple waves of surveys and follow-ups during which the same people (modulo some non-responses) are contained in each data set. Then the person ID variable in the data sets would be the linking variable. Another example might be one file at the person level, and another file at the city level. The linking variable would be city name, which would be unique in the city file, but could potentially be repeated in the person level file. The command to link files is frlink and requires specifying both the linking variable(s) and the frame to link to. frlink 1:1 linkvar, frame(otherframe) Let’s load some data from NHANES. Each file contains a row per subject. . frame reset . frame rename default demographics . frame create diet . frame create bp . . import sasxport5 &quot;https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/DEMO_I.XPT&quot;, cle &gt; ar . frame diet: import sasxport5 &quot;https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/DR1T &gt; OT_I.XPT&quot;, clear . frame bp: import sasxport5 &quot;https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/BPX_I. &gt; XPT&quot;, clear . frame dir * bp 9544 x 21 * demographics 9971 x 47 * diet 9544 x 168 Note: Frames marked with * contain unsaved data. So as you can see, the current frame is the “demographics” frame, and the other frames contains diet and blood pressure information. The variable seqn records person ID. . frlink 1:1 seqn, frame(bp) (427 observations in frame demographics unmatched) . frlink 1:1 seqn, frame(diet) (427 observations in frame demographics unmatched) The 1:1 subcommand specifies that it is a 1-to-1 link - each person has no more than 1 row of data in each file. An alternative is m:1 which allows multiple rows in the main file to be linked to a single row in the second frame. 1:m is not allowed at this point in time. These commands created two new variables bp and diet (the same new as the linked frames) which indicate which row of the linked from is connected with the given row. . list bp diet in 25/29 +-----------+ | bp diet | |-----------| 25. | 25 25 | 26. | 26 26 | 27. | . . | 28. | 27 27 | 29. | 28 28 | +-----------+ Here we see that row 27 in the demographics file was not found in either “bp” or “diet” and thus has no entry in the bp or diet variables. Links are tracked by the variables, we can see the current status of a link via frlink describe: . frlink describe diet History: ----------------------------------------------------------------------------- Link variable diet created on 2 Feb 2023 by . frlink 1:1 seqn, frame(diet) Frame diet contained an unnamed dataset ----------------------------------------------------------------------------- Verifying linkage ... Linkage is up to date. We can see all links from the current frame via frlink dir: . frlink dir (2 frlink variables found) ----------------------------------------------------------------------------- bp created by frlink 1:1 seqn, frame(bp) ----------------------------------------------------------------------------- diet created by frlink 1:1 seqn, frame(diet) ----------------------------------------------------------------------------- Note: Type &quot;frlink describe varname&quot; to find out more, including whether the variable is still valid. To unlink frames, simply drop the variable. . drop diet Finally, the names of the created variables can be modified via the generate option to frlink: . frlink 1:1 seqn, frame(diet) generate(linkdiet) (427 observations in frame demographics unmatched) . frlink dir (2 frlink variables found) ----------------------------------------------------------------------------- bp created by frlink 1:1 seqn, frame(bp) ----------------------------------------------------------------------------- linkdiet created by frlink 1:1 seqn, frame(diet) generate(linkdiet) ----------------------------------------------------------------------------- Note: Type &quot;frlink describe varname&quot; to find out more, including whether the variable is still valid. 6.3.1 Working with linked frames Once we have linked frames, we can use variables in the linked frame in analyses on the main frame. The frget command can copy variables from the linked frame into the primary frame. . summarize bpxchr variable bpxchr not found r(111); . frget bpxchr, from(bp) (8,033 missing values generated) (1 variable copied from linked frame) . summarize bpxchr Variable | Obs Mean Std. dev. Min Max -------------+--------------------------------------------------------- bpxchr | 1,938 106.5614 21.75754 58 190 This merges appropriately, with a 1:1 or m:1 link, to properly associate the values of the variable with the right observations. Alternatively, when using generate, we can reference a variable in another frame. . gen nonsense = frval(linkdiet, dr1tcalc)/frval(bp, bpxpls) + dmdhrage (3,158 missing values generated) Note that this calculation used variables from all three frames. A less nonsensical example might be where we want the percent of a countries population located in a given state. Imagine we have the primary frame of county data, and then a separate frame “state” containing state level information. gen percentpopulation = population/frval(state, population) 6.4 Loops Using macros can simplify code if you have to use the same string repeatedly, but what if you want to perform the same command repeatedly with different variables? Here we can use a foreach loop. This is easiest to see with examples. . sysuse pop2000, clear (2000 U.S. Census population by age and sex) The “pop2000” data contains data from the 2000 census, broken down by age and gender. The values are in total counts, lets say instead we want percentages by gender. For example, what percentage of Asians in age 25-29 are male? We could generate this manually. . gen maletotalperc = maletotal/total . gen femtotalperc = femtotal/total . gen malewhiteperc = malewhite/white This gets tedious fast as we need a total of 12 lines! Notice, however, that each line has a predictable pattern: gen &lt;gender&gt;&lt;race&gt;perc = &lt;gender&gt;&lt;race&gt;/&lt;race&gt; We can exploit this by creating a foreach loop over the racial categories and only needing a single command. . drop *perc . foreach race of varlist total-island { 2. gen male`race'perc = male`race'/`race' 3. gen fem`race'perc = fem`race'/`race' 4. } . list *perc in 1, ab(100) +---------------------------------------------------------------+ 1. | maletotalperc | femtotalperc | malewhiteperc | femwhiteperc | | .5116206 | .4883794 | .5130497 | .4869503 | |---------------+--------------+----------------+---------------| | maleblackperc | femblackperc | maleindianperc | femindianperc | | .5078017 | .4921983 | .5100116 | .4899884 | |---------------+--------------+----------------+---------------| | maleasianperc | femasianperc | maleislandperc | femislandperc | | .5029027 | .4970973 | .5167261 | .4832739 | +---------------------------------------------------------------+ Let’s breakdown each piece of the command. The command syntax for foreach is foreach &lt;new macroname&gt; of varlist &lt;list of variables&gt; The loop will create a macro that you name (in the example above, it was named “race”), and repeatedly set it to each subsequent entry in the list of variables. So in the code above, first “race” is set to “total”, then the two gen commands are run. Next, “race” is set to “white”, then the two commands are run. Etc. Within each of the gen commands, we use the backtick-quote notation just like with macros. Finally, we end the foreach line with an open curly brace, {, and the line after the last command within the loop has the matching close curly brace, }. We can also nest these loops. Notice that both gen statements above are identical except for “male” vs “fem”. Let’s put an internal loop: . drop *perc . foreach race of varlist total-island { 2. foreach gender in male fem { 3. gen `gender'`race'perc = `gender'`race'/`race' 4. } 5. } . list *perc in 1, ab(100) +---------------------------------------------------------------+ 1. | maletotalperc | femtotalperc | malewhiteperc | femwhiteperc | | .5116206 | .4883794 | .5130497 | .4869503 | |---------------+--------------+----------------+---------------| | maleblackperc | femblackperc | maleindianperc | femindianperc | | .5078017 | .4921983 | .5100116 | .4899884 | |---------------+--------------+----------------+---------------| | maleasianperc | femasianperc | maleislandperc | femislandperc | | .5029027 | .4970973 | .5167261 | .4832739 | +---------------------------------------------------------------+ Each time “race” gets set to a new variable, we enter another loop where “gender” gets set first to “male” then to “fem”. To help visualize it, here is what “race” and “gender” are set to each time the gen command is run: gen command “race” “gender” 1 total male 2 total fem 3 white male 4 white fem 5 black male 6 black fem 7 indian male 8 indian fem 9 asian male 10 asian fem 11 island male 12 island fem Notice the syntax of the above two foreach differs slightly: foreach &lt;macro name&gt; of varlist &lt;variables&gt; foreach &lt;macro name&gt; in &lt;list of strings&gt; It’s a bit annoying, but Stata handles the “of” and “in” slight differently. The “in” treats any strings on the right as strict. Meaning if the above loop over race were foreach race in total-island then Stata would set “race” to “total-island” and the gen command would run once! By using “of varlist”, you are telling Stata that before it sets “race” to anything, expand the varlist using the rules such as * and -. There is also foreach &lt;macro name&gt; of numlist &lt;list of numbers&gt; The benefit of “of numlist” is that numlists support things like 1/4 representing 1, 2, 3, 4. So foreach num of numlist 1 3/5 Loops over 1, 3, 4, 5, whereas foreach num in 1 3/5 loops over just “1” and “3/5”. The use of “in” is for when you need to loop over strings that are neither numbers nor variables (such as “male” and “fem” from above). 6.5 Suppressing output and errors There are two useful command prefixes that can be handy while writing more elaborate Do-files. 6.5.1 Capturing an error Imagine the following scenario. You want to write a Do-file that generates a new variable. However, you may need to re-run chunks of the Do-file repeatedly, so that the gen statement is hit repeatedly. After the first gen, we can’t call it again and need to use replace instead. However, if we used replace, it wouldn’t work the first time! One solution is to drop the variable before we gen it: . sysuse auto, clear (1978 automobile data) . drop newvar variable newvar not found r(111); . gen newvar = 1 That error, while not breaking the code, is awfully annoying! However, if we prefix it by capture, the error (and all output from the command) are “captured” and hidden. . list price in 1/5 +-------+ | price | |-------| 1. | 4,099 | 2. | 4,749 | 3. | 3,799 | 4. | 4,816 | 5. | 7,827 | +-------+ . capture list price in 1/5 . list abcd variable abcd not found r(111); . capture list abcd Therefore, the best way to generate our new variable is . capture drop newvar . gen newvar = 1 6.5.1.1 Return Code When you capture a command that errors, Stata saves the error code in the _rc macro. . list abc variable abc not found r(111); . capture list abc . display _rc 111 If the command does not error, _rc contains 0. . capture list price . display _rc 0 This can be used to offer additional code if an error occurs capture &lt;code that runs without error if something is true, but errors otherwise&gt; if _rc &gt; 0 { ... } If the code inside the capture runs without error, the if block will run. If the code inside the capture errors, the else block will run. Say you wanted to rename a variable if it exists, and if doesn’t exist, create it. (For example, you have to process a large number of files, and in some files, this variable may be missing for all rows and thus not reported.) You could run the following: capture rename oldvar newvar if _rc &gt; 0 { gen newvar = . } 6.5.2 Quieting the output quietly does the same basic thing as capture, except it does not hide errors. It can be useful combined with the returns: . quietly summ price . display r(mean) 6165.2568 This will come in very handy when you start running statistical models, where the output can be over a single screen, whereas you only want a small piece of it. Just to make the difference between capture and quietly clear: . list price in 1/5 +-------+ | price | |-------| 1. | 4,099 | 2. | 4,749 | 3. | 3,799 | 4. | 4,816 | 5. | 7,827 | +-------+ . quietly list price in 1/5 . capture list price in 1/5 . list abcd in 1/5 variable abcd not found r(111); . quietly list abcd in 1/5 variable abcd not found r(111); . capture list abcd in 1/5 With a command that doesn’t error (listing price), both quietly and capture perform the same. However, with a command that does error, quietly still errors, whereas capture just ignores it! “Local” as opposed to “global”, a distinction which is not important until you get deep into programming. For now, local is the safer option.↩︎ There are obviously other ways to compute this, but this gives a flavor of the use.↩︎ My guess is that nonotes will become the default in a version or 2, once users become used to vl.↩︎ "],["appendix.html", "Chapter 7 Appendix 7.1 Solutions", " Chapter 7 Appendix 7.1 Solutions 7.1.1 Exercise 1 Solution Exercise 1 1: sysuse lifeexp 3: sysuse sandstone, clear or clear sysuse sandstone 4: If the working directory isn’t convenient, change it using the dialogue box. Then, save sandstone. 7.1.2 Exercise 2 Solution Exercise 2 1: webuse census9, clear 2: Data is from the 1980 census, which we can see by the label (visible in describe, simple). We’ve got two identifiers of state, death rate, population, median age and census region. 3: Since there data has 50 rows, it’s a good guess there are no missing sates. 4: Looking at describe, we see that the two state identifiers are strings, the rest numeric. 5: compress. Nothing saved! Because Stata already did it before posting it! 7.1.3 Exercise 3 Solution Exercise 3 1: . webuse census9, clear (1980 Census data by state) . save mycensus9 file mycensus9.dta saved 2: . rename drate deathrate . label variable deathrate &quot;Death rate per 10,000&quot; 3: . tab region Census | region | Freq. Percent Cum. ------------+----------------------------------- NE | 9 18.00 18.00 N Cntrl | 12 24.00 42.00 South | 16 32.00 74.00 West | 13 26.00 100.00 ------------+----------------------------------- Total | 50 100.00 . label list cenreg cenreg: 1 NE 2 N Cntrl 3 South 4 West . label define region_label 1 &quot;Northeast&quot; 2 &quot;North Central&quot; 3 &quot;South&quot; 4 &quot;West&quot; . label values region region_label . label drop cenreg . label list region_label: 1 Northeast 2 North Central 3 South 4 West . tab region Census region | Freq. Percent Cum. --------------+----------------------------------- Northeast | 9 18.00 18.00 North Central | 12 24.00 42.00 South | 16 32.00 74.00 West | 13 26.00 100.00 --------------+----------------------------------- Total | 50 100.00 4: . save, replace file mycensus9.dta saved 7.1.4 Exercise 4 Solution Exercise 4 1: Use summarize and codebook to take a look at the mean/max/min. No errors detected/ 2: . codebook, compact Variable Obs Unique Mean Min Max Label ------------------------------------------------------------------------------- state 50 50 . . . State state2 50 50 . . . Two-letter state abbreviation deathrate 50 30 84.3 40 107 Death rate per 10,000 pop 50 50 4518149 401851 2.37e+07 Population medage 50 37 29.54 24.2 34.7 Median age region 50 4 2.66 1 4 Census region ------------------------------------------------------------------------------- deathrate and medage both have less than 50 unique values. This is due to both being heavily rounded. If we saw more precision, there would be more unique entires. 3: . codebook, problems Potential problems in dataset mycensus9.dta Potential problem Variables -------------------------------------------------- string vars with embedded blanks state -------------------------------------------------- This just flags spaces (\" \") in the data. Not a real problem! 7.1.5 Exercise 5 Solution Exercise 5 1: . gen deathperc = deathrate/10000 . label variable deathperc &quot;Percentage of population deceeased in 1980&quot; . list death* in 1/5 +---------------------+ | deathr~e deathp~c | |---------------------| 1. | 91 .0091 | 2. | 40 .004 | 3. | 78 .0078 | 4. | 99 .0099 | 5. | 79 .0079 | +---------------------+ 2: . gen agecat = 1 if medage &lt; . . replace agecat = 2 if medage &gt; 26.2 &amp; medage &lt;= 30.1 (30 real changes made) . replace agecat = 3 if medage &gt; 30.1 &amp; medage &lt;= 32.8 (17 real changes made) . replace agecat = 4 if medage &gt; 32.8 (1 real change made) . label define agecat_label 1 &quot;Significantly below national average&quot; /// &gt; 2 &quot;Below national average&quot; /// &gt; 3 &quot;Above national average&quot; /// &gt; 4 &quot;Significantly above national average&quot; . label values agecat agecat_label . tab agecat, mi agecat | Freq. Percent Cum. -------------------------------------+----------------------------------- Significantly below national average | 2 4.00 4.00 Below national average | 30 60.00 64.00 Above national average | 17 34.00 98.00 Significantly above national average | 1 2.00 100.00 -------------------------------------+----------------------------------- Total | 50 100.00 We have no missing data (seen with summarize and codebook in the previous exercise) but it’s good practice to check for them anyways. 3: . bysort agecat: summarize deathrate ------------------------------------------------------------------------------- -&gt; agecat = Significantly below national average Variable | Obs Mean Std. dev. Min Max -------------+--------------------------------------------------------- deathrate | 2 47.5 10.6066 40 55 ------------------------------------------------------------------------------- -&gt; agecat = Below national average Variable | Obs Mean Std. dev. Min Max -------------+--------------------------------------------------------- deathrate | 30 81.76667 9.761583 50 94 ------------------------------------------------------------------------------- -&gt; agecat = Above national average Variable | Obs Mean Std. dev. Min Max -------------+--------------------------------------------------------- deathrate | 17 91.76471 8.422659 73 104 ------------------------------------------------------------------------------- -&gt; agecat = Significantly above national average Variable | Obs Mean Std. dev. Min Max -------------+--------------------------------------------------------- deathrate | 1 107 . 107 107 We see that the groups with the higher median age tend to have higher deathrates. 4: . preserve . gsort -deathrate . list state deathrate in 1 +--------------------+ | state deathr~e | |--------------------| 1. | Florida 107 | +--------------------+ . gsort +deathrate . list state deathrate in 1 +-------------------+ | state deathr~e | |-------------------| 1. | Alaska 40 | +-------------------+ . gsort -medage . list state medage in 1 +------------------+ | state medage | |------------------| 1. | Florida 34.70 | +------------------+ . gsort +medage . list state medage in 1 +----------------+ | state medage | |----------------| 1. | Utah 24.20 | +----------------+ . restore 5: . encode state2, gen(statecodes) . codebook statecodes ------------------------------------------------------------------------------- statecodes Two-letter state abbreviation ------------------------------------------------------------------------------- Type: Numeric (long) Label: statecodes Range: [1,50] Units: 1 Unique values: 50 Missing .: 0/50 Examples: 10 GA 20 MD 30 NH 40 SC "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
