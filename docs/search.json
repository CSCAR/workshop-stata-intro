[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to Stata",
    "section": "",
    "text": "Preface\nThese notes are split into four primary sections:\nThese sections will generally be presented in sequence. The discussion will alternate between theory and practice. The format will alternate between lecture and exercises. Please ask questions as soon as they arise in your mind. Please provide feedback or voice concerns.\nThere are two additional sections:"
  },
  {
    "objectID": "index.html#creation-of-this-document",
    "href": "index.html#creation-of-this-document",
    "title": "Introduction to Stata",
    "section": "Creation of this document",
    "text": "Creation of this document\nThese notes are published using Quarto. The Stata code is first rendered using a Stata dynamic document. The source code for these notes can be found at https://github.com/CSCAR/workshop-stata-intro for the curious.\nAll images should link to full-size versions to see detail if needed."
  },
  {
    "objectID": "index.html#contact-information",
    "href": "index.html#contact-information",
    "title": "Introduction to Stata",
    "section": "Contact information",
    "text": "Contact information\n\nCSCAR\nhttp://cscar.research.umich.edu/\nCSCAR is available for free consultations with PhD statisticians (email deskpeople@umich.edu to request a consultation).\nCSCAR also has GSRAs available for more immediate help. Walk-ins to our office in Rackham are welcomed Monday-Friday 9am to 5pm (Closed Tuesdays 12-1pm). Alternatively, on our website, you can self-schedule into an hour consultation with the graduate students, which can be either remote or in-person (these are usually available same-day or next-day).\nCSCAR operates a email for help with statistical questions, feel free to send concise questions to stats-consulting@umich.edu.\nThe current contact for questions about the notes: Josh Errickson (jerrick@umich.edu)."
  },
  {
    "objectID": "index.html#acknowledgments",
    "href": "index.html#acknowledgments",
    "title": "Introduction to Stata",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nThese notes have evolved over the years thanks to many CSCAR statisticians, including Josh Errickson, Giselle Kolenic, Brady West, Heidi Reichert, and Lingling Zhang.\nThis material was created for use in workshops and short courses presented by faculty and staff from the Consulting for Statistics, Computing & Analytics Research (CSCAR) at the University of Michigan. No part of this material may be used for other purposes, copied, changed, or sold."
  },
  {
    "objectID": "01-the-basics-of-stata.html#the-stata-environment",
    "href": "01-the-basics-of-stata.html#the-stata-environment",
    "title": "1  The Basics of Stata",
    "section": "1.1 The Stata Environment",
    "text": "1.1 The Stata Environment\n\n\n\n\n\nWhen a user first opens Stata, there are five panes that will appear in the main window:\n\nThe Results Pane\n\nAll commands which are run are echoed out here, as well as any output they produce. Not all commands produce output though most do (e.g. obtaining summaries of the data or running a statistical procedure). Items that appear in the results pane in blue are clickable.\n\nThe Command Pane\n\nThis pane is where users can interactively type Stata commands and submit them to Stata for processing. Everything that one can do in Stata is based on a set of Stata commands. Stata commands are case sensitive. All Stata commands and options are in lower case. When variables are used in any command, the variable names are also case sensitive.\n\nThe Variables Pane\n\nThis pane displays all of the variables in the data set that is currently open in Stata, and users can click on variable names in this pane to carry the variables over into Stata commands in the Command pane. Note that Stata allows only one data-set to be open in a session.\n\nThe History Pane\n\nStata will keep a running record of all Stata commands that have been submitted in the current session in this pane. Users can simply click on previous commands in this pane to recall them in the Command pane.\n\nThe Properties Pane\n\nThis pane allows variable properties and data-set properties to be managed. Variable names, labels, value labels, display formats, and storage types can be viewed and modified here.\n\n\nEach of these five panes will be nested within the main Stata session, which contains menus and tool bars. There are additional windows that users can access from the Window menu, which include the Graph window (which will open when graphs have been created), the Viewer window (which is primarily used for help features and Stata news), the Data Editor window (for use when viewing data sets), and the Do-file Editor window (for use when writing .do files).\nIn the lower left-hand corner of the main Stata window (below the panes), there will be a directory displayed. This is known as the working directory, and is where Stata will look to find data files and other associated Stata files unless the user specifies another directory. We will cover examples of changing the working directory.\n\n1.1.1 Alternate Layout\n\n\n\n\n\nAn alternate layout (found in View -&gt; Layout) places the History and Variables pane in tabs on the right hand side instead.\n(Note that this screenshot is taken on a Mac, as opposed to the original screenshot on Windows, just for comparison.)"
  },
  {
    "objectID": "01-the-basics-of-stata.html#one-data",
    "href": "01-the-basics-of-stata.html#one-data",
    "title": "1  The Basics of Stata",
    "section": "1.2 One Data",
    "text": "1.2 One Data\nOne functionality where Stata differs than most other statistical or data analysis software is that Stata can only work with a single data set at a time.\nAny command you run knows to operate on the data set you have open. For example, there is a command summarize which provides summary information about variables. The command is simply summarize, there is no need to direct it towards a specific data set.\nIf you have multiple data sets you need to work with, you can either\n\nSwitch between the two data sets as needed. This can be burdensome, though tools such as preserve or frames help greatly.\nMerge the data sets, the better option. We’ll discuss merging towards the end of the course."
  },
  {
    "objectID": "01-the-basics-of-stata.html#give-stata-a-command",
    "href": "01-the-basics-of-stata.html#give-stata-a-command",
    "title": "1  The Basics of Stata",
    "section": "1.3 Give Stata a command",
    "text": "1.3 Give Stata a command\nLet’s try running a Stata command. In the command pane, type (or copy and paste) the following:\nversion\nThe following should appear in the Results pane:\n. version\nversion 18.0\nThe first line proceeded by the . indicates the command that was written, version, and the rest is the output. Here, I am running Stata version 18.0 (your version may vary).\nIn this document, if you see a single command without a period, it indicates something that was not run - either it’s not designed to be run (it’s fake code designed to illustrate a point), or more likely, the output is not interesting or unnecessary. If you instead see a Results output where the first line is the command prefaced by the ., that was run in Stata and only the Results are included since they include the command. The command can still be run, but should be run without the .1.\n\n1.3.1 Saving Results\nAny output that appears in the Results pane (including the echoed commands and any errors) can be copied and pasted into another location, such as Word. In addition, if you highlight text and right-click, you also have the options:\n\n“Copy table”: Useful for exporting to Excel. This can be tempermental; if the selected table is less “regular”, this may not produce the best results. It is most useful for text which comes naturally as a table rather than results which are forced into a table for display purposes.\n“Copy table as HTML”: You can paste this into a plaintext editor (Notepad.exe or TextEdit, not Word) and save it as a *.html to produce a webpage. If you paste this into Excel you get a slightly different table than the layout for “Copy table” which may be more useful.\n“Copy as picture”: Does exactly what it says - equivalent to taking a screenshot. Very handy!\n\nThere are a few commands that can be useful for saving results which we will not cover in this workshop, if you are interested, you can look into the help for them.\n\nlog: Saves a file consisting of everything printed to the Results pane.\nputexcel: Adds to a spreadsheet specific strings or output.\noutreg2: A user-written command to output the results of a model (e.g. regression) in a clean format.\n\n\n\n1.3.2 Dynamic Tags\nVersion 15 of Stata introduced dynamic tags and the dyndoc and dyntext commands which allows you to weave together narrative text and Stata code to produce a high-quality output (html, word or pdf). This document is written (in part) in Dynamic Tags. It is extremely powerful but is well outside the mandate of this class. If you are interested in this functionality, I’d be happy to help. This Stata manual is a good introduction."
  },
  {
    "objectID": "01-the-basics-of-stata.html#updating",
    "href": "01-the-basics-of-stata.html#updating",
    "title": "1  The Basics of Stata",
    "section": "1.4 Updating",
    "text": "1.4 Updating\nIf you have administrative access on your computer (e.g. if it is your personal machine, or your IT department has given you the ability), you can update Stata freely. Major point upgrades such as the newly released 18.0 require purchase and re-installation, but minor upgrades (such as the 16.1 and 16.2 updates) as well as minor internal updates are free.\nTo check for updates, you can run\nupdate query\nIf any updates are available (regardless of whether you ran a query first), you can obtain all updates with\nupdate all\nIf you do not have administrative access on your computer, you’ll need to reach out to your IT administrators to update."
  },
  {
    "objectID": "01-the-basics-of-stata.html#installing-user-written-commands",
    "href": "01-the-basics-of-stata.html#installing-user-written-commands",
    "title": "1  The Basics of Stata",
    "section": "1.5 Installing user-written commands",
    "text": "1.5 Installing user-written commands\nIn addition to built in commands, Stata supports user-written programs, know as “ado-files”2. Once installed, these user-written programs operate identically to any built-in command, with the caveat that they may not be quite as polished or complete since they’re volunteer written. Documentation is rarely up to Stata standards and often relegates details to a manuscript.\nWe won’t be covering any ado-files in these notes, but if you wanted to install a program named newcommand:\nssc install newcommand\nYou can remove a program with\nssc uninstall newcommand\nFinally, to see a list of all user-written programs you have installed, used\nado\nUpdating Stata will not update any ado-files, instead you can run\nadoupdate\nto list all available updates and\nadoupdate, update\nto perform all updates."
  },
  {
    "objectID": "01-the-basics-of-stata.html#do-files",
    "href": "01-the-basics-of-stata.html#do-files",
    "title": "1  The Basics of Stata",
    "section": "1.6 Do-files",
    "text": "1.6 Do-files\nWe saw that commands can be typed interactively, one command at a time, and the results immediately observed. From this, the output can be copied/exported/printed, or the results can be saved. However, a better paradigm would save all the commands run separately so that the analysis is reproducible.\nFor this purpose, Stata has Do-files (named because they are saved with the .do extension, such as analysis.do) which are scripts containing only commands and comments. We can then run any subset of the commands (including the entire file), re-running parts or all of the analysis. Additionally you can easily save and/or share this command, allowing yourself or a colleague to re-run the analysis.\nThere are several ways to start a new Do-file.\n\nFile -&gt; New -&gt; Do-file\nClick the “Do-file Editor” button in the main window\nYou can enter the command:\n\ndoedit\n\nIf you select some commands in the History pane, you can right click and choose “Send select to Do-file Editor”.\n\nFor the last option there, note that performing that twice will create two separate Do-files instead of appending the commands. Instead, you can copy and paste from the History pane to add to an existing Do-file.\nLet’s manually add some commands to a Do-file to see how to execute the commands. In a Do-file editor, enter the following\nsysuse auto, clear\nsummarize price\ntabulate foreign\nOnce the lines are in the editor, highlight the commands (you do not need to highlight the entire line, you merely need to ensure your selection includes part of every line you want run) and press the “Execute/Do” (on Windows) or “Do” (on Mac) button. You should see the following appear in your Results pane.\n. sysuse auto, clear\n(1978 automobile data)\n\n. summarize price\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n       price |         74    6165.257    2949.496       3291      15906\n\n. tabulate foreign\n\n Car origin |      Freq.     Percent        Cum.\n------------+-----------------------------------\n   Domestic |         52       70.27       70.27\n    Foreign |         22       29.73      100.00\n------------+-----------------------------------\n      Total |         74      100.00\nWe will cover in later sections what each of these commands does (sysuse, summarize, and tabulate).\n\n1.6.1 Comments\nComments are information in a Do-file which Stata will ignore. They can be used to stop a command from running without deleting it, or more usefully, to add information about the code which may be useful for others (or yourself in the future) to understand how some code works or to justify why you made certain choices. In general, comments can also help readability. There are three different ways to enter comments (and one additional special way).\nFirst, to comment out an entire line, precede it by *:\n. * This is a comment\nSecond, you can add a comment to the end of a line with //\n. version // Returns the Stata version number\nversion 18.0\n\n. // You can also use it to comment out an entire line.\nThere must be a space before the // if it comes after a command:\n. version// Returns the Stata version number\ninvalid syntax\nr(198);\nThirdly, you can comment out a section by wrapping it in /\\* and \\*/\n. /* Here's a several\n&gt; line comment.\n&gt; It just keeps going. */\n. summarize /* comment in the middle of a command! */ price\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n       price |         74    6165.257    2949.496       3291      15906\nNote that when a command wraps to more than one line in the Results pane (either due to a manual line break like this or a command that’s too wide for the Results pane), the prefix changes from . to &gt; to indicate that its all one command.\nFinally, there’s the special comment, ///. Stata commands must be on a single line. However, complicated commands may get very long, such that its hard to read them on a single line. Using /// instead of // allows wrapping onto the next line.\n. summarize ///\n&gt; price\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n       price |         74    6165.257    2949.496       3291      15906\nAs with //, there needs to be a space before the ///.\nOnly the * works on interactive commands entered in the Command pane. All four versions work in Do-files.\n\n\n1.6.2 Version control\nWhen writing a Do-file, you generally are creating it while using a single version of Stata. If a new version of Stata were released, its possible that your code may operate differently with the new version. If you add\nversion 14.2\nto the beginning of your Do-file, Stata will execute the commands as if it were still running version 14.2, even if you’ve updated to Stata 17. This works all the way back to Stata 2. (Obviously, this will not work if you try to run as Stata 17 when you only have Stata 14 installed.)\nNote that this version is the same command as the version we’ve been discussing before. It operates in this special fashion only when included at the top of a Do-file.\nBest practices is to always include a version ##.# line at the top of each Do-file, but if its code that will continue to see use, you should test it with the newer releases and update the code as necessary!"
  },
  {
    "objectID": "01-the-basics-of-stata.html#exercise-0",
    "href": "01-the-basics-of-stata.html#exercise-0",
    "title": "1  The Basics of Stata",
    "section": "1.7 Exercise 0",
    "text": "1.7 Exercise 0\nGet familiar with the Stata interface. If you’ve been following along, you may have already done all these!\n\nIf you haven’t already, open Stata. (You should be able to do this by clicking on the “Start” menu in the bottom left of the screen, then typing “Stata”.)\nThe use of each pane will become much clearer when we start opening data in the next section, but take a look at each.\nGive Stata a command: query memory. This lists some settings related to memory usage in Stata, for example, maxvar is the maximum number of variables in a model; matsize is the largest number of predictors allowed in a model.\nOpen a Do file. Place a version command at the top of the file corresponding to the version on your computer. Place the query memory command from the last step in the Do file.\nBe sure you know how to run these commands from the Do file.\nComment out the query memory command; we won’t need it anymore."
  },
  {
    "objectID": "01-the-basics-of-stata.html#basic-command-syntax",
    "href": "01-the-basics-of-stata.html#basic-command-syntax",
    "title": "1  The Basics of Stata",
    "section": "1.8 Basic command syntax",
    "text": "1.8 Basic command syntax\nMost Stata commands which operate on variables (as opposed to system commands such as version, update, query, etc.) follow the same general format. Recognizing this format will make it easier to understand new commands to which you are introduced.\nThe basic syntax is\ncommand &lt;variable(s)&gt;, &lt;options&gt;\nThe command can take on more than one word; e.g. to create a scatter plot, the command is graph twoway scatter.\nDepending on the command, the list of variables can contain 0 variables, 1 variable, or many variables separated by spaces. Whether the order of variables matters depends on the specific command.\nAbove, in the do-file, we ran three lines of code. The first, sysuse auto, is a system command that we’ll discuss later.\nThe second and third lines, summarize price mpg and tabulate foreign, follow the basic syntax - “summarize” and “tabulate” are the commands. “summarize” is operating on two variables, “price” and “mpg”; the order in which the variables appear in the command controls the order in which they appear in the table. “tabulate” is operating on a single variable, creating a one-way table; putting a second variable transforms it into a two-way table.\nThe options are not required (none of the above commands have options), but if they are given, they too are separated by spaces. There are some options that are consistent across a number of commands, and some options are specific to commands."
  },
  {
    "objectID": "01-the-basics-of-stata.html#stata-help",
    "href": "01-the-basics-of-stata.html#stata-help",
    "title": "1  The Basics of Stata",
    "section": "1.9 Stata Help",
    "text": "1.9 Stata Help\nStata has, hands down, the best built-in help files of any of the “Big 4” statistical software.3 Stata’s help should be your first stop for any of the following:\n\nUnderstanding the syntax of a command\nExploring the options available for a given command\nLooking at examples of the command in use\nUnderstanding the theoretical statistics behind the command.\n\nHelp can be accessed by calling help &lt;command&gt;, such as\nhelp summarize\nEach help page has numerous features, I will merely point out a few here.\n\nThe “Title” section contains a link (in blue) to a PDF which contains the Manual, which has more detail and examples than the help file alone.\nThe syntax section shows the basic syntax. Any part written in square brackets ([...]) are optional.\nThe examples in the help are great but basic; the PDF help (see #1) usually has more detailed examples.\nWe will discuss the “Stored results” in the [Programming][programming] section.\n\nhelp can also be used to search for the appropriate command. For example, if you wanted help merging some data together (which we will cover [later][merging files]), you might try running\nhelp merging\nmerging is not a valid Stata command, so instead Stata performs a search of the help files. This search is often not great. I would recommend searching online for the appropriate command to use (just search “Stata” and what you are trying to do), then using the built-in help for details on using the command.\nFinally, help help works and brings up some more information on the help command.\n\n1.9.1 Short commands\nYou’ll frequently see commands with partial underlining; for example summarize has the “su” underlined. Only the underlined part needs to be given for Stata to understand the command; e.g. the following are all equivalent:\nsummarize\nsumm\nsu\nThis is often true for options as well; detail (to report far more summary details) has the “d” underlined. So these are equivalent:\nsummarize, detail\nsu, detail\nsummarize, d\nsu, d\nThe short commands are very useful for quickly writing commands, but not so great at reading them. If you came across someone else’s Stata Do-file and saw su, d, you might have trouble figuring that out unless you already knew that short command. Thankfully, the short commands can be used with help, so help su will bring up the full summarize documentation."
  },
  {
    "objectID": "01-the-basics-of-stata.html#working-directory",
    "href": "01-the-basics-of-stata.html#working-directory",
    "title": "1  The Basics of Stata",
    "section": "1.10 Working directory",
    "text": "1.10 Working directory\nWe mentioned earlier the notion of a “working directory”, the current one you can see in the bottom left of the Stata window. You can think of a working directory as an open folder inside Windows Explorer (or Finder if you’re on a Mac). You can easily access any file within that folder without any additional trouble. You can access files in other folders (directories), but it requires moving to that folder.\nIn the same sense, when referring to files, any file in the working directory can be referred to buy its name. For example, to open a file (we’ll go into detail about doing this later) named “mydata.dta” which is in your current working directory, you need only enter\nuse mydata.dta\n(Technically you could just run use mydata as Stata will search for a file with the appropriate “.dta” extension automatically.)\nIf you were in a different working directory, you need to specify the full path to the file:\nuse C:\\Documents\\Stata\\Project\\mydata.dta\nSimilarly, when saving files, the working directory is the default choice.\nIf your file path has any spaces, you must wrap it in quotations:\nuse \"C:\\Documents\\Stata\\My Project\\mydata.dta\"\nThe working directory can be viewed with the pwd command (Print Working Directory)\n. pwd\nC:\\Documents\nYou can change the working directory by passing a path to cd (Change Directory):\ncd C:\\Documents\\Stata\\Project\nAlternatively and perhaps more easily, you can change the working directory by the menus, choosing “Files -&gt; Change working directory”. After selecting the appropriate directory, the full cd command will be printed in the Results, so you can save it in a Do-file for later use.\n\n1.10.1 File paths\nThere are some distinctions between Windows and Mac in regards to file paths, the most blatant that Windows uses forward slash (\\\\) whereas Mac uses back slashes (\\/). You can see full details of this by running help filename."
  },
  {
    "objectID": "01-the-basics-of-stata.html#footnotes",
    "href": "01-the-basics-of-stata.html#footnotes",
    "title": "1  The Basics of Stata",
    "section": "",
    "text": "Stata can handle commands that are prefaced by . (with a space between the period and comand) so you can copy/paste the . version and run it as is. However, don’t get used to that habit! The correct command is just version.↩︎\nAs we’ll see in a bit, you can save Stata commands in a “do-file”. While I’ve never seen an official definition, I tend to think of “ado” as “automatic do”.↩︎\nI consider the “Big 4” as Stata, SAS, SPSS, and R. SPSS has terrible help; SAS’s is good but dense and difficult to navigate if you don’t already know what you’re looking for; R’s is very hit-or-miss depending on who wrote it.↩︎"
  },
  {
    "objectID": "02-working-with-data-sets.html#built-in-data",
    "href": "02-working-with-data-sets.html#built-in-data",
    "title": "2  Working with Data Sets",
    "section": "2.1 Built-in data",
    "text": "2.1 Built-in data\nBefore we turn to using your own data, it is useful to know that Stata comes with a collection of sample data sets which you can use to try the Stata commands. Additionally, most (if not all) of the examples in Stata help will use these data sets.\nTo see a list of the built-in data sets, use\n. sysuse dir\n  auto.dta        census.dta      network1.dta    surface.dta\n  auto16.dta      citytemp.dta    network1a.dta   tsline1.dta\n  auto2.dta       citytemp4.dta   nlsw88.dta      tsline2.dta\n  autornd.dta     educ99gdp.dta   nlswide1.dta    uslifeexp.dta\n  bplong.dta      gnp96.dta       pop2000.dta     uslifeexp2.dta\n  bpwide.dta      lifeexp.dta     sandstone.dta   voter.dta\n  cancer.dta      mycensus9.dta   sp500.dta       xtline1.dta\nand use sysuse again to load data, for example the auto data which contains characteristics of various cars from a 1978 Consumer’s Report magazine.\n. sysuse auto\n(1978 automobile data)\nIf you make any modifications to your data, Stata will try and protect you by refusing to load a new data set which would dispose of your changes. If you are willing to dispose of your changes, you can either manually do it by calling\nclear\nor passing it as an option to sysuse,\n. sysuse auto, clear\n(1978 automobile data)\n\n2.1.1 Stata Website Data\nIn addition to the data sets distributed with Stata, Stata also makes available a large collection of data sets on their website which can be accessed with the webuse command. These data sets are used as examples in the Manual and can be seen listed as http://www.stata-press.com/data/r18/.\nwebuse hiway\nwebuse supports the clear option as well.\nThe exercises in this workshop will be using mostly built-in data sets as it makes distribution easy!"
  },
  {
    "objectID": "02-working-with-data-sets.html#opening-data",
    "href": "02-working-with-data-sets.html#opening-data",
    "title": "2  Working with Data Sets",
    "section": "2.2 Opening data",
    "text": "2.2 Opening data\nAs you may have deduced from the sysuse and webuse commands above, the command to load local data is use:\nuse &lt;filename&gt;\nAs discussed in the working directory section, Stata can see only files in its working directory, so only the name of the file needs to be passed. If the file exists in a different directory, you will need to give the full (or relative path). For example, if your working directory is “C:\\\\” and the file you are looking for, “mydata”, is in the “Project” subfolder, you could open it with any of the following:\nuse C:\\Documents\\Stata\\Project\\mydata\nuse Project\\mydata\ncd Project\nuse mydata\nNote that if the path (or file name) contains any spaces, you need to wrap the entire thing in quotes:\nuse \"C:\\Documents\\Stata\\My Project\\My Data\"\nIt is never wrong to use quotes (just not always required), so perhaps that’s a safer option.\nIf the location of your file is much different than your working directory, it can be quicker just to use the menu “File -&gt; Open” and use the file open dialog box instead. As with all commands, the use command will be echoed in the Results after using the dialog box, allowing you to add it to a Do-file.\nAs with sysuse and webuse, the clear option discards the existing data regardless of unsaved changes.\n\n2.2.1 Loading subsets of the data\nYou can load only a subset of the data into the program at a time. Generally I would recommend loading the full data and then discarding the extraneous information. However, if your data is very large, it might be handy to only load in some of it rather than the entire thing. As this is a lesser-used option we won’t go into too much detail, but as an example, if I wanted to load only the variables named “bp”, “heartrate” and “date” from the data set “patientdata”, restricted to male patients, I might use something like\nuse bp heartrate date if gender == \"male\" using patientdata\nHere, using and if are subcommands, which we will see used more as the day goes on.\nThe statement gender == \"male\" is a conditional statement which only loads male patients. We’ll discuss later about conditional statements.\nAlternatively, if you have a very large data set, you can load in a small chunk of it.\nuse patientdata in 1/100\nThis loads just the first 100 rows (a/b is a “numlist” counting from “a” to “b” by integers).\nFor further details, see help use, specifically the manual which has the full documentation."
  },
  {
    "objectID": "02-working-with-data-sets.html#editing-data-manually",
    "href": "02-working-with-data-sets.html#editing-data-manually",
    "title": "2  Working with Data Sets",
    "section": "2.3 Editing data manually",
    "text": "2.3 Editing data manually\nWe will discuss in Data Manipulation how to edit your data on a larger scale and in an automated fashion, but Stata does support modifying a spreadsheet of your data similar to Excel. At the top of the main window, you’ll see two buttons, “Data Editor” and “Data Browser”. These open the same new Data window, the only difference is that Stata is protecting you from yourself and if you open the “Data Browser” (or switch to it in the Data window), you cannot modify the data.\nOnce in the Data window, you can select cells and edit them as desired. Note that whenever you make a modification in the Data Editor, there is a corresponding command produced which actually performs the modification.\n. replace age = 27 in 11\n(1 real change made)\n\n2.3.1 Colors as variable type\nWhen viewing the data, the color of each column’s text provides information about the type of variable. We’ll go into more details later what these types mean. Below, for the auto data, you can see the make variable is red, indicating a string, the foreign variable is blue indicating a variable with an attached value label and the remainder of the variables are black for numeric."
  },
  {
    "objectID": "02-working-with-data-sets.html#saving-data",
    "href": "02-working-with-data-sets.html#saving-data",
    "title": "2  Working with Data Sets",
    "section": "2.4 Saving data",
    "text": "2.4 Saving data\nSaving data is done with the save command. There are two variations of running.\nsave, replace\nIn this first variation, by not giving a file name and passing the replace option, Stata will overwrite whichever file you loaded with use. (It will error if you loaded a file via sysuse or webuse.)\nThe second variation takes a file name:\nsave newfile\nsave newfile, replace\nHere, save will save a copy named “newfile.dta” in the working directory. You can pass it a full path just like with use to refer to a location outside of the working directory. By default, save will not overwrite existing files, but can be overwritten with the replace option.\nAs before, wrap the file name in quotes if it (or the path) includes any spaces.\nPrior to Stata 14, the save format was different. If you need to save a data set in the older format (perhaps to pass to a collaborator who is woefully behind the times), check help saveold."
  },
  {
    "objectID": "02-working-with-data-sets.html#importing-data",
    "href": "02-working-with-data-sets.html#importing-data",
    "title": "2  Working with Data Sets",
    "section": "2.5 Importing data",
    "text": "2.5 Importing data\nThe need often arises to import data from another format (such as Excel or SPSS). Stata has a suite of very useful commands for importing data sets having other formats. To see the types of data that Stata can import, select “File -&gt; Import”.\nWhile there are commands to do the importing (such as import excel file.xlsx), the dialog boxes for importation provide a preview of the imported data, making it easier to ensure that the importation will go smoothly. Just as with editing the data, after performing an import with the dialog box, the corresponding command is executed in the results window and can be copied in a Do-file for reproducibility.\n\n2.5.1 Importing Excel data\nData stored in Excel can be ported into Stata easily. To make your life easier, make sure the data adheres to these general principals. While technically none of these are “required”, ignoring them will lead to a lot more work down the road!\n\nRemove extraneous information (plots, notes, data dictionaries, summary statistics).\nRemove “fancy” formatting - merged cells, empty rows/columns.\nEnsure each column is of one “type” - if the column is supposed to be numbers, don’t include any words!\nMake missing values blank (unless you are interested in types of missingness, in which case be sure to have a coherent coding scheme).\n\nOnce you have cleaned your data, you can choose “File -&gt; Import -&gt; Excel Spreadsheet (.xls, .xlsx)”. The next dialog allows you to tweak the options. Important options include\n\nWorksheet: Make sure you are importing the correct sheet!\nCell range: If you have extraneous information in your spreadsheet, you can exclude it here. (Though in my experience it is better to remove the extraneous data from Excel, as its easy to forget something here!)\nImport first row as variable names: In Excel, it is common to have the first row being the variable names with the second row starting the data. In Stata, the variable names have their own special field, so only data should exist in the data. Check this to ensure the variables are properly named.\nImport all data as strings: It should rarely be useful to use this.\n\nStata reads all the data and tries to predict whether each column represents a number or a string. To do so, it goes through some logic.\n\nIs anything in the column non-numeric? If yes, it is a String. If no, continue.\nIs anything in the column formatted as a Date or Time? If yes, it is a Date or Time. If no, continue.\nIt is a number.\n\nIf Stata makes mistakes here (usually because the data is formatted oddly), things can go wrong. The last option, “Import all data as strings” can be used to force Stata to treat everything as a string so that it reads in the data exactly as stored in the Excel sheet so that you can clean it up later. Note that cleaning this up is usually more complicated then just fixing the Excel sheet first! (Note also that for larger data, this scan can be slow!)\nOnce the preview looks accurate, go ahead and import. As usual, this will create an import excel command in the Results that you can save for the future in a Do-file, but using save to create a Stata data set to load in later is probably a better option.\n\n\n2.5.2 Importing a CSV File\nCSV files (comma separated values) are a very useful format for passing data between software. Files specific for software (e.g. .dta for Stata, .xlsx for Excel, .sav for SPSS) carry a lot of overhead information - very useful when working exclusively within that software, but confusing for other software. The import menu in Stata (and other software) can often address this, but a CSV file bypasses this. Data in CSV format might look like\nid,salary,exprior,market,admin,yearsdg,rank,male\n1,38361.75,0,.72,0,14,2,0\n2,68906,2,1,,31,3,1\nThe first row is the variable names, all separated by commas. The 2nd row starts the data, where each variable is again separated by commas. Multiple commas in a row indicate a missing value.\nThe downside of CSV files is we lose any auxiliary information, such as descriptive titles, labels etc. Often, if you are obtaining CSV files from an online resource, they will provide a Do-file alongside the data that reads in the CSV file and applies labels, titles, etc. If not you’ll have to do this yourself!\nA CSV files can be imported using “File -&gt; Import -&gt; Text Data (delimited, *.csv, …)”\nImportant options include:\n\nDelimiter - There are other _SV types of files, such as tab or white space. Generally you can leave this at Automatic, but may need to be precise if your data has a lot of strings in it.\nTreat sequential delimiters as one - If you have missing data, it will appear as 5,4,,2,1. If this option is not selected, Stata will recognize the missing third entry. On the other hand, if your deliminator is white space, you may have data like 3 1 2 5. If you want that to be four variables instead of a bunch of other missing entries, select this option.\nUse first row for variable names - Same as the Excel version.\n\n\n\n2.5.3 Importing from a file not supported directly by Stata\nIf you have data in a format not supported by Stata, there are three options:\nFirst, try opening the the data in a word processor and see if it is delimited instead of more complicated (e.g. a CSV file with a different file extension). This is a long shot, but the easiest! If you open it in something like Word, make sure you don’t save it in .doc format! Instead, rename the file “.txt” or “.csv” and try importing it as that.\nSecond, see if the software which created the data can write it into Stata (.dta) format. Some software such as R supports this, though some software (such as SPSS) only supports writing to older versions of Stata. You can still try this, though be sure to double check that nothing went wrong, and re-save your data (which saves it as the new save format).\nFinally, see if you can open the data in the other software and export it into CSV or a similar common format.\nIf all else fails, there is software Stat Transfer, https://www.stattransfer.com, which can transfer between all sorts of formats with a click, but is not free. Your department or organization may offer access to it."
  },
  {
    "objectID": "02-working-with-data-sets.html#switching-between-data-sets",
    "href": "02-working-with-data-sets.html#switching-between-data-sets",
    "title": "2  Working with Data Sets",
    "section": "2.6 Switching between data sets",
    "text": "2.6 Switching between data sets\nHere we’ll discuss two ways to switch between data sets. Later we’ll discuss the third way to work with multiple data sets, merging.\n\n2.6.1 Temporarily preserving and restoring data\nSay you want to carry out a destructive operation on your data, temporarily. This could be either to close your data and load another, or to make a change to the current data.For example, say you want to remove some subset of your observations. One workflow to use would be:\nsysuse auto\n&lt;modify data set as desired&gt;\nsave tmp\n&lt;subset data&gt;\n&lt;obtain results&gt;\nuse tmp, clear\n&lt;delete the tmp file manually&gt;\nAlternatively, the preserve and restore commands perform the same set of operations in a more automated fashion:\nsysuse auto\n&lt;modify data set as desired&gt;\npreserve\n&lt;subset data&gt;\n&lt;obtain results&gt;\nrestore\nThe preserve command saves an image of the data as they are now, and the restore command reloads the image of the data, discarding any interim changes. There can only be a single image of the data preserved at a time, so if you preserve, then make a change and want to preserve again (without an intervening restore), you can pass the option not to restore to discard the preserved image of the data.\nrestore, not\nOne thing to note about the use of preserve and restore in Do-files: If you run a chunk of commands which include a preserve statement, after the code executes restore is automatically run even if restore was not in the set of commands you ran!\n\n\n2.6.2 Frames\nStarting in Stata 16, Stata can load multiple data sets into different “frames”, though you still work with a single data set at a time. Each frame has a name; when you first open Stata the frame you start with is named “default”.\n. frame\n  (current frame is default)\nThe “default” frame is nothing special; it’s simply the name when you open a fresh version of Stata. You can create a new frame via frame create,\n. frame create newframe\nand move between frames via frame change or cwf.\n. cwf newframe\n\n. frame\n  (current frame is newframe)\n\n. cwf default\nIf we look at all frames with frame dir,\n. frame dir\n  default   74 x 12; 1978 automobile data\n  newframe  0 x 0\nwe can see that the default frame has the most recent data we loaded, the auto data. We could switch to the newframe and load a separate data set if we wanted.\n. cwf newframe\n\n. sysuse bplong\n(Fictional blood-pressure data)\n\n. frame dir\n  default   74 x 12; 1978 automobile data\n  newframe  240 x 5; Fictional blood-pressure data\nNote that commands operate on our current frame, so calling describe will describe “bplong” since we’re still in newframe.\n. describe, short\n\nContains data from /Applications/Stata/ado/base/b/bplong.dta\n Observations:           240                  Fictional blood-pressure data\n    Variables:             5                  1 May 2022 11:28\nSorted by: patient\nWe can run commands on the other frame either by changing to that frame with cwf, or by using the frame ___: prefix:\n. frame default: describe, short\n\nContains data from /Applications/Stata/ado/base/a/auto.dta\n Observations:            74                  1978 automobile data\n    Variables:            12                  13 Apr 2022 17:45\nSorted by: foreign\n\n2.6.2.1 Dropping frames\nWhen you load a data set, it gets loaded into your computer’s memory. If you keep creating new frames and loading data, you can very quickly run out of memory!\nUse frame drop to dispose of old frames.\n. frame dir\n  default   74 x 12; 1978 automobile data\n  newframe  240 x 5; Fictional blood-pressure data\n\n. frame drop default\n\n. frame dir\n  newframe  240 x 5; Fictional blood-pressure data\n\n\n2.6.2.2 Copying data into frames\nOften you may want to create a collapse’d or otherwise modified version of your current data. You can use frame copy to create a duplicate which you can then destroy.\n. frame copy newframe newframe2\n\n. frame newframe2: collapse (mean) bp, by(patient)\n\n. frame dir\n  newframe   240 x 5; Fictional blood-pressure data\n* newframe2  120 x 2; Fictional blood-pressure data\n\nNote: Frames marked with * contain unsaved data.\nNote that you cannot copy into an existing frame; you must either delete the old frame or copy into a new name.\n\n\n2.6.2.3 Linking data sets\nWe’re not going to go into it now, but please see the section in the Programming & Advanced Features section for details on linking data sets if interested. You can link data sets between frames to either enable moving variables across frames, or if the data are at different units of analysis (e.g. a patient file and a clinic file), to easily merge the files together."
  },
  {
    "objectID": "02-working-with-data-sets.html#exercise-1",
    "href": "02-working-with-data-sets.html#exercise-1",
    "title": "2  Working with Data Sets",
    "section": "2.7 Exercise 1",
    "text": "2.7 Exercise 1\n\nLoad the built-in data set “lifeexp”.\nOpen the Data Editor window. Modify at least one of the cells.\nClose the Data window. Load the built-in data set “sandstone”. Don’t forget to clear or pass the clear option.\nSave a copy of this data to your computer.\n\nCheck your working directory. Make sure it is set somewhere convenient.\nUse save. Make sure to give it a name!\n\nIf you haven’t already, play with preserve and restore. Preserve the data, modify some values, then observe what happens when you restore."
  },
  {
    "objectID": "03-data-management.html#referring-to-variables",
    "href": "03-data-management.html#referring-to-variables",
    "title": "3  Data Management",
    "section": "3.1 Referring to variables",
    "text": "3.1 Referring to variables\nWhen we discussed basic command syntax, we said that the optional list of variables can include any number of variables (for some commands). Writing out all the variables can get very tedious as the number of variables increases. Thankfully there are two alternatives.\nFirst, we can use the wild card *1. For example, we could refer to the variables “turn” and “trunk” as t*, as both variables start with “t” and are followed by anything. However, be careful, as this would also match variables such as turnips, tprice, t, etc, if any such variables existed. It can also be used in the middle or beginning, e.g.:\n\nc*t would match cat, caught and ct\n*2 would match age2, gender2 and salary2012.\n\nAlternatively, if the variables we want to include are next to each other in the data (e.g. in the Variables pane), we can refer to a list of them. Say the variables x1 through x25 are in ordered in the logical fashion. We could refer to the whole list of them as x1-x25. This includes both x1 and x25, as well as any variable in between them. We will discuss the order command later to re-order variables.\nFinally, you often don’t need to give the entire name of the variable, just enough characters for Stata to be able to uniquely identify it (similar to short names). We’ll see in a minute more about the describe command, but for example,\n. describe headr\n\nVariable      Storage   Display    Value\n    name         type    format    label      Variable label\n-------------------------------------------------------------------------------\nheadroom        float   %6.1f                 Headroom (in.)\nStata will error if you don’t use enough characters:\n. describe t\nt ambiguous abbreviation\nr(111);\nBe very careful with this approach. I only recommend it’s use when exploring the data using the Command window; when writing a Do-file, use the full variable name to prevent errors!"
  },
  {
    "objectID": "03-data-management.html#describing-the-data",
    "href": "03-data-management.html#describing-the-data",
    "title": "3  Data Management",
    "section": "3.2 Describing the data",
    "text": "3.2 Describing the data\nThe first command you should run is describe.\n. describe\n\nContains data from /Applications/Stata/ado/base/a/auto.dta\n Observations:            74                  1978 automobile data\n    Variables:            12                  13 Apr 2022 17:45\n                                              (_dta has notes)\n-------------------------------------------------------------------------------\nVariable      Storage   Display    Value\n    name         type    format    label      Variable label\n-------------------------------------------------------------------------------\nmake            str18   %-18s                 Make and model\nprice           int     %8.0gc                Price\nmpg             int     %8.0g                 Mileage (mpg)\nrep78           int     %8.0g                 Repair record 1978\nheadroom        float   %6.1f                 Headroom (in.)\ntrunk           int     %8.0g                 Trunk space (cu. ft.)\nweight          int     %8.0gc                Weight (lbs.)\nlength          int     %8.0g                 Length (in.)\nturn            int     %8.0g                 Turn circle (ft.)\ndisplacement    int     %8.0g                 Displacement (cu. in.)\ngear_ratio      float   %6.2f                 Gear ratio\nforeign         byte    %8.0g      origin     Car origin\n-------------------------------------------------------------------------------\nSorted by: foreign\nThis displays a large amount of information, so let’s break in down.\nFirst, the header displays general data set information - the number of observations (obs, the number of rows) and variables (vars).\nNext, there is a table listing each variable in the data and some information about them. The “storage type” can be one of byte, int, long, float, double; all of which are simply numbers. We’ll touch on the differences between these when we discuss compress, but for now they all represent numeric variables. String variables are represented as str## where the ## represent the number of characters that the string can be, e.g. str18 shows that make has a maximum of 18 letters. (This limit is irrelevant, again, see compress for details.)\nThe “display format” column contains format information about each variable which only control how the variables are displayed in data view. For the most part you can ignore these and leave them at the default, though you may need to work with this if you have date or time information. For further details see\nhelp formats\n“value label” and “variable label” are used to display more information when running analyses using these variables. See the label section for further details.\nFinally, if the data is sorted, describe will provide information about the sorting.\ndescribe can also be used on a per variable basis:\n. describe mpg\n\nVariable      Storage   Display    Value\n    name         type    format    label      Variable label\n-------------------------------------------------------------------------------\nmpg             int     %8.0g                 Mileage (mpg)\n\n. describe trunk displacement\n\nVariable      Storage   Display    Value\n    name         type    format    label      Variable label\n-------------------------------------------------------------------------------\ntrunk           int     %8.0g                 Trunk space (cu. ft.)\ndisplacement    int     %8.0g                 Displacement (cu. in.)\nIf you have a very large number of variables you may wish to suppress the table of variables entirely:\n. describe, short\n\nContains data from /Applications/Stata/ado/base/a/auto.dta\n Observations:            74                  1978 automobile data\n    Variables:            12                  13 Apr 2022 17:45\nSorted by: foreign\nAlternatively, the simple option returns only the names of the variables, in column-dominant order (meaning you read down the columns not across the rows).\n. describe, simple\nmake          rep78         weight        displacement\nprice         headroom      length        gear_ratio\nmpg           trunk         turn          foreign"
  },
  {
    "objectID": "03-data-management.html#compressing-data",
    "href": "03-data-management.html#compressing-data",
    "title": "3  Data Management",
    "section": "3.3 Compressing data",
    "text": "3.3 Compressing data\nAs mentioned above, there are different ways to store a number variable, such as byte and long. The various options take more space to save - types which take less space can store only smaller numbers whereas types that take more space can store larger numbers. For example, a number stored as a byte can only take on values between -127 and 100 and only integers (e.g. not 2.5) whereas a number stored as float can store numbers up to \\(1.7x10^{38}\\) with up to 38 decimal places. Strings operate similarly; a string variable with 20 characters would store “abc” as 17 blank characters followed by the “abc”.\nUnderstanding the above is not that important these days as computer power and storage has increased to the point where the majority of us will not be reaching its limits. However, Stata does offer the compress command which attempts to store variables in the smallest possible type. For example, if a variable which is a float takes on only values 1 through 10, it is replaced by a byte (and similarly, strings are as long as the longest value).\nThe memory command lets us see the size of our data, particularlly the first entry of “Data” under “Used” shows that we start with 3,182 bytes or roughly 3Kb.\n. memory\n\nMemory usage\n                                         Used                Allocated\n----------------------------------------------------------------------\nData                                    3,182               67,108,864\nstrLs                                       0                        0\n----------------------------------------------------------------------\nData & strLs                            3,182               67,108,864\n\n----------------------------------------------------------------------\nData & strLs                            3,182               67,108,864\nVariable names, %fmts, ...              4,370                   71,230\nOverhead                            1,081,344                1,082,136\n\nStata matrices                              0                        0\nado-files                              22,919                   22,919\nStored results                              0                        0\n\nMata matrices                           1,904                    1,904\nMata functions                          1,632                    1,632\n\nset maxvar usage                    4,636,521                4,636,521\n\nOther                                  14,828                   14,828\n----------------------------------------------------------------------\nTotal                               5,752,072               72,940,034\n\n. compress\n  variable mpg was int now byte\n  variable rep78 was int now byte\n  variable trunk was int now byte\n  variable turn was int now byte\n  variable make was str18 now str17\n  (370 bytes saved)\n\n. memory\n\nMemory usage\n                                         Used                Allocated\n----------------------------------------------------------------------\nData                                    2,812               67,108,864\nstrLs                                       0                        0\n----------------------------------------------------------------------\nData & strLs                            2,812               67,108,864\n\n----------------------------------------------------------------------\nData & strLs                            2,812               67,108,864\nVariable names, %fmts, ...              4,370                   71,230\nOverhead                            1,081,344                1,082,136\n\nStata matrices                              0                        0\nado-files                              22,919                   22,919\nStored results                              0                        0\n\nMata matrices                           1,904                    1,904\nMata functions                          1,632                    1,632\n\nset maxvar usage                    4,636,521                4,636,521\n\nOther                                  14,828                   14,828\n----------------------------------------------------------------------\nTotal                               5,751,702               72,940,034\nWe see here a very modest saving (370 bytes, about 12%), but sometimes you can see much more significant gains.\n(When running Stata, instead of using memory, you can look at the “Size” entry in the properties pane.)\nDon’t be afraid of artificially restricting yourself going forward; if one of your values exceeds the limitations its type supports, Stata will automatically change types. So don’t hesitate to run compress when loading new data or after some manipulations."
  },
  {
    "objectID": "03-data-management.html#exercise-2",
    "href": "03-data-management.html#exercise-2",
    "title": "3  Data Management",
    "section": "3.4 Exercise 2",
    "text": "3.4 Exercise 2\n\n“census9” is accesible via webuse. Load it.\nSpend a minute looking at the data. What does this data seem to represent? What variables do we have? (describe will come in handy here!)\nAre there any missing states?\nWhat variables (if any) are numeric and what variables (if any) are strings?\nCompress the data. How much space is saved? Why do you think this is?"
  },
  {
    "objectID": "03-data-management.html#labels",
    "href": "03-data-management.html#labels",
    "title": "3  Data Management",
    "section": "3.5 Labels",
    "text": "3.5 Labels\nA raw data set is very sparse on context. In addition to the data itself, it will have at most a variable name, which in Stata cannot include spaces and is limited to 32 characters. All other context associated with the data must either be documented in a data dictionary or exist in the recollection of the analyst.\nIn an Excel file, to get around this, you might add additional content to the sheet outside of the raw data - a note here, a subtitle there, etc. However, Stata does not allow such arbitrary storage. In contrast, Stata allows you to directly label parts of the data with context information which will be displayed in the appropriate Results, to make Stata output much easier to read as well as removing the need for an external data dictionary.\n\n3.5.1 Labeling variables\nVariables names, as mentioned, are limited to 32 characters and do not allow spaces (or several other special characters). This is to encourage you to choose short, simple, and memorable variable names, since you’ll likely be typing them a lot!\nWe can easily add more information with a variable label. If you look at the describe output, you’ll notice that the auto data set already has variable labels applied to it.\n. describe\n\nContains data from /Applications/Stata/ado/base/a/auto.dta\n Observations:            74                  1978 automobile data\n    Variables:            12                  13 Apr 2022 17:45\n                                              (_dta has notes)\n-------------------------------------------------------------------------------\nVariable      Storage   Display    Value\n    name         type    format    label      Variable label\n-------------------------------------------------------------------------------\nmake            str17   %-17s                 Make and model\nprice           int     %8.0gc                Price\nmpg             byte    %8.0g                 Mileage (mpg)\nrep78           byte    %8.0g                 Repair record 1978\nheadroom        float   %6.1f                 Headroom (in.)\ntrunk           byte    %8.0g                 Trunk space (cu. ft.)\nweight          int     %8.0gc                Weight (lbs.)\nlength          int     %8.0g                 Length (in.)\nturn            byte    %8.0g                 Turn circle (ft.)\ndisplacement    int     %8.0g                 Displacement (cu. in.)\ngear_ratio      float   %6.2f                 Gear ratio\nforeign         byte    %8.0g      origin     Car origin\n-------------------------------------------------------------------------------\nSorted by: foreign\n     Note: Dataset has changed since last saved.\nWe can see variable rep78 (an utterly incomprehensible name at first glance, as opposed to mpg) has the label “Repair Record 1978”. You can apply your own variable labels (or overwrite existing by using the command:\nlabel variable &lt;variable name&gt; \"Variable label\"\nFor example:\n. label variable turn \"Some new label for turn\"\n\n. describe turn\n\nVariable      Storage   Display    Value\n    name         type    format    label      Variable label\n-------------------------------------------------------------------------------\nturn            byte    %8.0g                 Some new label for turn\nTo remove a variable label, you can call label variable &lt;varname&gt; without a new label to remove the existing one. (Equivalent to label variable &lt;varname&gt; \"\", so passing an empty variable label.)\n. label variable turn\n\n. describe turn\n\nVariable      Storage   Display    Value\n    name         type    format    label      Variable label\n-------------------------------------------------------------------------------\nturn            byte    %8.0g                 \n\n\n3.5.2 Labeling values\nIt is tempting to store categorical variables as strings. If you ask, for example, for someone’s state of residence, you might store the answers as “MI”, “OH”, “FL”, etc. However, Stata (like most statistical software) cannot handle string variables.2 A much better way to store this data would be to assign each state a numerical value, say MI = 1, OH = 2, FL = 3, etc, then keep a data dictionary linking the values to the labels they represent.\nStata allows you to store this value labels information within the data set, such that whenever the values are output, the labels are printed instead. Let’s take a look at the foreign variable. This variable takes on two levels, and we can tabulate it to see how many cars are in each category.\n. tabulate foreign\n\n Car origin |      Freq.     Percent        Cum.\n------------+-----------------------------------\n   Domestic |         52       70.27       70.27\n    Foreign |         22       29.73      100.00\n------------+-----------------------------------\n      Total |         74      100.00\nHere it appears that foreign is stored as two strings, but we know from describe that it is not:\n. describe foreign\n\nVariable      Storage   Display    Value\n    name         type    format    label      Variable label\n-------------------------------------------------------------------------------\nforeign         byte    %8.0g      origin     Car origin\nAdditionally, if you look at the data through Data Editor or Data Browser, you see that instead of foreign being red (as a string) it is blue, as we discussed earlier.\nLet’s look at that table ignoring the value labels:\n. tabulate foreign, nolabel\n\n Car origin |      Freq.     Percent        Cum.\n------------+-----------------------------------\n          0 |         52       70.27       70.27\n          1 |         22       29.73      100.00\n------------+-----------------------------------\n      Total |         74      100.00\nNow we see the values which are actually stored.\nLook at the describe output:\n. describe foreign\n\nVariable      Storage   Display    Value\n    name         type    format    label      Variable label\n-------------------------------------------------------------------------------\nforeign         byte    %8.0g      origin     Car origin\nYou’ll notice that the “value label” column has origin attached to foreign. In Stata, the value labels information are stored separately from the variables. They are two separate components - there is a variable and there is a value label. You connect the value label to a variable to use it.\nThe benefit of this separated structure is that if you have several variables which have the same coding scheme (e.g. a series of Likert scale questions, where 1-5 represents “Strongly Disagree”-“Strongly Agree”), you can create a single value label and rapidly apply it to all variables necessary.\nCorrespondingly, this process requires two commands. First we define the value labels:\nlabel define &lt;label name&gt; &lt;value&gt; \"&lt;label&gt;\" &lt;value&gt; \"&lt;label&gt;\" .....\nFor example, if we wanted to recreate the value label associated with foreign:\n. label define foreign_label 0 \"Domestic\" 1 \"Foreign\"\nValue labels exist in the data set, regardless of whether they are attached to any variables, we can see all value labels:\n. label list\nforeign_label:\n           0 Domestic\n           1 Foreign\norigin:\n           0 Domestic\n           1 Foreign\nHere we see the original origin as well as our new foreign_label. To attach it to the variable foreign:\n. label values foreign foreign_label\nIf we wanted to attach a single value label to multiple variables, we could simply provide a list of variables:\nlabel values &lt;var1&gt; &lt;var2&gt; &lt;var3&gt; &lt;label&gt;\nTo remove the value labels from a variable, use the label values &lt;variable&gt; command with no label name following the variable name:\n. label values foreign\n\n. describe foreign\n\nVariable      Storage   Display    Value\n    name         type    format    label      Variable label\n-------------------------------------------------------------------------------\nforeign         byte    %8.0g                 Car origin\nYou can view all value labels in the data set:\n. label list\nforeign_label:\n           0 Domestic\n           1 Foreign\norigin:\n           0 Domestic\n           1 Foreign\nNote that value labels exist within a data set regardless of whether they are attached to a variable. If there is a label value that you no longer want to keep in the data-set, you can drop it:\n. label drop foreign_label\n\n. label list\norigin:\n           0 Domestic\n           1 Foreign\nThis will not remove the value labels from any variables, but they will no longer be active (i.e. if you run describe it will still show that the value labels are attached, but running tabulate will not use them). So in order to completely remove a value label, you’ll need to both remove it from the variable as well as the data.\nDo not forget that modifying value labels counts as modifying the data. Make sure you save, replace after making these modifications (if you want to keep them) or they’ll be lost!"
  },
  {
    "objectID": "03-data-management.html#managing-variables",
    "href": "03-data-management.html#managing-variables",
    "title": "3  Data Management",
    "section": "3.6 Managing variables",
    "text": "3.6 Managing variables\nIn Stata, managing the names and order of variables is important to make entering commands easier due to the shortcuts for referring to variables. Recall that variables can be referred to using wildcards (e.g. a* to include age, address or a10, or using var1-var10 to include all variables between var1 and var10 as they are ordered). Of course, you may also want to rename or re-order variables for other reasons such as making the data easier to look at.\n\n3.6.1 Renaming variables\nTo rename variables:\nrename &lt;oldname&gt; &lt;newname&gt;\nFor example:\n. rename rep78 repair_record_1978\n\n. describe, simple\nmake          repair_~1978  weight        displacement\nprice         headroom      length        gear_ratio\nmpg           trunk         turn          foreign\nThe output truncated the name because it was so long.\nVariable names are unique; if you wanted to swap to variable names, you’d have to name one to a temporary name, rename the second, then rename the first again:\nrename a tmp\nrename b a\nrename tmp b\nYou can use wildcards in the renaming too. For example, imagine you had a collection of variables from a longitudinal data set, “visit1_age”, “visit1_weight”, “visit1_height”, etc. To simplify variable names, we’d prefer to use “age1”, “weight1”, etc.\nrename visit1_* *1\nFinally, you can change a variable name to upper/lower/proper case easily by passing upper/lower/proper as an argument and giving no new variable name.\n. rename length, upper\n\n. describe, simple\nmake          repair_~1978  weight        displacement\nprice         headroom      LENGTH        gear_ratio\nmpg           trunk         turn          foreign\nYou can also do this for the whole data set with the special variable list _all:\n. rename _all, upper\n\n. describe, simple\nMAKE          REPAIR_~1978  WEIGHT        DISPLACEMENT\nPRICE         HEADROOM      LENGTH        GEAR_RATIO\nMPG           TRUNK         TURN          FOREIGN\n\n. rename _all, lower\n\n\n3.6.2 Changing variable ordering\nThe order command takes a list of variables and moves them to the front/end/before a certain variable/after a certain variable. The options first, last, before(&lt;variable&gt;) and after(&lt;variable&gt;) control this.\n. order foreign // The default is `first`\n\n. describe, simple\nforeign       mpg           trunk         turn\nmake          repair_~1978  weight        displacement\nprice         headroom      length        gear_ratio\n\n. order weight, last\n\n. describe, simple\nforeign       mpg           trunk         displacement\nmake          repair_~1978  length        gear_ratio\nprice         headroom      turn          weight\n\n. order mpg trunk, before(displacement)\n\n. describe, simple\nforeign       repair_~1978  turn          displacement\nmake          headroom      mpg           gear_ratio\nprice         length        trunk         weight"
  },
  {
    "objectID": "03-data-management.html#exercise-3",
    "href": "03-data-management.html#exercise-3",
    "title": "3  Data Management",
    "section": "3.7 Exercise 3",
    "text": "3.7 Exercise 3\nIf you’ve changed to a different data set, load “census9” back up with webuse.\n\nGoing forward, we’ll be using a version of “census9” with changes we’re making. Save a copy of the data to somewhere convenient (such as your Desktop). Don’t forget to give it a name!\nThe drate variable is a bit vague - the name of the variable provides no clue that “d” = “death”, and the values (e.g. 75) are ambiguous.\n\nRename drate to deathrate.\nThe rate is actually per 10,000 individuals. Label dearthrate to include this information.\n\nThe variable region has a value label associated with it (“cenreg”). It has some inconsistent choices, namely “NE” and “N Cntrl”. Fix this.\n\nCreate a new value label which uses “Northeast” and “North Central” instead of “NE” and “N Cntrl”.\nAttach this new value label to region.\nRemove the existing value label “cenreg”.\nUse label list and tabulate to confirm it worked.\n\nSave the data, replacing the version you created in step 1."
  },
  {
    "objectID": "03-data-management.html#summarizing-the-data",
    "href": "03-data-management.html#summarizing-the-data",
    "title": "3  Data Management",
    "section": "3.8 Summarizing the data",
    "text": "3.8 Summarizing the data\nWhile these notes will not cover anything statistical, it can be handy from a data management perspective to look at some summary statistics, mostly to identify problematic variables. Among other things, we can try and detect\n\nUnexpectedly missing data\nIncorrectly coded data\nErrors/typos in input data\nIncorrect assumptions about variable values\n\nThere are numerous ways to look at summary statistics, from obtaining one-number summaries to visualizations, but we will focus on two Stata commands, summarize and codebook.\nsummarize produces basic summary statistics for numeric variables.\n. summarize\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n     foreign |         74    .2972973    .4601885          0          1\n        make |          0\n       price |         74    6165.257    2949.496       3291      15906\nrepair_~1978 |         69    3.405797    .9899323          1          5\n    headroom |         74    2.993243    .8459948        1.5          5\n-------------+---------------------------------------------------------\n      length |         74    187.9324    22.26634        142        233\n        turn |         74    39.64865    4.399354         31         51\n         mpg |         74     21.2973    5.785503         12         41\n       trunk |         74    13.75676    4.277404          5         23\ndisplacement |         74    197.2973    91.83722         79        425\n-------------+---------------------------------------------------------\n  gear_ratio |         74    3.014865    .4562871       2.19       3.89\n      weight |         74    3019.459    777.1936       1760       4840\nThe table reports the total number of non-missing values (make appears to be entirely missing because it is non-numeric), the mean (the average value), the standard deviation (a measure of how spread out the data is) and the minimum and maximum non-missing3 values observed.\nHere’s some suggestions of how to look at these values.\n\nMake sure the amount of missing data is expected. If the number of observations is lower than anticipated, is it an issue with the data collection? Or did the import into Stata cause issues? 5 cars have no repair_record_1978.\nThe mean should be a reasonable number, somewhere in the rough middle of the range of possible values for the variable. If you have age recorded for a random selection of adults and the mean age is 18, something has gone wrong. If the mean age is -18, something has gone tragically wrong!\nThe standard deviation is hard to interpret precisely, but in a very rough sense, 2/3rds of the values should lie within 1 standard deviation of the mean. For example, consider mpg. The mean is ~21 and the standard deviation is ~6, so roughly 2/3rds of the cars have mpg between 15 and 27. Does this seems reasonable? If the standard deviation is very high compared to the mean (e.g. if mpg’s standard deviation was 50) or close to 0, that could indicate an issue.\nAre the max and min reasonable? If the minimum LENGTH was -9, that’s problematic. Maybe -9 is the code for missing values? If the range of LENGTH is 14 to 2500, maybe the units differ? They measured in feet for some cars and inches for others?\n\nsummarize can also take a list of variables, e.g.\n. summarize t*\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n        turn |         74    39.64865    4.399354         31         51\n       trunk |         74    13.75676    4.277404          5         23\nFor more detailed information, we can look at the codebook. codebook works similarly to describe and summarize in the sense that without any additional arguments, it displays information on every variable; you can pass it a list of variables to only operate on those. Because codebook’s output is quite long, we only demonstrate the restricted version. Before we do that, we reload the “auto” data because we messed with it quite a bit earlier!\nFirst, categorical data:\n. sysuse auto, clear\n(1978 automobile data)\n\n. codebook rep78\n\n-------------------------------------------------------------------------------\nrep78                                                        Repair record 1978\n-------------------------------------------------------------------------------\n\n                  Type: Numeric (int)\n\n                 Range: [1,5]                         Units: 1\n         Unique values: 5                         Missing .: 5/74\n\n            Tabulation: Freq.  Value\n                            2  1\n                            8  2\n                           30  3\n                           18  4\n                           11  5\n                            5  .\nWe see that rep78 takes on five unique values, as well as having some missing values (.). If the unique values is more than expected, it’s something to investigate.\nNext, continuous variables:\n. codebook price\n\n-------------------------------------------------------------------------------\nprice                                                                     Price\n-------------------------------------------------------------------------------\n\n                  Type: Numeric (int)\n\n                 Range: [3291,15906]                  Units: 1\n         Unique values: 74                        Missing .: 0/74\n\n                  Mean: 6165.26\n             Std. dev.:  2949.5\n\n           Percentiles:     10%       25%       50%       75%       90%\n                           3895      4195    5006.5      6342     11385\nWe still see the number of unique values reported, but here every observation has a unique value (74 unique values, 74 rows in the data). There is no missing data. The percentiles should be checked to see if they’re reasonable, if 90% of the cars had a price under $100, something’s not right.\nFinally, string variables:\n. codebook make\n\n-------------------------------------------------------------------------------\nmake                                                             Make and model\n-------------------------------------------------------------------------------\n\n                  Type: String (str18), but longest is str17\n\n         Unique values: 74                        Missing \"\": 0/74\n\n              Examples: \"Cad. Deville\"\n                        \"Dodge Magnum\"\n                        \"Merc. XR-7\"\n                        \"Pont. Catalina\"\n\n               Warning: Variable has embedded blanks.\nWe get less information here, but still useful to check that the data is as expected. There are no empty strings nor any repeated strings. The warning about “embedded blanks” is spaces; it’s telling us that there are spaces in some of the cars (e.g. “Dodge Magnum”). The reason it is a warning is that “Dodge_Magnum” and “Dodge__Magnum” read the same to us, but that extra space means Stata recognizes these as two different variables.\nTwo options for codebook which come in handy:\n. codebook, compact\n\nVariable      Obs Unique      Mean   Min    Max  Label\n-------------------------------------------------------------------------------\nmake           74     74         .     .      .  Make and model\nprice          74     74  6165.257  3291  15906  Price\nmpg            74     21   21.2973    12     41  Mileage (mpg)\nrep78          69      5  3.405797     1      5  Repair record 1978\nheadroom       74      8  2.993243   1.5      5  Headroom (in.)\ntrunk          74     18  13.75676     5     23  Trunk space (cu. ft.)\nweight         74     64  3019.459  1760   4840  Weight (lbs.)\nlength         74     47  187.9324   142    233  Length (in.)\nturn           74     18  39.64865    31     51  Turn circle (ft.)\ndisplacement   74     31  197.2973    79    425  Displacement (cu. in.)\ngear_ratio     74     36  3.014865  2.19   3.89  Gear ratio\nforeign        74      2  .2972973     0      1  Car origin\n-------------------------------------------------------------------------------\ncompact shows a reduced size version, most useful for the “Unique” column. (Useful if that’s the only thing you’re running the codebook for.)\n. codebook, problems\n\nPotential problems in dataset /Applications/Stata/ado/base/a/auto.dta\n\n               Potential problem   Variables\n--------------------------------------------------\nstr# vars that may be compressed   make\nstring vars with embedded blanks   make\n--------------------------------------------------\nThis reports potential issues Stata has discovered in the data. In this data, neither are really concerns. (We can run compress, but this isn’t a “problem” so much as a suggestion. We already saw above the concern about “embedded blanks.”) More serious problems that it can detect include:\n\nConstant columns (all entries being the same value, including all missing).\nIssues with value labels (if you’ve attached a value label to a variable and subsequently deleted the value label without detaching it; or if your variable takes on values unaccounted for in the value label).\nIssues with date variables."
  },
  {
    "objectID": "03-data-management.html#exercise-4",
    "href": "03-data-management.html#exercise-4",
    "title": "3  Data Management",
    "section": "3.9 Exercise 4",
    "text": "3.9 Exercise 4\nUsing summarize and codebook to explore the “census9” data and answer the following questions:\n\nAre there any values which seem to be errors?\nI’d expect each state to have their own unique value of death rate, population and median age. Is this true? If not, why?\nAre there any problems with the data?"
  },
  {
    "objectID": "03-data-management.html#footnotes",
    "href": "03-data-management.html#footnotes",
    "title": "3  Data Management",
    "section": "",
    "text": "This is the reason why * as a comment does not work in the middle of a line (and we use // instead).↩︎\nIn the few situations where it can, it doesn’t handle them cleanly.↩︎\nAs we discuss later, in Stata, missing values (represented by . in the data) are considered to be higher than any other number (so 99999 &lt; .).↩︎"
  },
  {
    "objectID": "04-data-manipulation.html#restricting-commands-to-subsets",
    "href": "04-data-manipulation.html#restricting-commands-to-subsets",
    "title": "4  Data Manipulation",
    "section": "4.1 Restricting commands to subsets",
    "text": "4.1 Restricting commands to subsets\nWe’ll discuss operating on subsets of the data in far more detail a bit later, but first we’ll discuss how to modify the basic command syntax to run a command only on some rows of data.\nRecall the basic command syntax,\ncommand &lt;variable(s)&gt;, &lt;options&gt;\nBy default, this will use all rows of the data it can. However, we can restrict this.\ncommand &lt;variable(s)&gt; in &lt;number list&gt;, &lt;options&gt;\ncommand &lt;variable(s)&gt; if &lt;condition&gt;, &lt;options&gt;\nBoth are optional (obviously), but you can include them if desired.\nUsing in, we pass a number list which consists of a lower bound, a /, and an upper bound. For example, if we wanted to summarize the first 10 rows for a variable, we could run:\n. summarize weight\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n      weight |         74    3019.459    777.1936       1760       4840\n\n. summarize weight in 1/10\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n      weight |         10        3271    558.3796       2230       4080\nAs you can see, the second call to summarize thinks there are only 10 rows of data.\nThe if requires defining a conditional statement. Consider the following statements\n\\[\n  4 \\gt 2\n\\] \\[\n  1 \\gt 2\n\\]\nRemembering back to middle school math classes that \\(\\gt\\) means “greater than”, clearly the first statement is true and the second statement is false. We can assign values of true and false to any such conditional statements, which use the following set of conditional operators:\n\n\n\n\n\n\n\n\n\nSign\nDefinition\nTrue example\nFalse example\n\n\n\n\n\\(==\\)\nequality\n\\(3 == 3\\)\n\\(3 == 2\\)\n\n\n\\(!=\\)\nnot equal\n\\(3 != 4\\)\n\\(3 != 3\\)\n\n\n\\(\\gt\\)\ngreater than\n\\(4 \\gt 2\\)\n\\(1 \\gt 2\\)\n\n\n\\(\\lt\\)\nless than\n\\(1 \\lt 2\\)\n\\(4 \\lt 2\\)\n\n\n\\(\\gt=\\)\ngreater than or equal to\n\\(4 \\gt= 4\\)\n\\(1 \\gt= 2\\)\n\n\n\\(\\lt=\\)\nless than or equal to\n\\(1 \\lt= 1\\)\n\\(4 \\lt= 2\\)\n\n\n&\nand (both statements are true)\n\\((4 \\gt 2)\\) & \\((3 == 3)\\)\n\\((4 \\gt 2)\\) & \\((1 \\gt 2)\\)\n\n\n\\(\\|\\)\nor (either statement is true)\n\\((3 == 2) \\| (1 \\lt= 2)\\)\n\\((4 \\lt 2) \\| (1 \\gt 2)\\)\n\n\n\nSo we could summarize a variable only when some other variables have some values.\n. summarize weight if foreign == 1\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n      weight |         22    2315.909    433.0035       1760       3420\n\n. summarize weight if foreign == 1 | (mpg &gt; 20 & headroom &lt; 10)\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n      weight |         41    2505.122     585.291       1760       4290\nNote in the second example we used parentheses to evaluate a more complex expression; we follow order of operations (remember PEMBAS?) and evaluate the inner-most parantheses first. So first mpg &gt; 20 & headroom &lt; 10 gets evaluated and returns TRUE or FALSE; then following that, we evaluate either foreign == 1 | TRUE or foreign == 1 | FALSE depending on what the first result was.\nWe saw the usage of this earlier when discussing loading subsets of the data."
  },
  {
    "objectID": "04-data-manipulation.html#generating-new-variables",
    "href": "04-data-manipulation.html#generating-new-variables",
    "title": "4  Data Manipulation",
    "section": "4.2 Generating new variables",
    "text": "4.2 Generating new variables\nThe generate command can be used to create new variables which are functions of existing variables. For example, if we look at the variable label for weight, we see that it is measured in pounds.\n. describe weight\n\nVariable      Storage   Display    Value\n    name         type    format    label      Variable label\n-------------------------------------------------------------------------------\nweight          int     %8.0gc                Weight (lbs.)\nLet’s create a second weight variable measured in tons. The syntax for generate is straightforward,\ngenerate &lt;new varname&gt; = &lt;function of old variables&gt;\n. generate weight2 = weight/2000\nThe list command can be used to output some data, let’s use it here to output the first 5 rows’ weight and weight2 variables:\n. list weight* in 1/5\n\n     +------------------+\n     | weight   weight2 |\n     |------------------|\n  1. |  2,930     1.465 |\n  2. |  3,350     1.675 |\n  3. |  2,640      1.32 |\n  4. |  3,250     1.625 |\n  5. |  4,080      2.04 |\n     +------------------+\n(Note: I use list here because I need the variables outputted to create the document. When using Stata interactively, it’d probably be nicer to use browse or edit in the exact same fashion, e.g. browse weights* in 1/5. These enter the Data Browser (browse) or Data Browser (Edit Mode) (edit) showing the same subset of rows/columns as requested.)\nIf you check the arithmetic, you’ll see that we’ve got the right answer. We should probably add a variable label to our new weight\n. label variable weight2 \"Weight (tons)\"\n\n. describe weight*\n\nVariable      Storage   Display    Value\n    name         type    format    label      Variable label\n-------------------------------------------------------------------------------\nweight          int     %8.0gc                Weight (lbs.)\nweight2         float   %9.0g                 Weight (tons)\nIn addition to direct arithmetic equations, we can use a number of functions to perform calculations. For example, a common transformation is to take the log of any monetary variable, in our case price. This is done because typical monetary variables, such as price or salary, tend to be very right-skewed - most people make $30k-50k, and a few people make 6 or 7 digit incomes.\n. generate logprice = log(price)\n\n. label variable logprice \"Log price\"\n\n. list *price in 1/5\n\n     +------------------+\n     | price   logprice |\n     |------------------|\n  1. | 4,099   8.318499 |\n  2. | 4,749    8.46569 |\n  3. | 3,799   8.242494 |\n  4. | 4,816   8.479699 |\n  5. | 7,827   8.965335 |\n     +------------------+\nIn that command, log is the function name, and it is immediately followed by parentheses which enclose the variable to operate on. Read the parentheses as “of”, so that log(price) is read as “log of price”.\nThere are a lot of functions that can be used. We list some commonly used mathematical functions below for your convenience:\n\n+, -, *, /: Standard arithmetic\nabs( ): returns the absolute value\nexp( ): returns the exponential function of \\(e^x\\)\nlog( ) or ln( ): returns the natural logarithm of the argument1\nround( ), ceil( ), floor( ): returns the rounded value (rounded to nearest integer, rounded up, and rounded down)\nsqrt( ): returns the square root\n\nYou can see a full accounting of all functions you can use in this setting in\nhelp functions\n\n4.2.1 Creating dummies\nDummy variables (also known as indicator variables or binary variables) are variables which take on two values, 0 and 12. These are typically used in a setting where the 0 represents an absence of something (or an answer of “no”) and 1 represents the presence (or an answer of “yes”). When naming dummy variables, you should keep this in mind to make understanding the variable easier, as well as extracting interpretations regarding the variable in a model.\nFor example, “highschool” is a poor dummy variable - what does 0 highschool or 1 highschool represent? Obviously we could (and should) use value labels to associate 0 and 1 with informative labels, but it is more straightforward to use a variable name such as “highschool_graduate” or “graduateded_highschool) - a 0 represents”no” to the question of “graduated high school?”, hence a non-high school graduate; and a 1 represents a “yes”, hence a high school graduate.\nIf you are collecting data, consider collecting data as dummies where appropriate - if the question has a binary response, encode it as a dummy instead of strings. If a question has categorical responses, consider encoding them as a series of dummy variables instead (e.g. “Are you from MI?”, “Are you from OH?” etc). These changes will (usually) need to be made later anyways.\nNow here’s the trick: In Stata3, conditional statements return 1 (True) and 0 (False). So we can use them in generate statements to create binary variables easily.\n. generate price4k = price &gt; 4000\n\n. list price* in 1/5\n\n     +-----------------+\n     | price   price4k |\n     |-----------------|\n  1. | 4,099         1 |\n  2. | 4,749         1 |\n  3. | 3,799         0 |\n  4. | 4,816         1 |\n  5. | 7,827         1 |\n     +-----------------+\nNote that this is NOT the same thing as using if. E.g., we see the following error:\n. generate price4k2 = if price &gt; 4000\nif not found\nr(111);\nNow, price4k takes on values 1 and 0 depending on whether the conditional statement was true.\nFor a slightly more complicated example, lets create a dummy variable representing cheap cars. There are two possible definitions of cheap cars - cars which have a low cost, or cars which have low maintenance costs (high mileage and low repairs).\n. generate cheap = price &lt; 3500 | (rep78 &lt;= 2 & mpg &gt; 20)\n\n. list make price rep78 mpg if cheap == 1\n\n     +-----------------------------------------+\n     | make                price   rep78   mpg |\n     |-----------------------------------------|\n 14. | Chev. Chevette      3,299       3    29 |\n 17. | Chev. Monte Carlo   5,104       2    22 |\n 18. | Chev. Monza         3,667       2    24 |\n 34. | Merc. Zephyr        3,291       3    20 |\n 40. | Olds Starfire       4,195       1    24 |\n     |-----------------------------------------|\n 52. | Pont. Sunbird       4,172       2    24 |\n     +-----------------------------------------+\nThe list commands conditions on cheap == 1 because again, the conditional statement will return 1 for true and 0 for false. We see 6 cheap cars; the Chevette and Zephyr are cheap because of their cost, whereas the other four cars are cheap because of the maintenance costs.\n\n\n4.2.2 System Variables\nIn Stata, under the One Data principal, any information in the data4 must be in a variable. This includes the System Variables of _n and _N. You can imagine that every data st you ever open has two additional columns of data, one for _n and one for _N.\n_n represents the row number, currently. “Currently” means if the data is re-sorted, _n can change.\n_N represents the total number of rows in the data, hence this is the same for every row. Again, if the data changes (e.g. you drop some data) then _N may be updated.\nWhile you cannot access these System Variables normally (e.g. they don’t appear in the Data Browser), you can use them in generating variables or conditional statements. For example, we’ve seen that list can use in to restrict the rows it outputs, and we’ve seen that it can use if to choose conditionally. We can combine these:\n. list make in 1/2\n\n     +-------------+\n     | make        |\n     |-------------|\n  1. | AMC Concord |\n  2. | AMC Pacer   |\n     +-------------+\n\n. list make if _n &lt;= 2\n\n     +-------------+\n     | make        |\n     |-------------|\n  1. | AMC Concord |\n  2. | AMC Pacer   |\n     +-------------+\nA more useful example is to save the initial row numbering in your data. When we discuss sorting later, it may be useful to be able to return to the original ordering. Since _n changes when the data is re-sorted, if we save the initial row numbers to a permanent variable, we can always re-sort by it later. _N is slightly less useful but can be used similarly.\n. generate row = _n\n\n. generate totalobs = _N\n\n. list row totalobs in 1/5\n\n     +----------------+\n     | row   totalobs |\n     |----------------|\n  1. |   1         74 |\n  2. |   2         74 |\n  3. |   3         74 |\n  4. |   4         74 |\n  5. |   5         74 |\n     +----------------+\n\n\n4.2.3 Extensions to generate\nThe command egen5 offers some functionality that generate lacks, for example creating the mean of several variables\negen &lt;newvar&gt; = rowmean(var1, var2, var3)\nThe functions which egen support are fairly random; you can see the full list in the help:\nhelp egen"
  },
  {
    "objectID": "04-data-manipulation.html#replacing-existing-variables",
    "href": "04-data-manipulation.html#replacing-existing-variables",
    "title": "4  Data Manipulation",
    "section": "4.3 Replacing existing variables",
    "text": "4.3 Replacing existing variables\nEarlier we created the weight2 variable which changed the units on weight from pounds to tons. What if, instead of creating a new variable, we tried to just change the existing weight variable.\n. generate weight = weight/2000\nvariable weight already defined\nr(110);\nHere Stata refuses to proceed since weight is already defined. To overwrite weight, we’ll instead need to use the replace command.\n. replace weight = weight/2000\nvariable weight was int now float\n(74 real changes made)\n\n. list weight in 1/5\n\n     +--------+\n     | weight |\n     |--------|\n  1. |  1.465 |\n  2. |  1.675 |\n  3. |   1.32 |\n  4. |  1.625 |\n  5. |   2.04 |\n     +--------+\nreplace features syntax identical to generate.6\n\n4.3.1 Conditional variable generation\n(We’re going to reload the auto data set at this point to ensure all data is as originally saved.)\n. sysuse auto, clear\n(1978 automobile data)\nOne frequent task is recoding variables. This can be “binning” continuous variables into a few categories, re-ordering an ordinal variables, or collapsing categories in an already-categorical variable. There are also multi-variable versions; e.g. combining multiple variables into one.\nThe general workflow with these cases will be to optionally use generate to create the new variable, then use replace to conditional replace the original or new variable.\nAs an example, let’s generate a new variable which categorizes cars into light, medium weight, and heavy cars. We’ll define light cars as a weight below 1 ton (2000 lbs), and heavy cars as having a weight of 2 tons (4000 lbs) or more.\nBefore we do this, we’ve learned that the weight reported for the Pont. Grand Prix was incorrect - we don’t know what the correct weight is, but we know the presented one is wrong, so let’s make it missing. We could of course do this manually - open the data editor and delete the value of weight corresponding to the Pont. Grand Prix. As we saw earlier, manually editing the data like this produces a replace call that we can move into our Do file for reproducibility. However, this replace call would refer to a row number, something like\nreplace weight = . in 49\nWhat would happen if our data was shuffled prior to running this command? It would no longer be applied to the correct row. Therefore, it will be safer to use a conditional statement to identify the row corresponding to \"Pont. Grand Prix\".\n. replace weight = . if make == \"Pont. Grand Prix\"\n(1 real change made, 1 to missing)\n\n. list make weight if make == \"Pont. Grand Prix\"\n\n     +---------------------------+\n     | make               weight |\n     |---------------------------|\n 49. | Pont. Grand Prix        . |\n     +---------------------------+\nNow, we’ll return to generating the categorical weight variable. First, we’ll generate the new variable to store this information.\n. generate weight_cat = 1\n\n. tab weight_cat\n\n weight_cat |      Freq.     Percent        Cum.\n------------+-----------------------------------\n          1 |         74      100.00      100.00\n------------+-----------------------------------\n      Total |         74      100.00\nWithout any conditional statements, every observation’s weight_cat is set to 1. We’ll let the 1 represent the “light” category, so next we’ll replace it with 2 for cars in the “medium” category.\n. replace weight_cat = 2 if weight &gt;= 2000 & weight &lt; 4000\n(57 real changes made)\n\n. tab weight_cat\n\n weight_cat |      Freq.     Percent        Cum.\n------------+-----------------------------------\n          1 |         17       22.97       22.97\n          2 |         57       77.03      100.00\n------------+-----------------------------------\n      Total |         74      100.00\nNote the choice of &gt;= instead of &gt; and &lt; instead of &lt;=. As above, we stated that light cars have weight below 2000 lbs, so medium cars have a value of 2000 or more (greater than or equal). On the other end, heavy cars have a weght of 4000 lbs or more, so medium cars are strictly less than 4000 lbs (less than).\nFinish with the “heavy” cars\n. replace weight_cat = 3 if weight &gt;= 4000\n(10 real changes made)\n\n. tab weight_cat\n\n weight_cat |      Freq.     Percent        Cum.\n------------+-----------------------------------\n          1 |          7        9.46        9.46\n          2 |         57       77.03       86.49\n          3 |         10       13.51      100.00\n------------+-----------------------------------\n      Total |         74      100.00\nWhen using less than/greater than conditinal statements to split a variable into groups, you always want to ensure that when the two “endpoints” are the same, one uses strictly less/more, and the other uses “or equal”. If both use “or equal”, you’ll get inconsistent results for exact values. If neither use “or equal”, exact values will not be classified. (For example, if we had used weight &lt; 4000 and weight &gt; 4000, any car with exact weight of 4000 would not fall into either [and its weight_cat would stay 1, a light car]. On the other hand, if we had used weight &lt;= 4000 and weight &gt;= 4000, a car with exact weight of 4000 would be assigned to whichever of the lines was run last.)\nLastly, we’ll add some nice labels.\n. label define weight_cat 1 \"Light\" 2 \"Medium\" 3 \"Heavy\"\n\n. label values weight_cat weight_cat\n\n. tab weight_cat\n\n weight_cat |      Freq.     Percent        Cum.\n------------+-----------------------------------\n      Light |          7        9.46        9.46\n     Medium |         57       77.03       86.49\n      Heavy |         10       13.51      100.00\n------------+-----------------------------------\n      Total |         74      100.00\nThere’s one additional complication. Stata represents missing values by ., and . has a value of positive infinity. That means that\n\\[\n400 \\lt .\n\\]\nis true! There is some discussion on the Stata FAQs that goes into the rationale behind it, but the short version is that this slightly complicates variable generation but greatly simplifies and protects some data management tasks.\nThe complication referred to can be seen in the row corresponding to the Pont. Grand Prix\n. list make weight weight_cat in 46/50\n\n     +--------------------------------------+\n     | make               weight   weight~t |\n     |--------------------------------------|\n 46. | Plym. Volare        3,330     Medium |\n 47. | Pont. Catalina      3,700     Medium |\n 48. | Pont. Firebird      3,470     Medium |\n 49. | Pont. Grand Prix        .      Heavy |\n 50. | Pont. Le Mans       3,200     Medium |\n     +--------------------------------------+\nEven though the Grand Prix has no weight, it is categorized as “Heavy”\n. replace weight_cat = . if missing(weight)\n(1 real change made, 1 to missing)\n\n. tab weight_cat, missing\n\n weight_cat |      Freq.     Percent        Cum.\n------------+-----------------------------------\n      Light |          7        9.46        9.46\n     Medium |         57       77.03       86.49\n      Heavy |          9       12.16       98.65\n          . |          1        1.35      100.00\n------------+-----------------------------------\n      Total |         74      100.00\nThe missing() function returns true for each row with a missing value, and false for each row with an observed value, for the variable inside the parantheses (in this case, weight).\nYou may occasionally see if weight != . or if weight &lt;= . instead of the missing() function. Recall that missing values are sorted to be larger than the largest observed value, so this works just as well as missing(). However, Stata allows you to define “reasons” for missing, specifically .a, .b, all the way through .z. These are sorted such that . &lt; .a &lt; .b &lt; … &lt; .z. For this reason, != . is not suggested, as while . will be captured as missing, .a, etc will not be. Using missing() removes the temptation to write != instead of &lt;=.\nThe missing() function can be proceeded with an exclamation point to indicate not missing. For example\nreplace x = 2 if !missing(y)\nThe missing option to tab forces it to show a row for any missing values. Without it, missing rows are suppressed.\nTo summarize, we used the following commands:\ngenerate weight_cat = 1\nreplace weight_cat = 2 if weight &gt;= 2000 & weight &lt; 4000\nreplace weight_cat = 3 if weight &gt;= 4000\nreplace weight_cat = . if missing(weight)\nThere are various other ways it could have been done, such as\ngenerate weight_cat = 1 if weight &lt; 2000\nreplace weight_cat = 2 if weight &gt;= 2000 & weight &lt; 4000\nreplace weight_cat = 3 if weight &gt;= 4000 & !missing(weight)\ngenerate weight_cat = .\nreplace weight_cat = 1 if weight &lt; 2000\nreplace weight_cat = 2 if weight &gt;= 2000 & weight &lt;= 4000\nreplace weight_cat = 3 if weight &gt; 4000 & !missing(weight)\nOf course, we could also generate it in the reverse order (3 to 1) or even mixed up (3, 1, 2). There are also alternate ways to write the various conditionals, such as replacing weight &gt; 4000 with weight &gt;= 4001. There are usually multiple correct ways to specify any conditional."
  },
  {
    "objectID": "04-data-manipulation.html#more-complicated-replaces",
    "href": "04-data-manipulation.html#more-complicated-replaces",
    "title": "4  Data Manipulation",
    "section": "4.4 More complicated replaces",
    "text": "4.4 More complicated replaces\nThe above example for replace was fairly simplistic, but you can imagine the need for a much more complicated replacing structure (perhaps based on the value of multiple variables). If, however, you do have something this simple, the recode command could be used instead.\nThe recode command syntax is fairly simple,\nrecode &lt;oldvar&gt; (&lt;rule 1&gt;) (&lt;rule 2&gt;) ...., generate(&lt;newvar&gt;)\nThe different rules define the recoding to take place. For example, the above creation of weight_cat can be written as\nrecode weight (1/1999 = 1) (2000/4000 = 2) (4001/99999999 = 3) ///\n              (missing = .), generate(weight_cat)\nEach rule has the form of old value(s) = new value, where the old values can be any of:\n\nA single number, e.g. (5 = 2).\nseveral numbers, either\n\na numlist as in this example (note the use of a very large non-missing value for the upper bound)\na space-separated list of values, e.g. (1 5 10 = 4)\nMixture of the those two, e.g. (6 10 12/25 31 = 17)\n\nthe phrases missing, nonmissing or else to capture anything not elsewhere defined.\n\nThe new value must be a single number or a missing value (. or .a, etc). else cannot be used if missing or nonmissing is defined (and vice-versa), and all of those must be the last rules defined. E.g.,\nrecode x (missing = 5) (2 = 4) (else = 3) (1 = 2), generate(y)\nwill not run because “missing” and “else” are both simultaneously defined, and because the 1 = 2 rule is last instead of else or missing.\nNote that if you see older code you may see either the parantheses or the generate option excluded. You should include both of these.\nFinally, the rules are executed left-to-right. So if you have two rules referring to the same values, the first one is used, and the second is not. For example,\nrecode x (1/5 = 7) (2 = 4), generate(y)\nThe 2 = 4 rule will never take place because 2 is already recoded to 7 in the 1/5 = 7 rule."
  },
  {
    "objectID": "04-data-manipulation.html#subsetting",
    "href": "04-data-manipulation.html#subsetting",
    "title": "4  Data Manipulation",
    "section": "4.5 Subsetting",
    "text": "4.5 Subsetting\nAlmost any Stata command which operates on variables can operate on a subset of the data instead of the entire data, as we saw before, by using the if or in statements in the command. This is equivalent to throwing away some data and then performing the command. In general, you should avoid discarding data as you never know when you will possible use it. Of course, you could use preserve and restore to temporarily remove the data, but using the conditional subsetting is more straightforward.\nIf the conditional logic we want to use involves subsets of the data, we could use this to give us results within each group.\n. summarize price\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n       price |         74    6165.257    2949.496       3291      15906\n\n. summarize price if foreign == 0\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n       price |         52    6072.423    3097.104       3291      15906\n\n. summarize price if foreign == 1\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n       price |         22    6384.682    2621.915       3748      12990\nKeep track of the number of observations, Obs, to see that the second and third commands are in fact operating on the subsets. We see here that American cars are cheaper on average7.\n\n4.5.1 Repeat commands on subsets\nTo look at the average price for American and foreign cars, we ran two individual commands. If we wanted to look at the summaries by rep78, that would take 6 commands (values 1 through 5 and .)!\nInstead, we can use by and bysort to perform the same operation over each unique value in a variable. For example, we could repeat the above with:\n. by foreign: summ price\n\n-------------------------------------------------------------------------------\n-&gt; foreign = Domestic\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n       price |         52    6072.423    3097.104       3291      15906\n\n-------------------------------------------------------------------------------\n-&gt; foreign = Foreign\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n       price |         22    6384.682    2621.915       3748      12990\n\nThere is a strong assumption here that the data is already sorted by the variables we are splitting by on (e.g. foreign). If foreign were not sorted (or if you simply did not want to check/assume it was), you could instead use\nbysort foreign: summ price\nbysort is identical to sorting (which we’ll discuss later) first and running the by statement afterwards. In general, it is recommended to always use bysort instead of by, unless you believe the data is already sorted and want an error if that assumption is violated.\nBefore running these commands, consider generating a original ordering variable first.\nbysort’s variables cannot be conditional statements, so if you wanted to for example get summaries by low and high mileage cars, you’d need to generate a dummy variable first.\n. gen highmileage = mpg &gt; 20\n\n. bysort highmileage: summ price\n\n-------------------------------------------------------------------------------\n-&gt; highmileage = 0\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n       price |         38    6937.316    3262.392       3291      14500\n\n-------------------------------------------------------------------------------\n-&gt; highmileage = 1\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n       price |         36    5350.306    2358.612       3299      15906\n\nbysort can take two or more variables, and performs its commands within each unique combination of the variable. For example,\n. bysort foreign highmileage: summ price\n\n-------------------------------------------------------------------------------\n-&gt; foreign = Domestic, highmileage = 0\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n       price |         33    6585.606    3149.214       3291      14500\n\n-------------------------------------------------------------------------------\n-&gt; foreign = Domestic, highmileage = 1\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n       price |         19    5181.105    2867.906       3299      15906\n\n-------------------------------------------------------------------------------\n-&gt; foreign = Foreign, highmileage = 0\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n       price |          5      9258.6    3369.459       5719      12990\n\n-------------------------------------------------------------------------------\n-&gt; foreign = Foreign, highmileage = 1\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n       price |         17    5539.412    1686.472       3748       9735\n\nWhen specifying bysort, you can optionally specify a variable to sort on but not to group by. For example, let’s say your data consisted of doctors visits for patients, where patients may have more than one appointment. You want to generate a variable indicating whether a visit is the first by the patient. Say id stores the patient id, date stores the date of the visit.\nbysort id (date): gen firstvisit = _n == 1\nBy placing date in parentheses, this ensures that within each id, the data is sorted by date. Therefore the first row for each patient is their first visit, so _n == 1 evaluates to 1 only in that first row and 0 zero otherwise.\n\n\n4.5.2 Discarding data\nIf you do want to discard data, you can use keep or drop to do so. They each can perform on variables:\nkeep &lt;var1&gt; &lt;var2&gt; ...\ndrop &lt;var1&gt; &lt;var2&gt; ...\nor on observations:\nkeep if &lt;conditional&gt;\ndrop if &lt;conditional&gt;\nNote that these cannot be combined:\n. drop turn if mpg &gt; 20\ninvalid syntax\nr(198);\nkeep removes all variables except the listed variables, or removes any row which the conditional does not return true.\ndrop removes any listed variables, or removes any row which the conditional returns true."
  },
  {
    "objectID": "04-data-manipulation.html#dealing-with-duplicates",
    "href": "04-data-manipulation.html#dealing-with-duplicates",
    "title": "4  Data Manipulation",
    "section": "4.6 Dealing with duplicates",
    "text": "4.6 Dealing with duplicates\nIf your data is not expected to have duplicates, either across all variables or within certain variables, the duplicates command can make their detection and correction easier. The most basic command is duplicates report, which simply reports on the status of duplicate rows. Let’s use the built-in “bplong” data. This data contains 120 patients (patient) with measures of blood pressure (bp) at two different time points (when, a Before and After), and some descriptive variables (sex and agegrp).\n. sysuse bplong, clear\n(Fictional blood-pressure data)\n\n. duplicates report\n\nDuplicates in terms of all variables\n\n--------------------------------------\n   Copies | Observations       Surplus\n----------+---------------------------\n        1 |          240             0\n--------------------------------------\nThis report is not very interesting; it reports that there are 240 observations which have 1 copy (e.g. are unique), and hence no surplus. Given that each row should be unique (just in patient ID and before/after alone), this is not surprising. Let’s instead look at the duplicates just for bp and when:\n. duplicates report bp when\n\nDuplicates in terms of bp when\n\n--------------------------------------\n   Copies | Observations       Surplus\n----------+---------------------------\n        1 |           23             0\n        2 |           42            21\n        3 |           66            44\n        4 |           48            36\n        5 |           35            28\n        6 |           12            10\n        7 |           14            12\n--------------------------------------\nHere we have some duplicates. First, there are 23 observations which are fully unique. All other observations have repeats to some extent.\nThe second row of the output tells of us that there are 42 observations which have 2 copies. The language here can be a bit confusing; all it is saying is that there are 42 rows, each of which has a single duplicate within that same 42. So if we have values 1, 1, 2, 2, that would be reported as 4 observations with 2 surplus.\nThe number of surplus is the number of non-unique rows in that category. We could compute it ourselves - we know that there are 42 rows with 2 copies, so that means that half of the rows are “unique” and the other half are “duplicates” (which is unique and which is duplicate is not clear). So 42/2 = 21, and we have 21 surplus.\nConsider the row for 4 copies. There are 48 rows, each of which belongs to a set of four duplicates. For example, 1, 1, 1, 1, 2, 2, 2, 2, has observations 8 and copies 2. In this row, 48/4 = 12, so there are 12 unique values, meaning 36 surplus.\nOther useful commands include\n\nduplicates list: Shows every set of duplicates, including its row number and value. Obviously for something like this the output would be massive as of the 240 total rows, only 23 are not duplicated to some degree!\nduplicates tag &lt;vars&gt;, gen(&lt;newvar&gt;): Adds a new variable which represents the number of other copies for each row. For unique rows, this will be 0. For any duplicated rows, it will essentially be “copies” from duplicates report minus 1. This can be useful for examining duplicates or dropping them.\nduplicates drop: Be cautious with this, as it drops any row which is a duplicate of a previous row (in other words keeps the first entry of every set of duplicates)."
  },
  {
    "objectID": "04-data-manipulation.html#sorting",
    "href": "04-data-manipulation.html#sorting",
    "title": "4  Data Manipulation",
    "section": "4.7 Sorting",
    "text": "4.7 Sorting\nWe already saw sorting in the context of bysort. We can also sort as a standalone operation. As before, consider generating a original ordering variable first.\nWe’ll switch back to “auto” first.\n. sysuse auto, clear\n(1978 automobile data)\n\n. gen order = _n\nThe gsort function takes a list of variables to order by.\n. gsort rep78 price\n\n. list rep78 price in 1/5\n\n     +---------------+\n     | rep78   price |\n     |---------------|\n  1. |     1   4,195 |\n  2. |     1   4,934 |\n  3. |     2   3,667 |\n  4. |     2   4,010 |\n  5. |     2   4,060 |\n     +---------------+\nStata first sorts the data by rep78, ascending (so the lowest value is in row 1). Then within each set of rows that have a common value of rep78, it sorts by price.\nYou can append “+” or “-” to each variable to change whether it is ascending or descending. Without a prefix, the variable is sorted ascending.\n. gsort +rep78 -price\n\n. list rep78 price in 1/5\n\n     +----------------+\n     | rep78    price |\n     |----------------|\n  1. |     1    4,934 |\n  2. |     1    4,195 |\n  3. |     2   14,500 |\n  4. |     2    6,342 |\n  5. |     2    5,886 |\n     +----------------+\nRecall that missing values (.) are larger than any other values. When sorting with missing values, they follow this rule as well. If you want to treat missing values as smaller than all other values, you can pass the mfirst option to gsort. Note this does not make missingness “less than” anywhere else, only for the purposes of the current sort.\nSorting strings does work and is done alphabetically. All capital letters are “less than” all lower case letters, and a blank string (\"\") is the “smallest”. For example, if you have the strings DBC, Daa, \"\"8, EEE, the sorted ascending order would be \"\", DBC, Daa, EEE. The blank is first; the two strings starting with “D” are before the string EEE, and the upper case “B” precedes the lower case “a”.\nAs a side note, there is an additional command, sort, which can perform sorting. It does not allow sorting in descending order, however it does allow you to sort only a certain number of rows; that is, passing something like sort &lt;varname&gt; in 100/200 would sort only rows 100 through 200, leaving the remaining rows remain in their exact same position."
  },
  {
    "objectID": "04-data-manipulation.html#working-with-strings-and-categorical-variables",
    "href": "04-data-manipulation.html#working-with-strings-and-categorical-variables",
    "title": "4  Data Manipulation",
    "section": "4.8 Working with strings and categorical variables",
    "text": "4.8 Working with strings and categorical variables\nString variables are commonly used during data collection but are ultimately not very useful from a statistical point of view. Typically string variables should be represented as categorical variables with value labels as we’ve previously discussed. Here are some useful commands for operating on strings and categorical variables.\n\n4.8.1 Converting between string and numeric\nThese two commands convert strings and numerics between each other.\ndestring &lt;variable&gt;, gen(&lt;newvar&gt;)\ntostring &lt;variable&gt;, replace\nBoth commands can take the options replace (to replace the existing variable with the new one) or gen( ) (to generate a new variable). I would recommend always using gen to double-check that the conversion worked as expected, then using drop, rename and order to replace the existing variable.\n. desc mpg\n\nVariable      Storage   Display    Value\n    name         type    format    label      Variable label\n-------------------------------------------------------------------------------\nmpg             int     %8.0g                 Mileage (mpg)\n\n. tostring mpg, gen(mpg2)\nmpg2 generated as str2\n\n. desc mpg2\n\nVariable      Storage   Display    Value\n    name         type    format    label      Variable label\n-------------------------------------------------------------------------------\nmpg2            str2    %9s                   Mileage (mpg)\n\n. list mpg* in 1/5\n\n     +------------+\n     | mpg   mpg2 |\n     |------------|\n  1. |  18     18 |\n  2. |  24     24 |\n  3. |  14     14 |\n  4. |  17     17 |\n  5. |  16     16 |\n     +------------+\nNow that the new string is correct, we can replace the existing mpg.\n. drop mpg\n\n. rename mpg2 mpg\n\n. order mpg, after(price)\nLet’s go the other way around:\n. desc mpg\n\nVariable      Storage   Display    Value\n    name         type    format    label      Variable label\n-------------------------------------------------------------------------------\nmpg             str2    %9s                   Mileage (mpg)\n\n. destring mpg, gen(mpg2)\nmpg: all characters numeric; mpg2 generated as byte\n\n. desc mpg2\n\nVariable      Storage   Display    Value\n    name         type    format    label      Variable label\n-------------------------------------------------------------------------------\nmpg2            byte    %10.0g                Mileage (mpg)\n\n. list mpg* in 1/5\n\n     +------------+\n     | mpg   mpg2 |\n     |------------|\n  1. |  18     18 |\n  2. |  24     24 |\n  3. |  14     14 |\n  4. |  17     17 |\n  5. |  16     16 |\n     +------------+\n\n. drop mpg\n\n. rename mpg2 mpg\n\n. order mpg, after(price)\nAnd we’re back to the original set-up.9\nWhen using destring to convert a string variable (that it storing numeric data as strings - “13”, “14”) to a numeric variable, if there are any non-numeric entries, destring will fail. For example, lets replace one entry in the make variable with a numeric.\n. replace make = \"1\" in 1\n(1 real change made)\n\n. destring make, gen(make2)\nmake: contains nonnumeric characters; no generate\nWe must pass the force option. With this option, any strings which have non-numeric variables will be marked as missing.\n. destring make, gen(make2) force\nmake: contains nonnumeric characters; make2 generated as byte\n(73 missing values generated)\n\n. tab make2, mi\n\n   Make and |\n      model |      Freq.     Percent        Cum.\n------------+-----------------------------------\n          1 |          1        1.35        1.35\n          . |         73       98.65      100.00\n------------+-----------------------------------\n      Total |         74      100.00\ntostring also accepts the force option when using replace, we recommend instead to never use replace with tostring (you probably should not use it with destring either!).\n\n\n4.8.2 Converting strings into labeled numbers\nIf we have a string variable which has non-numerical values (e.g. race with values “white”, “black”, “Hispanic”, etc), the ideal way to store it is as numerical with value labels attached. While we could do this manually using a combination of gen and replace with some conditionals, a less tedious way to do so is via encode.\nWe’ll switch to the “hbp2” data set from the Stata website, records some blood pressure measurements. Remember this will erase any existing unsaved changes! You will not need any modifications you’ve made to other built-in datasets going forward (except census9 from Exercise 3 which you should already have saved), but if you do want to save it, do so first!\n. webuse hbp2, clear\n\n. tab sex, missing\n\n        Sex |      Freq.     Percent        Cum.\n------------+-----------------------------------\n            |          2        0.18        0.18\n     female |        433       38.32       38.50\n       male |        695       61.50      100.00\n------------+-----------------------------------\n      Total |      1,130      100.00\n\n. desc sex\n\nVariable      Storage   Display    Value\n    name         type    format    label      Variable label\n-------------------------------------------------------------------------------\nsex             str6    %9s                   Sex\nThe sex variable is a string with two values. First, let’s create a numeric with value labels version manually.\n. gen male = sex == \"male\"\n\n. label define male 0 \"female\" 1 \"male\"\n\n. label values male male\n\n. tab male, missing\n\n       male |      Freq.     Percent        Cum.\n------------+-----------------------------------\n     female |        435       38.50       38.50\n       male |        695       61.50      100.00\n------------+-----------------------------------\n      Total |      1,130      100.00\n\n. replace male = . if sex == \"\"\n(2 real changes made, 2 to missing)\n\n. tab male, missing\n\n       male |      Freq.     Percent        Cum.\n------------+-----------------------------------\n     female |        433       38.32       38.32\n       male |        695       61.50       99.82\n          . |          2        0.18      100.00\n------------+-----------------------------------\n      Total |      1,130      100.00\n\n. tab male, missing nolabel\n\n       male |      Freq.     Percent        Cum.\n------------+-----------------------------------\n          0 |        433       38.32       38.32\n          1 |        695       61.50       99.82\n          . |          2        0.18      100.00\n------------+-----------------------------------\n      Total |      1,130      100.00\nInstead, we can easily use encode:\n. encode sex, gen(sex2)\n\n. tab sex2, missing\n\n        Sex |      Freq.     Percent        Cum.\n------------+-----------------------------------\n     female |        433       38.32       38.32\n       male |        695       61.50       99.82\n          . |          2        0.18      100.00\n------------+-----------------------------------\n      Total |      1,130      100.00\n\n. tab sex2, missing nolabel\n\n        Sex |      Freq.     Percent        Cum.\n------------+-----------------------------------\n          1 |        433       38.32       38.32\n          2 |        695       61.50       99.82\n          . |          2        0.18      100.00\n------------+-----------------------------------\n      Total |      1,130      100.00\nHowever, we see that encode starts numbering at 1 instead of 0, which is not ideal for dummy variables. To get around this, we can create our value label manually first, then pass it as an argument to encode.\n. label define manualsex 0 \"female\" 1 \"male\"\n\n. encode sex, gen(sex3) label(manualsex)\n\n. tab sex3, missing\n\n        Sex |      Freq.     Percent        Cum.\n------------+-----------------------------------\n     female |        433       38.32       38.32\n       male |        695       61.50       99.82\n          . |          2        0.18      100.00\n------------+-----------------------------------\n      Total |      1,130      100.00\n\n. tab sex3, missing nolabel\n\n        Sex |      Freq.     Percent        Cum.\n------------+-----------------------------------\n          0 |        433       38.32       38.32\n          1 |        695       61.50       99.82\n          . |          2        0.18      100.00\n------------+-----------------------------------\n      Total |      1,130      100.00\nThis can be extended to allow any sort of ordering desired. For this trivial binary example, it might actually be faster to use gen and do it manually, but for a variable with a large number of categories, this is much easier.\ndecode works in the reverse, creating a string out of a numeric vector with labels attached to it.\n. decode sex3, gen(sex4)\n\n. desc sex4\n\nVariable      Storage   Display    Value\n    name         type    format    label      Variable label\n-------------------------------------------------------------------------------\nsex4            str6    %9s                   Sex\n\n. tab sex4, missing\n\n        Sex |      Freq.     Percent        Cum.\n------------+-----------------------------------\n            |          2        0.18        0.18\n     female |        433       38.32       38.50\n       male |        695       61.50      100.00\n------------+-----------------------------------\n      Total |      1,130      100.00\ndecode will fail if its target does not have value labels attached.\n\n\n4.8.3 String manipulation\nIf you find yourself in a situation where you simply must manipulate the strings directly, there are a number of string functions. You can see the full list in help string functions, but below we list a few commonly used ones.\n\nstrlen: Returns the number of characters in the string\nwordcount: Returns the number of whitespace-separated words.\n+: Adding two strings together concatenates them (e.g. abc + def = abcdef).\nstrupper and strlower: Converts to lower/upper case.\nstrtrim: Removes white space preceding and following non-string characters in a string (e.g. strtrim(\"  string   \") = \"string\"). To remove only left (preceding) or right (following) spaces, use strltrim or strrtrim.\nsubstr: Returns the substring starting at an index for a given number of characters (e.g. substr(\"abcdefg\", 2, 3) = \"bcd\").\n\nThese can be used inside gen and replace, e.g.\n. gen sexupper = strupper(sex)\n(2 missing values generated)\n\n. gen sexinitial = substr(sexupper, 1, 1)\n(2 missing values generated)\n\n. list sex sexupper sexinitial in 1/5\n\n     +------------------------------+\n     |    sex   sexupper   sexini~l |\n     |------------------------------|\n  1. | female     FEMALE          F |\n  2. |                              |\n  3. |   male       MALE          M |\n  4. |   male       MALE          M |\n  5. | female     FEMALE          F |\n     +------------------------------+"
  },
  {
    "objectID": "04-data-manipulation.html#exercise-5",
    "href": "04-data-manipulation.html#exercise-5",
    "title": "4  Data Manipulation",
    "section": "4.9 Exercise 5",
    "text": "4.9 Exercise 5\nOpen the saved version of “census9” with use, not the original version with webuse.\n\nGenerate a new variable, deathperc, which is the percentage of deaths in each state. (Remember that deathrate is deaths per 10,000.)\nThe average age of all Americans in 1980 is roughly 30.11 years of age. Generate a categorical with four values as described before, with appropriate value labels.\n\nSignificantly below national average: medage equal to 26.20 or less\nBelow national average: medage greater than 26.20 and less than or equal to 30.10.\nAbove national average: medage greater than 30.10 and less than or equal to 32.80.\nSignificantly above national average: medage greater than 32.80.\n\nWhat is the death rate in each of those four categories? (You can use summarize to obtain the means.) Does there appear to be any pattern?\nWhat state has the lowest death rate? The highest? The lowest average age? The highest?\nEach state has a single observation here, but if we had multiple years of data, then we could have “long data” with multiple rows per state. To prepare for this sort of data, encode the two-letter state abbreviation into a numeric value with value labels."
  },
  {
    "objectID": "04-data-manipulation.html#merging-files",
    "href": "04-data-manipulation.html#merging-files",
    "title": "4  Data Manipulation",
    "section": "4.10 Merging Files",
    "text": "4.10 Merging Files\nWhen managing data sets, the need often arises to merge two data sets together, either by matching two files together according to values on certain variables, or by adding cases to an existing data set. We’ll start with the simpler case of adding cases to an existing data set.\n\n4.10.1 Appending Files\nAppending is straightforward. Observations in a new data set (called the “using” data) are appended to the current data set (called the “master” data), matching variable names. If a variable in the using data exists already in the master data, its values are entered there. If a variable in the using data does not exist in the master, the new variable is added to the appended data set which is missing for all members of the master data. This is easiest to visualize. There are two data sets on Stata’s website which we can append, “odd” and “even”.\n. webuse odd, clear\n(First five odd numbers)\n\n. list\n\n     +--------------+\n     | number   odd |\n     |--------------|\n  1. |      1     1 |\n  2. |      2     3 |\n  3. |      3     5 |\n  4. |      4     7 |\n  5. |      5     9 |\n     +--------------+\n\n. webuse even\n(6th through 8th even numbers)\n\n. list\n\n     +---------------+\n     | number   even |\n     |---------------|\n  1. |      6     12 |\n  2. |      7     14 |\n  3. |      8     16 |\n     +---------------+\nIt does not truly matter which data set is the master data and which is the using data (it will later in match-merging), it will only affect the sorted order (the data in master is sorted first). The syntax is simply\nappend using &lt;using data&gt;\n. webuse even\n(6th through 8th even numbers)\n\n. append using http://www.stata-press.com/data/r16/odd\n(variable number was byte, now float to accommodate using data's values)\n\n. list\n\n     +---------------------+\n     | number   even   odd |\n     |---------------------|\n  1. |      6     12     . |\n  2. |      7     14     . |\n  3. |      8     16     . |\n  4. |      1      .     1 |\n  5. |      2      .     3 |\n     |---------------------|\n  6. |      3      .     5 |\n  7. |      4      .     7 |\n  8. |      5      .     9 |\n     +---------------------+\n(We must specify the complete path to the data instead of the webuse shorthand of just the data name. Of course, with real data that you locally have on your computer, you follow the working directory rules; if the file exists in your working directory you just give the name, otherwise give the complete path. I obtained that path by visiting the Stata data website and finding the link to “odd”.)\nNote that the “number” variable, which exists in both data sets, has complete data, while “even” and “odd” both have missing data as expected. The using part of the command is where the term the “using data” comes from.\nStata is case sensitive in its variable names, so “varname” and “Varname” are two unique variables. We could always fix this later with something like\nreplace varname = Varname if varname == .\nbut it is better to ensure before appending that the shared variables have identical names.\n\n\n4.10.2 Match-merging Data\nA more common data management necessity is to add variables from another data set to a master data set, match-merging the cases in the data sets by values on a single ID variable (or by values on multiple variables). There are two general forms of this match-merging.\nThe first, one-to-one merging, occurs when in each data, each individual is represented by only one row. For example, one data set containing final exam information and one data set containing demographic information. This “1:1” match takes rows which match on some variable(s) and places them together.\nThe second match, many-to-one, occurs when the data are measured on different “levels”. For example, consider if we have one data set containing household level characteristics and another containing town level characters. Two households from the same town would want the same town level data. This is either “1:m” or “m:1” depending on which data is the master data and which is the using data (e.g. 1:m indicates the household data is the master data and town is the using data).\n(Technically there is also many-to-many matching, “m:m”, but it is rarely used in practice.)\nWe’ll use data sets off Stata’s website again to demonstrate, specifically the “autosize” and “autocost” data which splits the “auto” data into two pieces.\n. webuse autosize, clear\n(1978 automobile data)\n\n. list in 1/5\n\n     +------------------------------------+\n     | make               weight   length |\n     |------------------------------------|\n  1. | Toyota Celica       2,410      174 |\n  2. | BMW 320i            2,650      177 |\n  3. | Cad. Seville        4,290      204 |\n  4. | Pont. Grand Prix    3,210      201 |\n  5. | Datsun 210          2,020      165 |\n     +------------------------------------+\n\n. webuse autocost\n(1978 automobile data)\n\n. list in 1/5\n\n     +-----------------------------+\n     |        make   price   rep78 |\n     |-----------------------------|\n  1. | AMC Concord    4099       3 |\n  2. |   AMC Pacer    4749       3 |\n  3. |  AMC Spirit    3799       . |\n  4. |   Audi 5000    9690       5 |\n  5. |    Audi Fox    6295       3 |\n     +-----------------------------+\nNow we can perform the merge using the syntax.\nmerge 1:1 &lt;variables to match on&gt; using &lt;using data set&gt;\nAll that needs to be specified is the variable to match cases by and the name of the data set with variables to be added. We could replace 1:1 with m:1 or 1:m as desired.\n. merge 1:1 make using http://www.stata-press.com/data/r16/autosize\n\n    Result                      Number of obs\n    -----------------------------------------\n    Not matched                            68\n        from master                        68  (_merge==1)\n        from using                          0  (_merge==2)\n\n    Matched                                 6  (_merge==3)\n    -----------------------------------------\n\n. list in 3/6\n\n     +----------------------------------------------------------------+\n     |       make   price   rep78   weight   length            _merge |\n     |----------------------------------------------------------------|\n  3. | AMC Spirit    3799       .        .        .   Master only (1) |\n  4. |  Audi 5000    9690       5        .        .   Master only (1) |\n  5. |   Audi Fox    6295       3        .        .   Master only (1) |\n  6. |   BMW 320i    9735       4    2,650      177       Matched (3) |\n     +----------------------------------------------------------------+\n(Again, we use the full path but for local files, following working directory rules.)\nFirst, take a look at the output of the merge command. We see that 68 cars were not matched, which means they exist in only one of the two data sets. In this case, they all exist in master data, but in general you could see a mix of the two. The remaining 6 observations were appropriately matched. This is a terrible merge! Hopefully with your real data, the majority of data is matched and only a few outliers are not matched.\nNotice the (_merge==#) tags. When you perform a merge, a new variable _merge is added which indicates the source for each row: 1 and 2 indicate the data was only found in the master data or using data respectively, while 3 indicates a match. There are two other possible values (4 and 5) which occur rarely, see the documentation at help merge for details.\nA few notes:\n\nStata will sort both files by the key variables before and after merging.\nYou can match on more than one variable. For example, if you had data based upon year and state, you might run merge 1:1 state year using ...\nIf you wanted to merge another file after the initial merge, you’ll need to drop the _merge variable first.\nIMPORTANT NOTE: Make sure that the only variables common to both files when performing a match-merge are the variables that will be used to match cases (like ID)! Stata will by default keep the variable in the master data when the merge is performed if the same variable appears in more than one file and is not defined as a matching variable. This may cause problems when performing merges. (You can overwrite this behavior with the update or replace options, see the documentation for details.)"
  },
  {
    "objectID": "04-data-manipulation.html#reshaping-files",
    "href": "04-data-manipulation.html#reshaping-files",
    "title": "4  Data Manipulation",
    "section": "4.11 Reshaping Files",
    "text": "4.11 Reshaping Files\nDifferent data formats are needed for various statistical methods. Stata prefers data in “Long” format, but also makes it easy to convert between Long and “Wide”. Stata uses the reshape command to convert data formats.\n\n\n\n\n\nIn this example, the wide format of the data has each row representing a single observation. The variables X1, X2 and X3 are what make this “wide”. These are typically variables measured at different time points, but don’t have to be. In the long format, each row represents an observation at a specific index.\nA nice feature of Stata’s reshape command is that the syntax to convert from wide-to-long or from long-to-wide are identical, except for desired format (long vs wide).\nConvert to long:\nreshape long &lt;stub&gt;, i(&lt;ivar&gt;) j(&lt;jvar&gt;)\nConvert to wide:\nreshape wide &lt;stub&gt;, i(&lt;ivar&gt;) j(&lt;jvar&gt;)\nWe need to identify three components, the stub, ivar and jvar.\n\n“stub”: The stub in wide format is the common prefix of the repeated variables names. In the illustration above, X1, X2 and X3 have the common prefix “X”. In the long format, the stub is simply the name of the variable which is repeated. In the illustration above, X is this variable. Hence the stub is X for both.\n“ivar”: The ivar is the id variable. In the long format, this should be constant across individuals. In both formats above, the id is ID.\n“jvar”: The jvar in long format is the variable that distinguishes which index each repeated measure is from. In the illustration above, Index fills this role. In wide format, this does not exist. So when converting from wide to long, you can use any name for the jvar.\n\nPutting this all together together, the two commands to convert between the illustrations above would be:\nreshape long X, i(ID) j(Index)\nreshape wide X, i(ID) j(Index)\nAs an example, we’ll use the built-in data set “bplong”\n. sysuse bplong, clear\n(Fictional blood-pressure data)\n\n. list in 1/5\n\n     +----------------------------------------+\n     | patient    sex   agegrp     when    bp |\n     |----------------------------------------|\n  1. |       1   Male    30-45   Before   143 |\n  2. |       1   Male    30-45    After   153 |\n  3. |       2   Male    30-45   Before   163 |\n  4. |       2   Male    30-45    After   170 |\n  5. |       3   Male    30-45   Before   153 |\n     +----------------------------------------+\nEach patient has two rows representing their before and after measurements. when indicates which time period the measurement occurs in, and bp is the only time-varying variable (both sex and agegrp are constant, presumably the “Before” and “After” occur within a short time period such that neither of those can change). Let’s identify the three components\n\n“stub”: Since we’re going from long to wide, the “stub” is any time-varying variables, here only bp.\n“ivar”: patient identifies individuals.\n“jvar”: when identifies time period.\n\nPutting this together,\n. reshape wide bp, i(patient) j(when)\n(j = 1 2)\n\nData                               Long   -&gt;   Wide\n-----------------------------------------------------------------------------\nNumber of observations              240   -&gt;   120         \nNumber of variables                   5   -&gt;   5           \nj variable (2 values)              when   -&gt;   (dropped)\nxij variables:\n                                     bp   -&gt;   bp1 bp2\n-----------------------------------------------------------------------------\n\n. list in 1/5\n\n     +-------------------------------------+\n     | patient   bp1   bp2    sex   agegrp |\n     |-------------------------------------|\n  1. |       1   143   153   Male    30-45 |\n  2. |       2   163   170   Male    30-45 |\n  3. |       3   153   168   Male    30-45 |\n  4. |       4   153   142   Male    30-45 |\n  5. |       5   146   141   Male    30-45 |\n     +-------------------------------------+\nEach row represents a single patient, and bp1 and bp2 represent the before and after measurements.\nLet’s generate the command to convert back to long.\n\n“stub”: “bp” is the stub of bp1 and bp2.\n“ivar”: patient identifies individuals.\n“jvar”: Since the data is currently wide, there is no existing jvar and we can call it whatever we like. For consistency, we’ll call it “when” again.\n\nThe command is identical! Just swap wide for long.\n. reshape long bp, i(patient) j(when)\n(j = 1 2)\n\nData                               Wide   -&gt;   Long\n-----------------------------------------------------------------------------\nNumber of observations              120   -&gt;   240         \nNumber of variables                   5   -&gt;   5           \nj variable (2 values)                     -&gt;   when\nxij variables:\n                                bp1 bp2   -&gt;   bp\n-----------------------------------------------------------------------------\n\n. list in 1/5\n\n     +----------------------------------------+\n     | patient     when    bp    sex   agegrp |\n     |----------------------------------------|\n  1. |       1   Before   143   Male    30-45 |\n  2. |       1    After   153   Male    30-45 |\n  3. |       2   Before   163   Male    30-45 |\n  4. |       2    After   170   Male    30-45 |\n  5. |       3   Before   153   Male    30-45 |\n     +----------------------------------------+\nThe variables are slightly out of order, but we’ve completely recovered the original data.\nAfter you’ve run a single reshape command, and assuming nothing has changed (you do not want to change stub, ivar or jvar, and the variables in the data are the same), you can convert between wide and long without specifying anything. Try it:\nreshape wide\nreshape long\nNow, notice that when we reshaped the original long data into wide format, the two “bp” variables where bp1 and bp2, not something like bp_before and bp_after. In most cases this is fine (as the common use case for this is repeated measures over time), but not always - what if we wanted to save the “before” and “after” labels? Do note that thankfully Stata saves these labels, so when converting back to long, it restores the “Before” and “After” tags.\nIf you do want to save the text instead of the count, you need to use strings. We’ll use decode to convert to a string, then use that as the jvar.\n. decode when, gen(when2)\n\n. drop when\n\n. rename when2 when\n\n. reshape wide bp, i(patient) j(when) string\n(j = After Before)\n\nData                               Long   -&gt;   Wide\n-----------------------------------------------------------------------------\nNumber of observations              240   -&gt;   120         \nNumber of variables                   5   -&gt;   5           \nj variable (2 values)              when   -&gt;   (dropped)\nxij variables:\n                                     bp   -&gt;   bpAfter bpBefore\n-----------------------------------------------------------------------------\n\n. list in 1/5\n\n     +----------------------------------------------+\n     | patient   bpAfter   bpBefore    sex   agegrp |\n     |----------------------------------------------|\n  1. |       1       153        143   Male    30-45 |\n  2. |       2       170        163   Male    30-45 |\n  3. |       3       168        153   Male    30-45 |\n  4. |       4       142        153   Male    30-45 |\n  5. |       5       141        146   Male    30-45 |\n     +----------------------------------------------+\nNote the string option. When converting back to long, you’ll need to encode the string to get it back to numeric.\n. reshape long\n(j = After Before)\n\nData                               Wide   -&gt;   Long\n-----------------------------------------------------------------------------\nNumber of observations              120   -&gt;   240         \nNumber of variables                   5   -&gt;   5           \nj variable (2 values)                     -&gt;   when\nxij variables:\n                       bpAfter bpBefore   -&gt;   bp\n-----------------------------------------------------------------------------\n\n. desc when\n\nVariable      Storage   Display    Value\n    name         type    format    label      Variable label\n-------------------------------------------------------------------------------\nwhen            str6    %9s                   Status\n\n. encode when, gen(when2)\n\n. drop when\n\n. rename when2 when\n\n. desc when\n\nVariable      Storage   Display    Value\n    name         type    format    label      Variable label\n-------------------------------------------------------------------------------\nwhen            long    %8.0g      when2      Status\nA few notes:\n\nIf you have wide data and some individuals are missing some repeated measures, when converting to tall, they will still have a row with a blank value. You can easily drop it:\nreshape long\ndrop if &lt;varname&gt; == .\nConverting back to wide will re-enter those missing values; reshape does not care if the long data is “complete”.\nMore than one stub can be entered if you have more than one repeated measurement. For example, if the variables were {“id”, “x1”, “x2”, “y1”, “y2”}, you could enter\nreshape long x y, i(id) j(index)\nNote that they technically don’t have to have the same indices (e.g. you could have “x1”, “x2”, “y3”, “y4”) although that would create a weird result where each row of index 1 or 2 is missing y and each row of index 3 or 4 is missing x.\nIf you have wide data and many time-varying variables, there is no shorthand for entering all the stubs. For large data, this is extremely frustrating. I’d recommend using describe, simple to get a list of all variable names, then using find & replace to remove the indices. If you know a better way, let me know!"
  },
  {
    "objectID": "04-data-manipulation.html#footnotes",
    "href": "04-data-manipulation.html#footnotes",
    "title": "4  Data Manipulation",
    "section": "",
    "text": "If you want log with a different base, you can use the transformation that dividing by log(b) is equivalent to using b as a base. In other words, if you need log base 10, use gen newvar = log(oldvar)/log(10).↩︎\nTechnically and mathematically they can take on any two values, but your life will be easier if you stick with the 0/1 convention.↩︎\nThis is true of most statistical software in fact.↩︎\nWe’ll see some exceptions to this in the programming section.↩︎\negen is not a short command for “egenerate”; the full command name is simply “egen”.↩︎\ngenerate has a few features we do not discuss which replace does not support. Namely, generate can set the type manually (instead of letting Stata choose the best type automatically), and generate can place the new variable as desired rather than using order. Clearly, neither of these features are needed for replace.↩︎\nNote that this is not a statistical claim, we would have to do a two-sample t-test to make any statistical claim.↩︎\nI’m explcitly writing the quotations here as otherwise it would just look missing. The quotations aren’t part of the saved string.↩︎\nIf you are sharp-eyed, you may have noticed that the original mpg was an “int” whereas the final one is a “byte”. If we had called compress on the original data, it would have done that type conversion anyways - so we’re ok!↩︎"
  },
  {
    "objectID": "05-programming.html#macros",
    "href": "05-programming.html#macros",
    "title": "5  Programming & Advanced Features",
    "section": "5.1 Macros",
    "text": "5.1 Macros\nWhile variables stored as strings aren’t of much use to us, strings stored as other strings can be quite useful. Imagine the following scenario: You have a collection of 5 variables that you want to perform several different operations on. You might have code like this:\nlist var1 var2 var3 var4 var5 in 1/5\nsumm var1 var2 var3 var4 var5\nlabel define mylab 0 \"No\" 1 \"Yes\"\nlabel values var1 var2 var3 var4 var5 mylab\nduplicates list var1 var2 var3 var4 var5\nThis can get extremely tedious as the number of variables and commands increases. You could copy and paste a lot, but even that takes a lot of effort.\nInstead, we can store the list of variables (strictly speaking, the string which contains the list of variables) in a shorter key string, and refer to that instead!\nlocal vars = \"var1 var2 var3 var4 var5\"\nlist `vars' in 1/5\nsumm `vars'\nlabel define mylab 0 \"No\" 1 \"Yes\"\nlabel values `vars' mylab\nduplicates list `vars'\nThe first command, local, defines what is known as a “local macro”1. Whenever it is referred to, wrapped in a backtick (to the left of the 1 key at the top-left of the keyboard) and a single quote, Stata replaces it with the original text. So when you enter\nlist `vars' in 1/5\nStata immediately replaces \\`vars’ with var1 var2 var3 var4 var5, then executes\nlist var1 var2 var3 var4 var5 in 1/5\nImportant: Local macros are deleted as soon as code finishes executing! That means that you must use them in a do-file, and you must run all lines which create and access the macro at the same time, by highlighting them all.\nSome other notes:\n\nIf your macro contains text that should be quoted, you still need to quote it when accessing. For example, if you had\nlabel variable price1 \"Price (in dollars) at Time Point 1\"\nlabel variable price2 \"Price (in dollars) at Time Point 2\"\nyou could instead write\nlocal pricelab = \"Price (in dollars) at Time Point\"\nlabel variable price1 \"`pricelab' 1\"\nlabel variable price2 \"`pricelab' 2\"\nYou can use display to print the content of macros to the output to preview them.\n\n. local test = \"abc\"\n\n. display \"`test'\"\nabc\n\nYou may occasionally see code that excludes the = in defining a macro (e.g. local vars \"var1 var2\"). The differences between including and excluding the = are mostly unimportant, so I recommend sticking with the = unless you specifically need the other version.\n\n\n5.1.1 Class and Return\nEvery command in Stata is of a particular type. One major aspect of the type is what the command “returns”. Some commands are n-class, which means they don’t return anything. Some are c-class, which are only used by programmers and rarely useful elsewhere. The two common ones are e-class and r-class. The distinction between the two is inconsequential, besides that they store their “returns” in different places.\nHere, summarize is a r-class command, so it stores its returns in “return”. We can see them all by return list. On the other hand, mean (which we haven’t discussed, but basically displays summary statistics similar to summarize but provides some additional functionality) is an e-class command, storing its results in ereturn:\n. summ price\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n       price |         74    6165.257    2949.496       3291      15906\n\n. return list\n\nscalars:\n                  r(N) =  74\n              r(sum_w) =  74\n               r(mean) =  6165.256756756757\n                r(Var) =  8699525.974268788\n                 r(sd) =  2949.495884768919\n                r(min) =  3291\n                r(max) =  15906\n                r(sum) =  456229\n\n. mean price\n\nMean estimation                             Number of obs = 74\n\n--------------------------------------------------------------\n             |       Mean   Std. err.     [95% conf. interval]\n-------------+------------------------------------------------\n       price |   6165.257   342.8719      5481.914      6848.6\n--------------------------------------------------------------\n\n. ereturn list\n\nscalars:\n               e(df_r) =  73\n             e(N_over) =  1\n                  e(N) =  74\n               e(k_eq) =  1\n               e(rank) =  1\n\nmacros:\n            e(cmdline) : \"mean price\"\n                e(cmd) : \"mean\"\n                e(vce) : \"analytic\"\n              e(title) : \"Mean estimation\"\n          e(estat_cmd) : \"estat_vce_only\"\n            e(varlist) : \"price\"\n       e(marginsnotok) : \"_ALL\"\n         e(properties) : \"b V\"\n\nmatrices:\n                  e(b) :  1 x 1\n                  e(V) :  1 x 1\n                 e(sd) :  1 x 1\n                 e(_N) :  1 x 1\n              e(error) :  1 x 1\n\nfunctions:\n             e(sample)   \nRather than try and keep track of what gets stored where, if you look at the very bottom of any help file, it will say something like “summarize stores the following in r():” or “mean stores the following in e():”, corresponding to return and ereturn respectively.\nAlong with the [One Data][one data] principal, Stata also follows the One _-class principal - meaning you can only view the return or ereturn for the most recent command of that class. So if you run a summarize command, then do a bunch of n-class calls (gsort for example), the return list call will still give you the returns for that first summarize. However, as soon as you run another r-class command, you lose access to the first one. You can save any piece of it using a macro. For example, to calculate the average difference in price between foreign and domestic cars2:\n. summ price if foreign == 1\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n       price |         22    6384.682    2621.915       3748      12990\n\n. local fprice = r(mean)\n\n. summ price if foreign == 0\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n       price |         52    6072.423    3097.104       3291      15906\n\n. local dprice = r(mean)\n\n. display `dprice' - `fprice'\n-312.25874"
  },
  {
    "objectID": "05-programming.html#variable-lists",
    "href": "05-programming.html#variable-lists",
    "title": "5  Programming & Advanced Features",
    "section": "5.2 Variable Lists",
    "text": "5.2 Variable Lists\nIntroduced in Stata 16, variable lists solves a common technique used in previous versions of Stata to define a global containing a list of variables to be used later in the document. For example, you might see something like this at the top of a Do file:\nglobal predictors x1 x2 x3 x4\nthen further down the document something like\nregress y $predictors\nlogit z $predictors\nStata has formalized this concept with the addition of the vl command (variable list). It works similarly to the use of globals: lists of variables are defined, then later reference via the $name syntax. However, using vl has the benefits of improved organization, customizations unique to variable lists, error checking, and overall convenience.\n\n5.2.1 Initialization of Variable Lists\nTo begin using variable lists, vl set must be run.\n. sysuse auto\n(1978 automobile data)\n\n. vl set\n\n-------------------------------------------------------------------------------\n                  |                      Macro's contents\n                  |------------------------------------------------------------\nMacro             |  # Vars   Description\n------------------+------------------------------------------------------------\nSystem            |\n  $vlcategorical  |       2   categorical variables\n  $vlcontinuous   |       2   continuous variables\n  $vluncertain    |       7   perhaps continuous, perhaps categorical variables\n  $vlother        |       0   all missing or constant variables\n-------------------------------------------------------------------------------\nNotes\n\n      1. Review contents of vlcategorical and vlcontinuous to ensure they are\n         correct.  Type vl list vlcategorical and type vl list vlcontinuous.\n\n      2. If there are any variables in vluncertain, you can reallocate them\n         to vlcategorical, vlcontinuous, or vlother.  Type\n         vl list vluncertain.\n\n      3. Use vl move to move variables among classifications.  For example,\n         type vl move (x50 x80) vlcontinuous to move variables x50 and x80 to\n         the continuous classification.\n\n      4. vlnames are global macros.  Type the vlname without the leading\n         dollar sign ($) when using vl commands.  Example: vlcategorical not\n         $vlcategorical.  Type the dollar sign with other Stata commands to\n         get a varlist.\nThis produces a surprisingly large amount of output. When you initialize the use of variable lists, Stata will automatically create four variable lists, called the “System variable lists”. Every numeric variable in the current data set is automatically placed into one of these four lists:\n\nvlcategorical: Variables which Stata thinks are categorical. These generally have to be non-negative, integer valued variables with less than 10 unique values.\nvlcontinuous: Variables which Stata thinks are continuous. These generally are variables which have negative values, have non-integer values, or are non-negative integers with more than 100 unique values.\nvluncertain: Variables which Stata is unsure whether they are continuous or categorical. These generally are non-negative integer valued variables with between 10 and 100 unique values.\nvlother: Any numeric variables that aren’t really useful - either all missing or constant variables.\n\nThere is a potential fifth system variable list, vldummy, which is created when option dummy is passed. Unsurprisingly, this will take variables containing only values 0 and 1 out of vlcategorical and into this list.\nThe “Notes” given below the output are generic; they appear regardless of how well Stata was able to categorize the variables. They can be suppressed with the nonotes option to vl set3.\nThe two thresholds given above, 10 and 100, can be adjusted by the categorical and uncertain options. For example,\nvl set, categorical(20) uncertain(50)\nRunning vl set on an already vl-set data set will result in an error, unless the clear option is given, which will re-generate the lists.\n. vl set, dummy nonotes\none or more already classified variables specified\n    You requested that variables be added to vl's system classifications, but\n    you specified 11 variables that were already classified.\nr(110);\n\n. vl set, dummy nonotes clear\n\n-------------------------------------------------------------------------------\n                  |                      Macro's contents\n                  |------------------------------------------------------------\nMacro             |  # Vars   Description\n------------------+------------------------------------------------------------\nSystem            |\n  $vldummy        |       1   0/1 variable\n  $vlcategorical  |       1   categorical variable\n  $vlcontinuous   |       2   continuous variables\n  $vluncertain    |       7   perhaps continuous, perhaps categorical variables\n  $vlother        |       0   all missing or constant variables\n-------------------------------------------------------------------------------\nIn the above, we changed our minds and wanted to include the vldummy list, but since we’d already vl-set, we had the clear the existing set.\n\n\n5.2.2 Viewing lists\nWhen initializing the variable lists, we’re treated to a nice table of all defined lists. We can replay it via\n. vl dir\n\n-------------------------------------------------------------------------------\n                  |                      Macro's contents\n                  |------------------------------------------------------------\nMacro             |  # Vars   Description\n------------------+------------------------------------------------------------\nSystem            |\n  $vldummy        |       1   0/1 variable\n  $vlcategorical  |       1   categorical variable\n  $vlcontinuous   |       2   continuous variables\n  $vluncertain    |       7   perhaps continuous, perhaps categorical variables\n  $vlother        |       0   all missing or constant variables\n-------------------------------------------------------------------------------\nTo see the actual contents of the variable lists, we’ll need to sue vl list.\n. vl list\n\n----------------------------------------------------\n    Variable | Macro           Values         Levels\n-------------+--------------------------------------\n     foreign | $vldummy        0 and 1             2\n       rep78 | $vlcategorical  integers &gt;=0        5\n    headroom | $vlcontinuous   noninteger           \n  gear_ratio | $vlcontinuous   noninteger           \n       price | $vluncertain    integers &gt;=0       74\n         mpg | $vluncertain    integers &gt;=0       21\n       trunk | $vluncertain    integers &gt;=0       18\n      weight | $vluncertain    integers &gt;=0       64\n      length | $vluncertain    integers &gt;=0       47\n        turn | $vluncertain    integers &gt;=0       18\ndisplacement | $vluncertain    integers &gt;=0       31\n----------------------------------------------------\nThis output produces one row for each variable in each variable list it is in. We haven’t used this yet, but variables can be in multiple lists.\nWe can list only specific lists:\n. vl list vlcategorical\n\n------------------------------------------------\nVariable | Macro           Values         Levels\n---------+--------------------------------------\n   rep78 | $vlcategorical  integers &gt;=0        5\n------------------------------------------------\nor specific variables\n. vl list (turn weight)\n\n------------------------------------------------\nVariable | Macro           Values         Levels\n---------+--------------------------------------\n    turn | $vluncertain    integers &gt;=0       18\n  weight | $vluncertain    integers &gt;=0       64\n------------------------------------------------\nIf “turn” was in multiple variable lists, each would appear as a row in this output.\nThere’s a bit of odd notation which can be used to sort the output by variable name, which makes it easier to identify variables which appear in multiple lists.\n. vl list (_all), sort\n\n----------------------------------------------------\n    Variable | Macro           Values         Levels\n-------------+--------------------------------------\ndisplacement | $vluncertain    integers &gt;=0       31\n     foreign | $vldummy        0 and 1             2\n  gear_ratio | $vlcontinuous   noninteger           \n    headroom | $vlcontinuous   noninteger           \n      length | $vluncertain    integers &gt;=0       47\n         mpg | $vluncertain    integers &gt;=0       21\n       price | $vluncertain    integers &gt;=0       74\n       rep78 | $vlcategorical  integers &gt;=0        5\n       trunk | $vluncertain    integers &gt;=0       18\n        turn | $vluncertain    integers &gt;=0       18\n      weight | $vluncertain    integers &gt;=0       64\n----------------------------------------------------\nThe (_all) tells Stata to report on all variables, and sorting (when you specify at least one variable) orders by variable name rather than variable list name.\nThis will also list any numeric variables which are not found in any list.\n\n5.2.2.1 Moving variables in system lists\nAfter initializing the variable lists, if you plan on using the system lists, you may need to move variables around (e.g. classifying the vluncertain variables into their proper lists). This can be done via vl move which has the syntax\nvl move (&lt;variables to move&gt;) &lt;destination list&gt;\nFor example, all the variables in vluncertain are actually continuous:\n. vl list vluncertain\n\n----------------------------------------------------\n    Variable | Macro           Values         Levels\n-------------+--------------------------------------\n       price | $vluncertain    integers &gt;=0       74\n         mpg | $vluncertain    integers &gt;=0       21\n       trunk | $vluncertain    integers &gt;=0       18\n      weight | $vluncertain    integers &gt;=0       64\n      length | $vluncertain    integers &gt;=0       47\n        turn | $vluncertain    integers &gt;=0       18\ndisplacement | $vluncertain    integers &gt;=0       31\n----------------------------------------------------\n\n. vl move (price mpg trunk weight length turn displacement) vlcontinuous\nnote: 7 variables specified and 7 variables moved.\n\n------------------------------\nMacro          # Added/Removed\n------------------------------\n$vldummy                     0\n$vlcategorical               0\n$vlcontinuous                7\n$vluncertain                -7\n$vlother                     0\n------------------------------\n\n. vl dir\n\n-------------------------------------------------------------------------------\n                  |                      Macro's contents\n                  |------------------------------------------------------------\nMacro             |  # Vars   Description\n------------------+------------------------------------------------------------\nSystem            |\n  $vldummy        |       1   0/1 variable\n  $vlcategorical  |       1   categorical variable\n  $vlcontinuous   |       9   continuous variables\n  $vluncertain    |       0   perhaps continuous, perhaps categorical variables\n  $vlother        |       0   all missing or constant variables\n-------------------------------------------------------------------------------\nAlternatively, since we’re moving all variables in vluncertain, we can see our first use of the variable list!\n. vl set, dummy nonotes clear\n\n-------------------------------------------------------------------------------\n                  |                      Macro's contents\n                  |------------------------------------------------------------\nMacro             |  # Vars   Description\n------------------+------------------------------------------------------------\nSystem            |\n  $vldummy        |       1   0/1 variable\n  $vlcategorical  |       1   categorical variable\n  $vlcontinuous   |       2   continuous variables\n  $vluncertain    |       7   perhaps continuous, perhaps categorical variables\n  $vlother        |       0   all missing or constant variables\n-------------------------------------------------------------------------------\n\n. vl move ($vluncertain) vlcontinuous\nnote: 7 variables specified and 7 variables moved.\n\n------------------------------\nMacro          # Added/Removed\n------------------------------\n$vldummy                     0\n$vlcategorical               0\n$vlcontinuous                7\n$vluncertain                -7\n$vlother                     0\n------------------------------\nNote that variable lists are essentially just global macros so can be referred to via \\$name. Note, however, that the \\$ is only used when we want to actually use the variable list as a macro - in this case, we wanted to expand vluncertain into it’s list of variables. When we’re referring to a variable list in the vl commands, we do not use the \\$.\n\n\n\n5.2.3 User Variable Lists\nIn addition to the System variable lists, you can define your own User variables lists, which I imagine will be used far more often. These are easy to create with vl create:\n. vl create mylist1 = (weight mpg)\nnote: $mylist1 initialized with 2 variables.\n\n. vl create mylist2 = (weight length trunk)\nnote: $mylist2 initialized with 3 variables.\n\n. vl dir, user\n\n-------------------------------------------------------------------------------\n                  |                      Macro's contents\n                  |------------------------------------------------------------\nMacro             |  # Vars   Description\n------------------+------------------------------------------------------------\nUser              |\n  $mylist1        |       2   variables\n  $mylist2        |       3   variables\n-------------------------------------------------------------------------------\n\n. vl list, user\n\n------------------------------------------------\nVariable | Macro           Values         Levels\n---------+--------------------------------------\n  weight | $mylist1        integers &gt;=0       64\n     mpg | $mylist1        integers &gt;=0       21\n  weight | $mylist2        integers &gt;=0       64\n  length | $mylist2        integers &gt;=0       47\n   trunk | $mylist2        integers &gt;=0       18\n------------------------------------------------\nNote the addition of the user option to vl list and vl dir to show only User variable lists and suppress the System variable lists. We can also demonstrate the odd sorting syntax here:\n. vl list (_all), sort user\n\n----------------------------------------------------\n    Variable | Macro           Values         Levels\n-------------+--------------------------------------\ndisplacement | not in vluser                      31\n     foreign | not in vluser                       2\n  gear_ratio | not in vluser                        \n    headroom | not in vluser                        \n      length | $mylist2        integers &gt;=0       47\n         mpg | $mylist1        integers &gt;=0       21\n       price | not in vluser                      74\n       rep78 | not in vluser                       5\n       trunk | $mylist2        integers &gt;=0       18\n        turn | not in vluser                      18\n      weight | $mylist1        integers &gt;=0       64\n      weight | $mylist2        integers &gt;=0       64\n----------------------------------------------------\nYou can refer to variable lists in all the usual shortcut ways:\nvl create mylist = (x1-x100 z*)\nWe can add labels to variable lists:\n. vl label mylist1 \"Related to gas consumption\"\n\n. vl label mylist2 \"Related to size\"\n\n. vl dir, user\n\n-------------------------------------------------------------------------------\n                  |                      Macro's contents\n                  |------------------------------------------------------------\nMacro             |  # Vars   Description\n------------------+------------------------------------------------------------\nUser              |\n  $mylist1        |       2   Related to gas consumption\n  $mylist2        |       3   Related to size\n-------------------------------------------------------------------------------\n\n5.2.3.1 Modifying User Variable Lists\nFirst, note that with User Variable Lists, the vl move command does not work. It only works with system variable lists.\nWe can create new user variable lists which build off old lists with vl create. To add a new variable:\n. vl create mylist3 = mylist2 + (gear_ratio)\nnote: $mylist3 initialized with 4 variables.\n\n. vl list, user\n\n--------------------------------------------------\n  Variable | Macro           Values         Levels\n-----------+--------------------------------------\n    weight | $mylist1        integers &gt;=0       64\n       mpg | $mylist1        integers &gt;=0       21\n    weight | $mylist2        integers &gt;=0       64\n    length | $mylist2        integers &gt;=0       47\n     trunk | $mylist2        integers &gt;=0       18\n    weight | $mylist3        integers &gt;=0       64\n    length | $mylist3        integers &gt;=0       47\n     trunk | $mylist3        integers &gt;=0       18\ngear_ratio | $mylist3        noninteger           \n--------------------------------------------------\n\n. vl create mylist4 = mylist2 - (turn)\nnote: $mylist4 initialized with 3 variables.\n\n. vl list, user\n\n--------------------------------------------------\n  Variable | Macro           Values         Levels\n-----------+--------------------------------------\n    weight | $mylist1        integers &gt;=0       64\n       mpg | $mylist1        integers &gt;=0       21\n    weight | $mylist2        integers &gt;=0       64\n    length | $mylist2        integers &gt;=0       47\n     trunk | $mylist2        integers &gt;=0       18\n    weight | $mylist3        integers &gt;=0       64\n    length | $mylist3        integers &gt;=0       47\n     trunk | $mylist3        integers &gt;=0       18\ngear_ratio | $mylist3        noninteger           \n    weight | $mylist4        integers &gt;=0       64\n    length | $mylist4        integers &gt;=0       47\n     trunk | $mylist4        integers &gt;=0       18\n--------------------------------------------------\nInstead of adding (or removing) single variables at a time, we can instead add or remove lists. Keeping with the comment above, you do not use \\$ here to refer to the list.\n. vl create mylist5 = mylist2 - mylist1\nnote: $mylist5 initialized with 2 variables.\n\n. vl list mylist5\n\n------------------------------------------------\nVariable | Macro           Values         Levels\n---------+--------------------------------------\n  length | $mylist5        integers &gt;=0       47\n   trunk | $mylist5        integers &gt;=0       18\n------------------------------------------------\nHowever, if we want to simply modify an existing list, a better approach would be the vl modify command. vl create and vl modify are similar to generate and replace; the former creates a new variable list while the later changes an existing variable list, but the syntax right of the = is the same.\n. vl modify mylist3 = mylist3 + (headroom)\nnote: 1 variable added to $mylist3.\n\n. vl modify mylist3 = mylist3 - (weight)\nnote: 1 variable removed from $mylist3.\n\n\n\n5.2.4 Dropping variable list\nVariable lists can be dropped via vl drop\n. vl dir, user\n\n-------------------------------------------------------------------------------\n                  |                      Macro's contents\n                  |------------------------------------------------------------\nMacro             |  # Vars   Description\n------------------+------------------------------------------------------------\nUser              |\n  $mylist1        |       2   Related to gas consumption\n  $mylist2        |       3   Related to size\n  $mylist3        |       4   variables\n  $mylist4        |       3   variables\n  $mylist5        |       2   variables\n-------------------------------------------------------------------------------\n\n. vl drop mylist4 mylist5\n\n. vl dir, user\n\n-------------------------------------------------------------------------------\n                  |                      Macro's contents\n                  |------------------------------------------------------------\nMacro             |  # Vars   Description\n------------------+------------------------------------------------------------\nUser              |\n  $mylist1        |       2   Related to gas consumption\n  $mylist2        |       3   Related to size\n  $mylist3        |       4   variables\n-------------------------------------------------------------------------------\nSystem lists cannot be dropped; if you run vl drop vlcontinuous it just removes all the variables from it.\n\n\n5.2.5 Using Variable Lists\nTo be explicit, we can use variable lists in any command which would take the variables in that list. For example,\n. describe $mylist3\n\nVariable      Storage   Display    Value\n    name         type    format    label      Variable label\n-------------------------------------------------------------------------------\nlength          int     %8.0g                 Length (in.)\ntrunk           int     %8.0g                 Trunk space (cu. ft.)\ngear_ratio      float   %6.2f                 Gear ratio\nheadroom        float   %6.1f                 Headroom (in.)\n\n. describe $vlcategorical\n\nVariable      Storage   Display    Value\n    name         type    format    label      Variable label\n-------------------------------------------------------------------------------\nrep78           int     %8.0g                 Repair record 1978\nWe can also use them in a modeling setting.\n. regress mpg $mylist3\n\n      Source |       SS           df       MS      Number of obs   =        74\n-------------+----------------------------------   F(4, 69)        =     30.77\n       Model |  1565.65298         4  391.413244   Prob &gt; F        =    0.0000\n    Residual |  877.806484        69  12.7218331   R-squared       =    0.6408\n-------------+----------------------------------   Adj R-squared   =    0.6199\n       Total |  2443.45946        73  33.4720474   Root MSE        =    3.5668\n\n------------------------------------------------------------------------------\n         mpg | Coefficient  Std. err.      t    P&gt;|t|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n      length |  -.1837962   .0327629    -5.61   0.000    -.2491564   -.1184361\n       trunk |  -.0103867   .1627025    -0.06   0.949    -.3349693    .3141959\n  gear_ratio |   1.526952    1.27546     1.20   0.235    -1.017521    4.071426\n    headroom |   .0136375   .6602514     0.02   0.984    -1.303528    1.330803\n       _cons |   51.33708   8.300888     6.18   0.000     34.77727     67.8969\n------------------------------------------------------------------------------\nHowever, we’ll run into an issue here - how to specify categorical variables or interactions? The vl substitute command creates “factor-variable lists” that can include factor variable indicators (i.), continuous variable indicators (c.), and interactions (# or ##). (The name “factor-variable list” is slightly disingenuous; you could create a “factor-variable list” that includes no actual factors, for example, if you wanted to interact two continuous variables.)\nCreating a factor-varible list via vl substitute can be done by specifying variables or variable lists.\n. vl substitute sublist1 = mpg mylist3\n\n. display \"$sublist1\"\nmpg length trunk gear_ratio headroom\n\n. vl dir\n\n-------------------------------------------------------------------------------\n                  |                      Macro's contents\n                  |------------------------------------------------------------\nMacro             |  # Vars   Description\n------------------+------------------------------------------------------------\nSystem            |\n  $vldummy        |       1   0/1 variable\n  $vlcategorical  |       1   categorical variable\n  $vlcontinuous   |       9   continuous variables\n  $vluncertain    |       0   perhaps continuous, perhaps categorical variables\n  $vlother        |       0   all missing or constant variables\nUser              |\n  $mylist1        |       2   Related to gas consumption\n  $mylist2        |       3   Related to size\n  $mylist3        |       4   variables\n  $sublist1       |           factor-variable list\n-------------------------------------------------------------------------------\nNote the use of display \"\\$listname\" instead of vl list. Factor-variable lists are not just lists of vairables, they also can include the features above, so must be displayed. Note that in the vl dir, “sublist1” has no number of variables listed, making it stand apart.\nWe can make this more interesting by actually including continuous/factor indicatores and/or interactions.\n. vl substitute sublist2 = c.mylist1##i.vldummy\n\n. display \"$sublist2\"\nweight mpg i.foreign i.foreign#c.weight i.foreign#c.mpg\nNote the need to specify that mylist1 is continuous (with c.). It follows the normal convention that Stata assumes predictors in a model are continuous by default, unless they’re invloved in an interaction, in which case it assumes they are factors by default.\n. regress price $sublist2\n\n      Source |       SS           df       MS      Number of obs   =        74\n-------------+----------------------------------   F(5, 68)        =     16.82\n       Model |   351163805         5  70232760.9   Prob &gt; F        =    0.0000\n    Residual |   283901591        68   4175023.4   R-squared       =    0.5530\n-------------+----------------------------------   Adj R-squared   =    0.5201\n       Total |   635065396        73  8699525.97   Root MSE        =    2043.3\n\n------------------------------------------------------------------------------\n       price | Coefficient  Std. err.      t    P&gt;|t|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n      weight |   4.415037   .8529259     5.18   0.000      2.71305    6.117024\n         mpg |    237.691   125.0383     1.90   0.062    -11.81907     487.201\n             |\n     foreign |\n    Foreign  |   8219.603   7265.713     1.13   0.262    -6278.902    22718.11\n             |\n     foreign#|\n    c.weight |\n    Foreign  |   .7408054   1.647504     0.45   0.654    -2.546738    4.028348\n             |\n     foreign#|\n       c.mpg |\n    Foreign  |  -257.4683    155.426    -1.66   0.102     -567.616    52.67938\n             |\n       _cons |  -13285.44   5149.648    -2.58   0.012    -23561.41   -3009.481\n------------------------------------------------------------------------------\n\n5.2.5.1 Updating factor-variable Lists\nFactor-variable lists cannot be directly modified.\n. display \"$sublist1\"\nmpg length trunk gear_ratio headroom\n\n. vl modify sublist1 = sublist1 - mpg\nsublist1 not allowed\n    vlusernames containing factor variables not allowed in this context\n    r(198);\nHowever, if you create a factor-variable list using only other variable lists, if those lists get updated, so does the factor-variable list!\n. vl create continuous = (turn trunk)\nnote: $continuous initialized with 2 variables.\n\n. vl create categorical = (rep78 foreign)\nnote: $categorical initialized with 2 variables.\n\n. vl substitute predictors = c.continuous##i.categorical\n\n. display \"$predictors\"\nturn trunk i.rep78 i.foreign i.rep78#c.turn i.foreign#c.turn i.rep78#c.trunk i.\n&gt; foreign#c.trunk\n\n. vl modify continuous = continuous - (trunk)\nnote: 1 variable removed from $continuous.\n\n. quiet vl rebuild\n\n. display \"$predictors\"\nturn i.rep78 i.foreign i.rep78#c.turn i.foreign#c.turn\nNote the call to vl rebuild. Among other things, it will re-generate the factor-variable lists. (It produces a vl dir output without an option to suppress it, hence the use of quiet.)\n\n\n\n5.2.6 Stored Statistics\nYou may have noticed that certain characteristics of the variable are reported.\n. vl list mylist3\n\n--------------------------------------------------\n  Variable | Macro           Values         Levels\n-----------+--------------------------------------\n  headroom | $mylist3        noninteger           \n     trunk | $mylist3        integers &gt;=0       18\n    length | $mylist3        integers &gt;=0       47\ngear_ratio | $mylist3        noninteger           \n--------------------------------------------------\nThis reports some characteristics of the variables (integer, whether it’s non-negative) and the number of unique values. We can also see some other statistics:\n. vl list mylist3, min max obs\n\n-------------------------------------------------------------------------------\nVariable | Macro           Values         Levels       Min       Max        Obs\n---------+---------------------------------------------------------------------\nheadroom | $mylist3        noninteger                  1.5         5         74\n   trunk | $mylist3        integers &gt;=0       18         5        23         74\n  length | $mylist3        integers &gt;=0       47       142       233         74\ngear_r~o | $mylist3        noninteger                 2.19      3.89         74\n-------------------------------------------------------------------------------\nThis is similar to codebook except faster; these characteristics are saved at the time the variable list is created or modified and not updated automatically. If the data changes, this does not get updated.\n. drop if weight &lt; 3000\n(35 observations deleted)\n\n. summarize weight\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n      weight |         39    3653.846    423.5788       3170       4840\n\n. vl list (weight), min max obs\n\n-------------------------------------------------------------------------------\nVariable | Macro           Values         Levels       Min       Max        Obs\n---------+---------------------------------------------------------------------\n  weight | $vlcontinuous   integers &gt;=0       64      1760      4840         74\n  weight | $mylist1        integers &gt;=0       64      1760      4840         74\n  weight | $mylist2        integers &gt;=0       64      1760      4840         74\n-------------------------------------------------------------------------------\nTo re-generate these stored statistics, we call vl set again, with the update option.\n. vl set, update\n\n-------------------------------------------------------------------------------\n                  |                      Macro's contents\n                  |------------------------------------------------------------\nMacro             |  # Vars   Description\n------------------+------------------------------------------------------------\nSystem            |\n  $vldummy        |       1   0/1 variable\n  $vlcategorical  |       1   categorical variable\n  $vlcontinuous   |       9   continuous variables\n  $vluncertain    |       0   perhaps continuous, perhaps categorical variables\n  $vlother        |       0   all missing or constant variables\n-------------------------------------------------------------------------------\n\n. vl list (weight), min max obs\n\n-------------------------------------------------------------------------------\nVariable | Macro           Values         Levels       Min       Max        Obs\n---------+---------------------------------------------------------------------\n  weight | $vlcontinuous   integers &gt;=0       34      3170      4840         39\n  weight | $mylist1        integers &gt;=0       34      3170      4840         39\n  weight | $mylist2        integers &gt;=0       34      3170      4840         39\n-------------------------------------------------------------------------------\nWhen the update option is passed, variable lists are not affected, only stored statistics are updated."
  },
  {
    "objectID": "05-programming.html#linking-data-sets",
    "href": "05-programming.html#linking-data-sets",
    "title": "5  Programming & Advanced Features",
    "section": "5.3 Linking data sets",
    "text": "5.3 Linking data sets\nIn addition to allowing multiple data sets to be open at a time, we can link frames together such that rows of data in each frames are connected to each-other and can inter-operate. This requires a linking variable in each data set which will connect the rows. The two data sets can be at the same levels or at different levels.\nFor example, we might have data sets collected from multiple waves of surveys and follow-ups during which the same people (modulo some non-responses) are contained in each data set. Then the person ID variable in the data sets would be the linking variable.\nAnother example might be one file at the person level, and another file at the city level. The linking variable would be city name, which would be unique in the city file, but could potentially be repeated in the person level file.\nThe command to link files is frlink and requires specifying both the linking variable(s) and the frame to link to.\nfrlink 1:1 linkvar, frame(otherframe)\nLet’s load some data from NHANES. Each file contains a row per subject.\n. frame reset\n\n. frame rename default demographics\n\n. frame create diet\n\n. frame create bp\n\n. \n. import sasxport5 \"https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/DEMO_I.XPT\", cle\n&gt; ar\n\n. frame diet: import sasxport5 \"https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/DR1T\n&gt; OT_I.XPT\", clear\n\n. frame bp: import sasxport5 \"https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/BPX_I.\n&gt; XPT\", clear\n\n. frame dir\n* bp            9544 x 21\n* demographics  9971 x 47\n* diet          9544 x 168\n\nNote: Frames marked with * contain unsaved data.\nSo as you can see, the current frame is the “demographics” frame, and the other frames contains diet and blood pressure information. The variable seqn records person ID.\n. frlink 1:1 seqn, frame(bp)\n(427 observations in frame demographics unmatched)\n\n. frlink 1:1 seqn, frame(diet)\n(427 observations in frame demographics unmatched)\nThe 1:1 subcommand specifies that it is a 1-to-1 link - each person has no more than 1 row of data in each file. An alternative is m:1 which allows multiple rows in the main file to be linked to a single row in the second frame. 1:m is not allowed at this point in time.\nThese commands created two new variables bp and diet (the same new as the linked frames) which indicate which row of the linked from is connected with the given row.\n. list bp diet in 25/29\n\n     +-----------+\n     | bp   diet |\n     |-----------|\n 25. | 25     25 |\n 26. | 26     26 |\n 27. |  .      . |\n 28. | 27     27 |\n 29. | 28     28 |\n     +-----------+\nHere we see that row 27 in the demographics file was not found in either “bp” or “diet” and thus has no entry in the bp or diet variables.\nLinks are tracked by the variables, we can see the current status of a link via frlink describe:\n. frlink describe diet\n\n  History:\n  -----------------------------------------------------------------------------\n    Link variable diet created on 11 Aug 2023 by\n\n    . frlink 1:1 seqn, frame(diet)\n\n    Frame diet contained an unnamed dataset\n  -----------------------------------------------------------------------------\n  Verifying linkage ...\n  Linkage is up to date.\nWe can see all links from the current frame via frlink dir:\n. frlink dir\n  (2 frlink variables found)\n  -----------------------------------------------------------------------------\n  bp created by frlink 1:1 seqn, frame(bp)\n  -----------------------------------------------------------------------------\n  diet created by frlink 1:1 seqn, frame(diet)\n  -----------------------------------------------------------------------------\n  Note: Type \"frlink describe varname\" to find out more, including whether\n  the variable is still valid.\nTo unlink frames, simply drop the variable.\n. drop diet\nFinally, the names of the created variables can be modified via the generate option to frlink:\n. frlink 1:1 seqn, frame(diet) generate(linkdiet)\n(427 observations in frame demographics unmatched)\n\n. frlink dir\n  (2 frlink variables found)\n  -----------------------------------------------------------------------------\n  bp created by frlink 1:1 seqn, frame(bp)\n  -----------------------------------------------------------------------------\n  linkdiet created by frlink 1:1 seqn, frame(diet) generate(linkdiet)\n  -----------------------------------------------------------------------------\n  Note: Type \"frlink describe varname\" to find out more, including whether\n  the variable is still valid.\n\n5.3.1 Working with linked frames\nOnce we have linked frames, we can use variables in the linked frame in analyses on the main frame.\nThe frget command can copy variables from the linked frame into the primary frame.\n. summarize bpxchr\nvariable bpxchr not found\nr(111);\n\n. frget bpxchr, from(bp)\n(8,033 missing values generated)\n(1 variable copied from linked frame)\n\n. summarize bpxchr\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n      bpxchr |      1,938    106.5614    21.75754         58        190\nThis merges appropriately, with a 1:1 or m:1 link, to properly associate the values of the variable with the right observations.\nAlternatively, when using generate, we can reference a variable in another frame.\n. gen nonsense = frval(linkdiet, dr1tcalc)/frval(bp, bpxpls) + dmdhrage\n(3,158 missing values generated)\nNote that this calculation used variables from all three frames. A less nonsensical example might be where we want the percent of a countries population located in a given state. Imagine we have the primary frame of county data, and then a separate frame “state” containing state level information.\ngen percentpopulation = population/frval(state, population)"
  },
  {
    "objectID": "05-programming.html#loops",
    "href": "05-programming.html#loops",
    "title": "5  Programming & Advanced Features",
    "section": "5.4 Loops",
    "text": "5.4 Loops\nUsing macros can simplify code if you have to use the same string repeatedly, but what if you want to perform the same command repeatedly with different variables? Here we can use a foreach loop. This is easiest to see with examples.\n. sysuse pop2000, clear\n(2000 U.S. Census population by age and sex)\nThe “pop2000” data contains data from the 2000 census, broken down by age and gender. The values are in total counts, lets say instead we want percentages by gender. For example, what percentage of Asians in age 25-29 are male? We could generate this manually.\n. gen maletotalperc = maletotal/total\n\n. gen femtotalperc = femtotal/total\n\n. gen malewhiteperc = malewhite/white\nThis gets tedious fast as we need a total of 12 lines! Notice, however, that each line has a predictable pattern:\ngen &lt;gender&gt;&lt;race&gt;perc = &lt;gender&gt;&lt;race&gt;/&lt;race&gt;\nWe can exploit this by creating a foreach loop over the racial categories and only needing a single command.\n. drop *perc\n\n. foreach race of varlist total-island {\n  2.   gen male`race'perc = male`race'/`race'\n  3.   gen fem`race'perc = fem`race'/`race'\n  4. }\n\n. list *perc in 1, ab(100)\n\n     +---------------------------------------------------------------+\n  1. | maletotalperc | femtotalperc | malewhiteperc  | femwhiteperc  |\n     |      .5116206 |     .4883794 |      .5130497  |     .4869503  |\n     |---------------+--------------+----------------+---------------|\n     | maleblackperc | femblackperc | maleindianperc | femindianperc |\n     |      .5078017 |     .4921983 |       .5100116 |      .4899884 |\n     |---------------+--------------+----------------+---------------|\n     | maleasianperc | femasianperc | maleislandperc | femislandperc |\n     |      .5029027 |     .4970973 |       .5167261 |      .4832739 |\n     +---------------------------------------------------------------+\nLet’s breakdown each piece of the command. The command syntax for foreach is\nforeach &lt;new macroname&gt; of varlist &lt;list of variables&gt;\nThe loop will create a macro that you name (in the example above, it was named “race”), and repeatedly set it to each subsequent entry in the list of variables. So in the code above, first “race” is set to “total”, then the two gen commands are run. Next, “race” is set to “white”, then the two commands are run. Etc.\nWithin each of the gen commands, we use the backtick-quote notation just like with macros.\nFinally, we end the foreach line with an open curly brace, {, and the line after the last command within the loop has the matching close curly brace, }.\nWe can also nest these loops. Notice that both gen statements above are identical except for “male” vs “fem”. Let’s put an internal loop:\n. drop *perc\n\n. foreach race of varlist total-island {\n  2.   foreach gender in male fem {\n  3.     gen `gender'`race'perc = `gender'`race'/`race'\n  4.   }\n  5. }\n\n. list *perc in 1, ab(100)\n\n     +---------------------------------------------------------------+\n  1. | maletotalperc | femtotalperc | malewhiteperc  | femwhiteperc  |\n     |      .5116206 |     .4883794 |      .5130497  |     .4869503  |\n     |---------------+--------------+----------------+---------------|\n     | maleblackperc | femblackperc | maleindianperc | femindianperc |\n     |      .5078017 |     .4921983 |       .5100116 |      .4899884 |\n     |---------------+--------------+----------------+---------------|\n     | maleasianperc | femasianperc | maleislandperc | femislandperc |\n     |      .5029027 |     .4970973 |       .5167261 |      .4832739 |\n     +---------------------------------------------------------------+\nEach time “race” gets set to a new variable, we enter another loop where “gender” gets set first to “male” then to “fem”. To help visualize it, here is what “race” and “gender” are set to each time the gen command is run:\n\n\n\ngen command\n“race”\n“gender”\n\n\n\n\n1\ntotal\nmale\n\n\n2\ntotal\nfem\n\n\n3\nwhite\nmale\n\n\n4\nwhite\nfem\n\n\n5\nblack\nmale\n\n\n6\nblack\nfem\n\n\n7\nindian\nmale\n\n\n8\nindian\nfem\n\n\n9\nasian\nmale\n\n\n10\nasian\nfem\n\n\n11\nisland\nmale\n\n\n12\nisland\nfem\n\n\n\nNotice the syntax of the above two foreach differs slightly:\nforeach &lt;macro name&gt; of varlist &lt;variables&gt;\nforeach &lt;macro name&gt; in &lt;list of strings&gt;\nIt’s a bit annoying, but Stata handles the “of” and “in” slight differently. The “in” treats any strings on the right as strict. Meaning if the above loop over race were\nforeach race in total-island\nthen Stata would set “race” to “total-island” and the gen command would run once! By using “of varlist”, you are telling Stata that before it sets “race” to anything, expand the varlist using the [rules such as * and -][referring to variables].\nThere is also\nforeach &lt;macro name&gt; of numlist &lt;list of numbers&gt;\nThe benefit of “of numlist” is that numlists support things like 1/4 representing 1, 2, 3, 4. So\nforeach num of numlist 1 3/5\nLoops over 1, 3, 4, 5, whereas\nforeach num in 1 3/5\nloops over just “1” and “3/5”.\nThe use of “in” is for when you need to loop over strings that are neither numbers nor variables (such as “male” and “fem” from above)."
  },
  {
    "objectID": "05-programming.html#suppressing-output-and-errors",
    "href": "05-programming.html#suppressing-output-and-errors",
    "title": "5  Programming & Advanced Features",
    "section": "5.5 Suppressing output and errors",
    "text": "5.5 Suppressing output and errors\nThere are two useful command prefixes that can be handy while writing more elaborate Do-files.\n\n5.5.1 Capturing an error\nImagine the following scenario. You want to write a Do-file that generates a new variable. However, you may need to re-run chunks of the Do-file repeatedly, so that the gen statement is hit repeatedly. After the first gen, we can’t call it again and need to use replace instead. However, if we used replace, it wouldn’t work the first time! One solution is to drop the variable before we gen it:\n. sysuse auto, clear\n(1978 automobile data)\n\n. drop newvar\nvariable newvar not found\nr(111);\n\n. gen newvar = 1\nThat error, while not breaking the code, is awfully annoying! However, if we prefix it by capture, the error (and all output from the command) are “captured” and hidden.\n. list price in 1/5\n\n     +-------+\n     | price |\n     |-------|\n  1. | 4,099 |\n  2. | 4,749 |\n  3. | 3,799 |\n  4. | 4,816 |\n  5. | 7,827 |\n     +-------+\n\n. capture list price in 1/5\n\n. list abcd\nvariable abcd not found\nr(111);\n\n. capture list abcd\nTherefore, the best way to generate our new variable is\n. capture drop newvar\n\n. gen newvar = 1\n\n5.5.1.1 Return Code\nWhen you capture a command that errors, Stata saves the error code in the _rc macro.\n. list abc\nvariable abc not found\nr(111);\n\n. capture list abc\n\n. display _rc\n111\nIf the command does not error, _rc contains 0.\n. capture list price\n\n. display _rc\n0\nThis can be used to offer additional code if an error occurs\ncapture &lt;code that runs without error if something is true, but errors otherwise&gt;\nif _rc &gt; 0 {\n  ...\n}\nIf the code inside the capture runs without error, the if block will run. If the code inside the capture errors, the else block will run.\nSay you wanted to rename a variable if it exists, and if doesn’t exist, create it. (For example, you have to process a large number of files, and in some files, this variable may be missing for all rows and thus not reported.) You could run the following:\ncapture rename oldvar newvar\nif _rc &gt; 0 {\n  gen newvar = .\n}\n\n\n\n5.5.2 Quieting the output\nquietly does the same basic thing as capture, except it does not hide errors. It can be useful combined with the returns:\n. quietly summ price\n\n. display r(mean)\n6165.2568\nThis will come in very handy when you start running statistical models, where the output can be over a single screen, whereas you only want a small piece of it.\nJust to make the difference between capture and quietly clear:\n. list price in 1/5\n\n     +-------+\n     | price |\n     |-------|\n  1. | 4,099 |\n  2. | 4,749 |\n  3. | 3,799 |\n  4. | 4,816 |\n  5. | 7,827 |\n     +-------+\n\n. quietly list price in 1/5\n\n. capture list price in 1/5\n\n. list abcd in 1/5\nvariable abcd not found\nr(111);\n\n. quietly list abcd in 1/5\nvariable abcd not found\nr(111);\n\n. capture list abcd in 1/5\nWith a command that doesn’t error (listing price), both quietly and capture perform the same. However, with a command that does error, quietly still errors, whereas capture just ignores it!"
  },
  {
    "objectID": "05-programming.html#footnotes",
    "href": "05-programming.html#footnotes",
    "title": "5  Programming & Advanced Features",
    "section": "",
    "text": "“Local” as opposed to “global”, a distinction which is not important until you get deep into programming. For now, local is the safer option.↩︎\nThere are obviously other ways to compute this, but this gives a flavor of the use.↩︎\nMy guess is that nonotes will become the default in a version or 2, once users become used to vl.↩︎"
  },
  {
    "objectID": "appendix.html#solutions",
    "href": "appendix.html#solutions",
    "title": "Appendix",
    "section": "Solutions",
    "text": "Solutions\n\nExercise 1 Solution\n[Exercise 1][Exercise 1]\n1:\nsysuse lifeexp\n3:\nsysuse sandstone, clear\nor\nclear\nsysuse sandstone\n4: If the working directory isn’t convenient, change it using the dialogue box. Then, save sandstone.\n\n\nExercise 2 Solution\n[Exercise 2][Exercise 2]\n1:\nwebuse census9, clear\n2: Data is from the 1980 census, which we can see by the label (visible in describe, simple). We’ve got two identifiers of state, death rate, population, median age and census region.\n3: Since there data has 50 rows, it’s a good guess there are no missing sates.\n4: Looking at describe, we see that the two state identifiers are strings, the rest numeric.\n5: compress. Nothing saved! Because Stata already did it before posting it!\n\n\nExercise 3 Solution\n[Exercise 3][Exercise 3]\n1:\n. webuse census9, clear\n(1980 Census data by state)\n\n. save mycensus9\nfile mycensus9.dta already exists\nr(602);\n\n```~\n\n2:\n\n```stata\n. rename drate deathrate\n\n. label variable deathrate \"Death rate per 10,000\"\n3:\n. tab region\n\n     Census |\n     region |      Freq.     Percent        Cum.\n------------+-----------------------------------\n         NE |          9       18.00       18.00\n    N Cntrl |         12       24.00       42.00\n      South |         16       32.00       74.00\n       West |         13       26.00      100.00\n------------+-----------------------------------\n      Total |         50      100.00\n\n. label list cenreg\ncenreg:\n           1 NE\n           2 N Cntrl\n           3 South\n           4 West\n\n. label define region_label 1 \"Northeast\" 2 \"North Central\" 3 \"South\" 4 \"West\"\n\n. label values region region_label\n\n. label drop cenreg\n\n. label list\nregion_label:\n           1 Northeast\n           2 North Central\n           3 South\n           4 West\n\n. tab region\n\nCensus region |      Freq.     Percent        Cum.\n--------------+-----------------------------------\n    Northeast |          9       18.00       18.00\nNorth Central |         12       24.00       42.00\n        South |         16       32.00       74.00\n         West |         13       26.00      100.00\n--------------+-----------------------------------\n        Total |         50      100.00\n4:\n. save, replace\nmay not write files over Internet\nr(633);\n\n\nExercise 4 Solution\n[Exercise 4][Exercise 4]\n1: Use summarize and codebook to take a look at the mean/max/min. No errors detected.\n2:\n. codebook, compact\n\nVariable   Obs Unique     Mean     Min       Max  Label\n-------------------------------------------------------------------------------\nstate       50     50        .       .         .  State\nstate2      50     50        .       .         .  Two-letter state abbreviation\ndeathrate   50     30     84.3      40       107  Death rate per 10,000\npop         50     50  4518149  401851  2.37e+07  Population\nmedage      50     37    29.54    24.2      34.7  Median age\nregion      50      4     2.66       1         4  Census region\n-------------------------------------------------------------------------------\ndeathrate and medage both have less than 50 unique values. This is due to both being heavily rounded. If we saw more precision, there would be more unique entires.\n3:\n. codebook, problems\n\nPotential problems in dataset https://www.stata-press.com/data/r18/census9.dta\n\n               Potential problem   Variables\n--------------------------------------------------\nstring vars with embedded blanks   state\n--------------------------------------------------\nThis just flags spaces (” “) in the data. Not a real problem!\n\n\nExercise 5 Solution\n[Exercise 5][Exercise 5]\n1:\n. gen deathperc = deathrate/10000\n\n. label variable deathperc \"Percentage of population deceeased in 1980\"\n\n. list death* in 1/5\n\n     +---------------------+\n     | deathr~e   deathp~c |\n     |---------------------|\n  1. |       91      .0091 |\n  2. |       40       .004 |\n  3. |       78      .0078 |\n  4. |       99      .0099 |\n  5. |       79      .0079 |\n     +---------------------+\n2:\n. gen agecat = 1 if medage &lt; .\n\n. replace agecat = 2 if medage &gt; 26.2 & medage &lt;= 30.1\n(30 real changes made)\n\n. replace agecat = 3 if medage &gt; 30.1 & medage &lt;= 32.8\n(17 real changes made)\n\n. replace agecat = 4 if medage &gt; 32.8\n(1 real change made)\n\n. label define agecat_label 1 \"Significantly below national average\" ///\n&gt;                           2 \"Below national average\" ///\n&gt;                           3 \"Above national average\" ///\n&gt;                           4 \"Significantly above national average\"\n\n. label values agecat agecat_label\n\n. tab agecat, mi\n\n                              agecat |      Freq.     Percent        Cum.\n-------------------------------------+-----------------------------------\nSignificantly below national average |          2        4.00        4.00\n              Below national average |         30       60.00       64.00\n              Above national average |         17       34.00       98.00\nSignificantly above national average |          1        2.00      100.00\n-------------------------------------+-----------------------------------\n                               Total |         50      100.00\nWe have no missing data (seen with summarize and codebook in the previous exercise) but it’s good practice to check for them anyways.\n3:\n. bysort agecat: summarize deathrate\n\n-------------------------------------------------------------------------------\n-&gt; agecat = Significantly below national average\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n   deathrate |          2        47.5     10.6066         40         55\n\n-------------------------------------------------------------------------------\n-&gt; agecat = Below national average\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n   deathrate |         30    81.76667    9.761583         50         94\n\n-------------------------------------------------------------------------------\n-&gt; agecat = Above national average\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n   deathrate |         17    91.76471    8.422659         73        104\n\n-------------------------------------------------------------------------------\n-&gt; agecat = Significantly above national average\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n   deathrate |          1         107           .        107        107\n\nWe see that the groups with the higher median age tend to have higher deathrates.\n4:\n. preserve\n\n. gsort -deathrate\n\n. list state deathrate in 1\n\n     +--------------------+\n     | state     deathr~e |\n     |--------------------|\n  1. | Florida        107 |\n     +--------------------+\n\n. gsort +deathrate\n\n. list state deathrate in 1\n\n     +-------------------+\n     | state    deathr~e |\n     |-------------------|\n  1. | Alaska         40 |\n     +-------------------+\n\n. gsort -medage\n\n. list state medage in 1\n\n     +------------------+\n     | state     medage |\n     |------------------|\n  1. | Florida    34.70 |\n     +------------------+\n\n. gsort +medage\n\n. list state medage in 1\n\n     +----------------+\n     | state   medage |\n     |----------------|\n  1. | Utah     24.20 |\n     +----------------+\n\n. restore\n5:\n. encode state2, gen(statecodes)\n\n. codebook statecodes\n\n-------------------------------------------------------------------------------\nstatecodes                                        Two-letter state abbreviation\n-------------------------------------------------------------------------------\n\n                  Type: Numeric (long)\n                 Label: statecodes\n\n                 Range: [1,50]                        Units: 1\n         Unique values: 50                        Missing .: 0/50\n\n              Examples: 10    GA\n                        20    MD\n                        30    NH\n                        40    SC"
  }
]